caret_22_feature_selection_using_simulated_annealing
22 Feature Selection using Simulated Annealing
feature-selection-using-simulated-annealing.html
 22.3 Basic Syntax The syntax of this function is very similar to the previous information for genetic algorithm searches. The most basic usage of the function is: where x : a data frame or matrix of predictor values y : a factor or numeric vector of outcomes iters : the number of iterations for the SA This isn’t very specific. All of the action is in the control function. That can be used to specify the model to be fit, how predictions are made and summarized as well as the genetic operations. Suppose that we want to fit a linear regression model. To do this, we can use train as an interface and pass arguments to that function through safs : Other options, such as preProcess , can be passed in as well. Some important options to safsControl are: method , number , repeats , index , indexOut , etc: options similar to those for train top control resampling. metric : this is similar to train ’s option but, in this case, the value should be a named vector with values for the internal and external metrics. If none are specified, the first value returned by the summary functions (see details below) are used and a warning is issued. A similar two-element vector for the option maximize is also required. See the last example here for an illustration. holdout : this is a number between [0, 1) that can be used to hold out samples for computing the internal fitness value. Note that this is independent of the external resampling step. Suppose 10-fold CV is being used. Within a resampling iteration, holdout can be used to sample an additional proportion of the 90% resampled data to use for estimating fitness. This may not be a good idea unless you have a very large training set and want to avoid an internal resampling procedure to estimate fitness. improve : an integer (or infinity) defining how many iterations should pass without an improvement in fitness before the current subset is reset to the last known improvement. allowParallel : should the external resampling loop be run in parallel?. There are a few built-in sets of functions to use with safs : caretSA , rfSA , and treebagSA . The first is a simple interface to train . When using this, as shown above, arguments can be passed to train using the ... structure and the resampling estimates of performance can be used as the internal fitness value. The functions provided by rfSA and treebagSA avoid using train and their internal estimates of fitness come from using the out-of-bag estimates generated from the model. 