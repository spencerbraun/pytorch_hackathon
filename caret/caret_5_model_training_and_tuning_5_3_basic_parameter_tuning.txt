caret_5_model_training_and_tuning
5 Model Training and Tuning
model-training-and-tuning.html
 5.3 Basic Parameter Tuning By default, simple bootstrap resampling is used for line 3 in the algorithm above. Others are available, such as repeated K -fold cross-validation, leave-one-out etc. The function trainControl can be used to specifiy the type of resampling: More information about trainControl is given in a section below . The first two arguments to train are the predictor and outcome data objects, respectively. The third argument, method , specifies the type of model (see train Model List or train Models By Tag ). To illustrate, we will fit a boosted tree model via the gbm package. The basic syntax for fitting this model using repeated cross-validation is shown below: For a gradient boosting machine (GBM) model, there are three main tuning parameters: number of iterations, i.e. trees, (called n.trees in the gbm function) complexity of the tree, called interaction.depth learning rate: how quickly the algorithm adapts, called shrinkage the minimum number of training set samples in a node to commence splitting ( n.minobsinnode ) The default values tested for this model are shown in the first two columns ( shrinkage and n.minobsinnode are not shown beause the grid set of candidate models all use a single value for these tuning parameters). The column labeled “ Accuracy ” is the overall agreement rate averaged over cross-validation iterations. The agreement standard deviation is also calculated from the cross-validation results. The column “ Kappa ” is Cohen’s (unweighted) Kappa statistic averaged across the resampling results. train works with specific models (see train Model List or train Models By Tag ). For these models, train can automatically create a grid of tuning parameters. By default, if p is the number of tuning parameters, the grid size is 3^p . As another example, regularized discriminant analysis (RDA) models have two parameters ( gamma and lambda ), both of which lie between zero and one. The default training grid would produce nine combinations in this two-dimensional space. There is additional functionality in train that is described in the next section. 