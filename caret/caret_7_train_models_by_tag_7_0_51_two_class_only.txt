caret_7_train_models_by_tag
7 train Models By Tag
train-models-by-tag.html
 7.0.51 Two Class Only (back to contents ) AdaBoost Classification Trees Type: Classification Tuning parameters: nIter (#Trees) method (Method) Required packages: fastAdaboost Bagged Logic Regression Type: Regression, Classification Tuning parameters: nleaves (Maximum Number of Leaves) ntrees (Number of Trees) Required packages: logicFS Notes: Unlike other packages used by train , the logicFS package is fully loaded when this model is used. Bayesian Additive Regression Trees Type: Classification, Regression Tuning parameters: num_trees (#Trees) k (Prior Boundary) alpha (Base Terminal Node Hyperparameter) beta (Power Terminal Node Hyperparameter) nu (Degrees of Freedom) Required packages: bartMachine A model-specific variable importance metric is available. Binary Discriminant Analysis Type: Classification Tuning parameters: lambda.freqs (Shrinkage Intensity) Required packages: binda Boosted Classification Trees Type: Classification Tuning parameters: iter (#Trees) maxdepth (Max Tree Depth) nu (Learning Rate) Required packages: ada , plyr Boosted Generalized Additive Model Type: Regression, Classification Tuning parameters: mstop (# Boosting Iterations) prune (AIC Prune?) Required packages: mboost , plyr , import Notes: The prune option for this model enables the number of iterations to be determined by the optimal AIC value across all iterations. See the examples in ?mboost::mstop . If pruning is not used, the ensemble makes predictions using the exact value of the mstop tuning parameter value. Boosted Generalized Linear Model Type: Regression, Classification Tuning parameters: mstop (# Boosting Iterations) prune (AIC Prune?) Required packages: plyr , mboost A model-specific variable importance metric is available. Notes: The prune option for this model enables the number of iterations to be determined by the optimal AIC value across all iterations. See the examples in ?mboost::mstop . If pruning is not used, the ensemble makes predictions using the exact value of the mstop tuning parameter value. CHi-squared Automated Interaction Detection Type: Classification Tuning parameters: alpha2 (Merging Threshold) alpha3 (Splitting former Merged Threshold) alpha4 ( Splitting former Merged Threshold) Required packages: CHAID Cost-Sensitive C5.0 Type: Classification Tuning parameters: trials (# Boosting Iterations) model (Model Type) winnow (Winnow) cost (Cost) Required packages: C50 , plyr A model-specific variable importance metric is available. Cost-Sensitive CART Type: Classification Tuning parameters: cp (Complexity Parameter) Cost (Cost) Required packages: rpart , plyr DeepBoost Type: Classification Tuning parameters: num_iter (# Boosting Iterations) tree_depth (Tree Depth) beta (L1 Regularization) lambda (Tree Depth Regularization) loss_type (Loss) Required packages: deepboost Distance Weighted Discrimination with Polynomial Kernel Type: Classification Tuning parameters: lambda (Regularization Parameter) qval (q) degree (Polynomial Degree) scale (Scale) Required packages: kerndwd Distance Weighted Discrimination with Radial Basis Function Kernel Type: Classification Tuning parameters: lambda (Regularization Parameter) qval (q) sigma (Sigma) Required packages: kernlab , kerndwd Generalized Linear Model Type: Regression, Classification No tuning parameters for this model A model-specific variable importance metric is available. Generalized Linear Model with Stepwise Feature Selection Type: Regression, Classification No tuning parameters for this model Required packages: MASS glmnet Type: Regression, Classification Tuning parameters: alpha (Mixing Percentage) lambda (Regularization Parameter) Required packages: h2o A model-specific variable importance metric is available. L2 Regularized Linear Support Vector Machines with Class Weights Type: Classification Tuning parameters: cost (Cost) Loss (Loss Function) weight (Class Weight) Required packages: LiblineaR Linear Distance Weighted Discrimination Type: Classification Tuning parameters: lambda (Regularization Parameter) qval (q) Required packages: kerndwd Linear Support Vector Machines with Class Weights Type: Classification Tuning parameters: cost (Cost) weight (Class Weight) Required packages: e1071 Logic Regression Type: Regression, Classification Tuning parameters: treesize (Maximum Number of Leaves) ntrees (Number of Trees) Required packages: LogicReg Multilayer Perceptron Network with Dropout Type: Classification Tuning parameters: size (#Hidden Units) dropout (Dropout Rate) batch_size (Batch Size) lr (Learning Rate) rho (Rho) decay (Learning Rate Decay) cost (Cost) activation (Activation Function) Required packages: keras Notes: After train completes, the keras model object is serialized so that it can be used between R session. When predicting, the code will temporarily unsearalize the object. To make the predictions more efficient, the user might want to use keras::unsearlize_model(object$finalModel$object) in the current R session so that that operation is only done once. Also, this model cannot be run in parallel due to the nature of how tensorflow does the computations. Finally, the cost parameter weights the first class in the outcome vector. Unlike other packages used by train , the dplyr package is fully loaded when this model is used. Multilayer Perceptron Network with Weight Decay Type: Classification Tuning parameters: size (#Hidden Units) lambda (L2 Regularization) batch_size (Batch Size) lr (Learning Rate) rho (Rho) decay (Learning Rate Decay) cost (Cost) activation (Activation Function) Required packages: keras Notes: After train completes, the keras model object is serialized so that it can be used between R session. When predicting, the code will temporarily unsearalize the object. To make the predictions more efficient, the user might want to use keras::unsearlize_model(object$finalModel$object) in the current R session so that that operation is only done once. Also, this model cannot be run in parallel due to the nature of how tensorflow does the computations. Finally, the cost parameter weights the first class in the outcome vector. Unlike other packages used by train , the dplyr package is fully loaded when this model is used. Oblique Random Forest Type: Classification Tuning parameters: mtry (#Randomly Selected Predictors) Required packages: obliqueRF Notes: Unlike other packages used by train , the obliqueRF package is fully loaded when this model is used. Oblique Random Forest Type: Classification Tuning parameters: mtry (#Randomly Selected Predictors) Required packages: obliqueRF Notes: Unlike other packages used by train , the obliqueRF package is fully loaded when this model is used. Oblique Random Forest Type: Classification Tuning parameters: mtry (#Randomly Selected Predictors) Required packages: obliqueRF Notes: Unlike other packages used by train , the obliqueRF package is fully loaded when this model is used. Oblique Random Forest Type: Classification Tuning parameters: mtry (#Randomly Selected Predictors) Required packages: obliqueRF Notes: Unlike other packages used by train , the obliqueRF package is fully loaded when this model is used. Partial Least Squares Generalized Linear Models Type: Classification, Regression Tuning parameters: nt (#PLS Components) alpha.pvals.expli (p-Value threshold) Required packages: plsRglm Notes: Unlike other packages used by train , the plsRglm package is fully loaded when this model is used. Rotation Forest Type: Classification Tuning parameters: K (#Variable Subsets) L (Ensemble Size) Required packages: rotationForest A model-specific variable importance metric is available. Rotation Forest Type: Classification Tuning parameters: K (#Variable Subsets) L (Ensemble Size) cp (Complexity Parameter) Required packages: rpart , plyr , rotationForest A model-specific variable importance metric is available. Support Vector Machines with Class Weights Type: Classification Tuning parameters: sigma (Sigma) C (Cost) Weight (Weight) Required packages: kernlab Tree-Based Ensembles Type: Regression, Classification Tuning parameters: maxinter (Maximum Interaction Depth) mode (Prediction Mode) Required packages: nodeHarvest 