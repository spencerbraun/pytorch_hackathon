caret_19_feature_selection_using_univariate_filters
19 Feature Selection using Univariate Filters
feature-selection-using-univariate-filters.html
 19.1 Univariate Filters Another approach to feature selection is to pre-screen the predictors using simple univariate statistical methods then only use those that pass some criterion in the subsequent model steps. Similar to recursive selection, cross-validation of the subsequent models will be biased as the remaining predictors have already been evaluate on the data set. Proper performance estimates via resampling should include the feature selection step. As an example, it has been suggested for classification models, that predictors can be filtered by conducting some sort of k -sample test (where k is the number of classes) to see if the mean of the predictor is different between the classes. Wilcoxon tests, t -tests and ANOVA models are sometimes used. Predictors that have statistically significant differences between the classes are then used for modeling. The caret function sbf (for selection by filter) can be used to cross-validate such feature selection schemes. Similar to rfe , functions can be passed into sbf for the computational components: univariate filtering, model fitting, prediction and performance summaries (details are given below). The function is applied to the entire training set and also to different resampled versions of the data set. From this, generalizable estimates of performance can be computed that properly take into account the feature selection step. Also, the results of the predictor filters can be tracked over resamples to understand the uncertainty in the filtering. 