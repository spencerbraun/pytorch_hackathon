caret_7_train_models_by_tag
7 train Models By Tag
train-models-by-tag.html
 7.0.1 Accepts Case Weights (back to contents ) Adjacent Categories Probability Model for Ordinal Data Type: Classification Tuning parameters: parallel (Parallel Curves) link (Link Function) Required packages: VGAM Bagged CART Type: Regression, Classification No tuning parameters for this model Required packages: ipred , plyr , e1071 A model-specific variable importance metric is available. Bagged Flexible Discriminant Analysis Type: Classification Tuning parameters: degree (Product Degree) nprune (#Terms) Required packages: earth , mda A model-specific variable importance metric is available. Notes: Unlike other packages used by train , the earth package is fully loaded when this model is used. Bagged MARS Type: Regression, Classification Tuning parameters: nprune (#Terms) degree (Product Degree) Required packages: earth A model-specific variable importance metric is available. Notes: Unlike other packages used by train , the earth package is fully loaded when this model is used. Bagged MARS using gCV Pruning Type: Regression, Classification Tuning parameters: degree (Product Degree) Required packages: earth A model-specific variable importance metric is available. Notes: Unlike other packages used by train , the earth package is fully loaded when this model is used. Bayesian Generalized Linear Model Type: Regression, Classification No tuning parameters for this model Required packages: arm Boosted Generalized Additive Model Type: Regression, Classification Tuning parameters: mstop (# Boosting Iterations) prune (AIC Prune?) Required packages: mboost , plyr , import Notes: The prune option for this model enables the number of iterations to be determined by the optimal AIC value across all iterations. See the examples in ?mboost::mstop . If pruning is not used, the ensemble makes predictions using the exact value of the mstop tuning parameter value. Boosted Generalized Linear Model Type: Regression, Classification Tuning parameters: mstop (# Boosting Iterations) prune (AIC Prune?) Required packages: plyr , mboost A model-specific variable importance metric is available. Notes: The prune option for this model enables the number of iterations to be determined by the optimal AIC value across all iterations. See the examples in ?mboost::mstop . If pruning is not used, the ensemble makes predictions using the exact value of the mstop tuning parameter value. Boosted Tree Type: Regression, Classification Tuning parameters: mstop (#Trees) maxdepth (Max Tree Depth) Required packages: party , mboost , plyr , partykit C5.0 Type: Classification Tuning parameters: trials (# Boosting Iterations) model (Model Type) winnow (Winnow) Required packages: C50 , plyr A model-specific variable importance metric is available. CART Type: Regression, Classification Tuning parameters: cp (Complexity Parameter) Required packages: rpart A model-specific variable importance metric is available. CART Type: Regression, Classification No tuning parameters for this model Required packages: rpart A model-specific variable importance metric is available. Notes: This CART model replicates the same process used by the rpart function where the model complexity is determined using the one-standard error method. This procedure is replicated inside of the resampling done by train so that an external resampling estimate can be obtained. CART Type: Regression, Classification Tuning parameters: maxdepth (Max Tree Depth) Required packages: rpart A model-specific variable importance metric is available. CART or Ordinal Responses Type: Classification Tuning parameters: cp (Complexity Parameter) split (Split Function) prune (Pruning Measure) Required packages: rpartScore , plyr A model-specific variable importance metric is available. CHi-squared Automated Interaction Detection Type: Classification Tuning parameters: alpha2 (Merging Threshold) alpha3 (Splitting former Merged Threshold) alpha4 ( Splitting former Merged Threshold) Required packages: CHAID Conditional Inference Random Forest Type: Classification, Regression Tuning parameters: mtry (#Randomly Selected Predictors) Required packages: party A model-specific variable importance metric is available. Conditional Inference Tree Type: Classification, Regression Tuning parameters: mincriterion (1 - P-Value Threshold) Required packages: party Conditional Inference Tree Type: Regression, Classification Tuning parameters: maxdepth (Max Tree Depth) mincriterion (1 - P-Value Threshold) Required packages: party Continuation Ratio Model for Ordinal Data Type: Classification Tuning parameters: parallel (Parallel Curves) link (Link Function) Required packages: VGAM Cost-Sensitive C5.0 Type: Classification Tuning parameters: trials (# Boosting Iterations) model (Model Type) winnow (Winnow) cost (Cost) Required packages: C50 , plyr A model-specific variable importance metric is available. Cost-Sensitive CART Type: Classification Tuning parameters: cp (Complexity Parameter) Cost (Cost) Required packages: rpart , plyr Cumulative Probability Model for Ordinal Data Type: Classification Tuning parameters: parallel (Parallel Curves) link (Link Function) Required packages: VGAM DeepBoost Type: Classification Tuning parameters: num_iter (# Boosting Iterations) tree_depth (Tree Depth) beta (L1 Regularization) lambda (Tree Depth Regularization) loss_type (Loss) Required packages: deepboost eXtreme Gradient Boosting Type: Regression, Classification Tuning parameters: nrounds (# Boosting Iterations) max_depth (Max Tree Depth) eta (Shrinkage) gamma (Minimum Loss Reduction) subsample (Subsample Percentage) colsample_bytree (Subsample Ratio of Columns) rate_drop (Fraction of Trees Dropped) skip_drop (Prob. of Skipping Drop-out) min_child_weight (Minimum Sum of Instance Weight) Required packages: xgboost , plyr A model-specific variable importance metric is available. eXtreme Gradient Boosting Type: Regression, Classification Tuning parameters: nrounds (# Boosting Iterations) max_depth (Max Tree Depth) eta (Shrinkage) gamma (Minimum Loss Reduction) colsample_bytree (Subsample Ratio of Columns) min_child_weight (Minimum Sum of Instance Weight) subsample (Subsample Percentage) Required packages: xgboost , plyr A model-specific variable importance metric is available. Flexible Discriminant Analysis Type: Classification Tuning parameters: degree (Product Degree) nprune (#Terms) Required packages: earth , mda A model-specific variable importance metric is available. Notes: Unlike other packages used by train , the earth package is fully loaded when this model is used. Generalized Linear Model Type: Regression, Classification No tuning parameters for this model A model-specific variable importance metric is available. Generalized Linear Model with Stepwise Feature Selection Type: Regression, Classification No tuning parameters for this model Required packages: MASS Linear Regression Type: Regression Tuning parameters: intercept (intercept) A model-specific variable importance metric is available. Linear Regression with Stepwise Selection Type: Regression No tuning parameters for this model Required packages: MASS Model Averaged Neural Network Type: Classification, Regression Tuning parameters: size (#Hidden Units) decay (Weight Decay) bag (Bagging) Required packages: nnet Multivariate Adaptive Regression Spline Type: Regression, Classification Tuning parameters: nprune (#Terms) degree (Product Degree) Required packages: earth A model-specific variable importance metric is available. Notes: Unlike other packages used by train , the earth package is fully loaded when this model is used. Multivariate Adaptive Regression Splines Type: Regression, Classification Tuning parameters: degree (Product Degree) Required packages: earth A model-specific variable importance metric is available. Notes: Unlike other packages used by train , the earth package is fully loaded when this model is used. Negative Binomial Generalized Linear Model Type: Regression Tuning parameters: link (Link Function) Required packages: MASS A model-specific variable importance metric is available. Neural Network Type: Classification, Regression Tuning parameters: size (#Hidden Units) decay (Weight Decay) Required packages: nnet A model-specific variable importance metric is available. Neural Networks with Feature Extraction Type: Classification, Regression Tuning parameters: size (#Hidden Units) decay (Weight Decay) Required packages: nnet Ordered Logistic or Probit Regression Type: Classification Tuning parameters: method (parameter) Required packages: MASS A model-specific variable importance metric is available. Penalized Discriminant Analysis Type: Classification Tuning parameters: lambda (Shrinkage Penalty Coefficient) Required packages: mda Penalized Discriminant Analysis Type: Classification Tuning parameters: df (Degrees of Freedom) Required packages: mda Penalized Multinomial Regression Type: Classification Tuning parameters: decay (Weight Decay) Required packages: nnet A model-specific variable importance metric is available. Projection Pursuit Regression Type: Regression Tuning parameters: nterms (# Terms) Random Forest Type: Classification, Regression Tuning parameters: mtry (#Randomly Selected Predictors) splitrule (Splitting Rule) min.node.size (Minimal Node Size) Required packages: e1071 , ranger , dplyr A model-specific variable importance metric is available. Robust Linear Model Type: Regression Tuning parameters: intercept (intercept) psi (psi) Required packages: MASS A model-specific variable importance metric is available. Single C5.0 Ruleset Type: Classification No tuning parameters for this model Required packages: C50 A model-specific variable importance metric is available. Single C5.0 Tree Type: Classification No tuning parameters for this model Required packages: C50 A model-specific variable importance metric is available. Stochastic Gradient Boosting Type: Regression, Classification Tuning parameters: n.trees (# Boosting Iterations) interaction.depth (Max Tree Depth) shrinkage (Shrinkage) n.minobsinnode (Min. Terminal Node Size) Required packages: gbm , plyr A model-specific variable importance metric is available. Tree Models from Genetic Algorithms Type: Regression, Classification Tuning parameters: alpha (Complexity Parameter) Required packages: evtree 