caret_13_using_your_own_model_in_train
13 Using Your Own Model in train
using-your-own-model-in-train.html
 13.7 Illustrative Example 4: PLS Feature Extraction Pre-Processing PCA is a common tool for feature extraction prior to modeling but is unsupervised . Partial Least Squares (PLS) is essentially a supervised version of PCA. For some data sets, there may be some benefit to using PLS to generate new features from the original data (the PLS scores) then use those as an input into a different predictive model. PLS requires parameter tuning. In the example below, we use PLS on a data set with highly correlated predictors then use the PLS scores in a random forest model. The “trick” here is to save the PLS loadings along with the random forest model fit so that the loadings can be used on future samples for prediction. Also, the PLS and random forest models are jointly tuned instead of an initial modeling process that finalizes the PLS model, then builds the random forest model separately. In this was we optimize both at once. Another important point is that the resampling results reflect the variability in the random forest and PLS models. If we did PLS up-front then resampled the random forest model, we would under-estimate the noise in the modeling process. The tecator spectroscopy data are used: Here is the model code: We fit the models and look at the resampling results for the joint model: The test set results indicate that these data like the linear model more than anything: 