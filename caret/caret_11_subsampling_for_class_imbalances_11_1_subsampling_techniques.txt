caret_11_subsampling_for_class_imbalances
11 Subsampling For Class Imbalances
subsampling-for-class-imbalances.html
 11.1 Subsampling Techniques To illustrate these methods, let’s simulate some data with a class imbalance using this method. We will simulate a training and test set where each contains 10000 samples and a minority class rate of about 5.9%: Let’s create different versions of the training set prior to model tuning: For these data, we’ll use a bagged classification and estimate the area under the ROC curve using five repeats of 10-fold CV. We will collate the resampling results and create a wrapper to estimate the test set performance: The training and test set estimates for the area under the ROC curve do not appear to correlate. Based on the resampling results, one would infer that up-sampling is nearly perfect and that ROSE does relatively poorly. The reason that up-sampling appears to perform so well is that the samples in the majority class are replicated and have a large potential to be in both the model building and hold-out sets. In essence, the hold-outs here are not truly independent samples. In reality, all of the sampling methods do about the same (based on the test set). The statistics for the basic model fit with no sampling are fairly in-line with one another (0.939 via resampling and 0.925 for the test set). 