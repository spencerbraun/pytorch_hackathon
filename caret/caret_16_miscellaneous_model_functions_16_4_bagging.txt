caret_16_miscellaneous_model_functions
16 Miscellaneous Model Functions
miscellaneous-model-functions.html
 16.4 Bagging The bag function offers a general platform for bagging classification and regression models. Like rfe and sbf , it is open and models are specified by declaring functions for the model fitting and prediction code (and several built-in sets of functions exist in the package). The function bagControl has options to specify the functions (more details below). The function also has a few non-standard features: The argument var can enable random sampling of the predictors at each bagging iteration. This is to de-correlate the bagged models in the same spirit of random forests (although here the sampling is done once for the whole model). The default is to use all the predictors for each model. The bagControl function has a logical argument called downSample that is useful for classification models with severe class imbalance. The bootstrapped data set is reduced so that the sample sizes for the classes with larger frequencies are the same as the sample size for the minority class. If a parallel backend for the foreach package has been loaded and registered, the bagged models can be trained in parallel. The function’s control function requires the following arguments: 16.4.1 The fit Function Inputs: x : a data frame of the training set predictor data. y : the training set outcomes. ... arguments passed from train to this function The output is the object corresponding to the trained model and any other objects required for prediction. A simple example for a linear discriminant analysis model from the MASS package is: 16.4.2 The pred Function This should be a function that produces predictors for new samples. Inputs: object : the object generated by the fit module. x : a matrix or data frame of predictor data. The output is either a number vector (for regression), a factor (or character) vector for classification or a matrix/data frame of class probabilities. For classification, it is probably better to average class probabilities instead of using the votes of the class predictions. Using the lda example again: 16.4.3 The aggregate Function This should be a function that takes the predictions from the constituent models and converts them to a single prediction per sample. Inputs: x : a list of objects returned by the pred module. type : an optional string that describes the type of output (e.g. “class”, “prob” etc.). The output is either a number vector (for regression), a factor (or character) vector for classification or a matrix/data frame of class probabilities. For the linear discriminant model above, we saved the matrix of class probabilities. To average them and generate a class prediction, we could use: For example, to bag a conditional inference tree (from the party package): 