caret_21_feature_selection_using_genetic_algorithms
21 Feature Selection using Genetic Algorithms
feature-selection-using-genetic-algorithms.html
 21.1 Genetic Algorithms Genetic algorithms (GAs) mimic Darwinian forces of natural selection to find optimal values of some function ( Mitchell, 1998 ). An initial set of candidate solutions are created and their corresponding fitness values are calculated (where larger values are better). This set of solutions is referred to as a population and each solution as an individual . The individuals with the best fitness values are combined randomly to produce offsprings which make up the next population. To do so, individual are selected and undergo cross-over (mimicking genetic reproduction) and also are subject to random mutations. This process is repeated again and again and many generations are produced (i.e.Â iterations of the search procedure) that should create better and better solutions. For feature selection, the individuals are subsets of predictors that are encoded as binary; a feature is either included or not in the subset. The fitness values are some measure of model performance, such as the RMSE or classification accuracy. One issue with using GAs for feature selection is that the optimization process can be very aggressive and their is potential for the GA to overfit to the predictors (much like the previous discussion for RFE). 