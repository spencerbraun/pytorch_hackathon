caret_18_feature_selection_overview
18 Feature Selection Overview
feature-selection-overview.html
 18.1 Models with Built-In Feature Selection Many models that can be accessed using caret ’s train function produce prediction equations that do not necessarily use all the predictors. These models are thought to have built-in feature selection: ada , AdaBag , AdaBoost.M1 , adaboost , bagEarth , bagEarthGCV , bagFDA , bagFDAGCV , bartMachine , blasso , BstLm , bstSm , C5.0 , C5.0Cost , C5.0Rules , C5.0Tree , cforest , chaid , ctree , ctree2 , cubist , deepboost , earth , enet , evtree , extraTrees , fda , gamboost , gbm_h2o , gbm , gcvEarth , glmnet_h2o , glmnet , glmStepAIC , J48 , JRip , lars , lars2 , lasso , LMT , LogitBoost , M5 , M5Rules , msaenet , nodeHarvest , OneR , ordinalNet , ordinalRF , ORFlog , ORFpls , ORFridge , ORFsvm , pam , parRF , PART , penalized , PenalizedLDA , qrf , ranger , Rborist , relaxo , rf , rFerns , rfRules , rotationForest , rotationForestCp , rpart , rpart1SE , rpart2 , rpartCost , rpartScore , rqlasso , rqnc , RRF , RRFglobal , sdwd , smda , sparseLDA , spikeslab , wsrf , xgbDART , xgbLinear , xgbTree . Many of the functions have an ancillary method called predictors that returns a vector indicating which predictors were used in the final model. In many cases, using these models with built-in feature selection will be more efficient than algorithms where the search routine for the right predictors is external to the model. Built-in feature selection typically couples the predictor search algorithm with the parameter estimation and are usually optimized with a single objective function (e.g. error rates or likelihood). 