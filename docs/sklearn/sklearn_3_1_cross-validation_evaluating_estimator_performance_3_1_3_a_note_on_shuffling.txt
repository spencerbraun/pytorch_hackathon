sklearn_3_1_cross-validation_evaluating_estimator_performance
3.1. Cross-validation: evaluating estimator performance
modules/cross_validation.html
 3.1.3. A note on shuffling  If the data ordering is not arbitrary (e.g. samples with the same class label are contiguous), shuffling it first may be essential to get a meaningful cross- validation result. However, the opposite may be true if the samples are not independently and identically distributed. For example, if samples correspond to news articles, and are ordered by their time of publication, then shuffling the data will likely lead to a model that is overfit and an inflated validation score: it will be tested on samples that are artificially similar (close in time) to training samples. Some cross validation iterators, such as KFold , have an inbuilt option to shuffle the data indices before splitting them. Note that: This consumes less memory than shuffling the data directly. By default no shuffling occurs, including for the (stratified) K fold cross- validation performed by specifying to cross_val_score , grid search, etc. Keep in mind that train_test_split still returns a random split. The parameter defaults to , meaning that the shuffling will be different every time is iterated. However, will use the same shuffling for each set of parameters validated by a single call to its method. To get identical results for each split, set to an integer. 