sklearn_1_16_probability_calibration
1.16. Probability calibration
modules/calibration.html
 1.16.3. Usage  The CalibratedClassifierCV class is used to calibrate a classifier. CalibratedClassifierCV uses a cross-validation approach to fit both the classifier and the regressor. For each of the k couple, a classifier is trained on the train set, and its predictions on the test set are used to fit a regressor. We end up with k couples where each regressor maps the output of its corresponding classifier into [0, 1]. Each couple is exposed in the attribute, where each entry is a calibrated classifier with a predict_proba method that outputs calibrated probabilities. The output of predict_proba for the main CalibratedClassifierCV instance corresponds to the average of the predicted probabilities of the estimators in the list. The output of predict is the class that has the highest probability. The regressor that is used for calibration depends on the parameter. corresponds to a parametric approach based on Platt’s logistic model 3 , i.e. is modeled as where is the logistic function, and and are real numbers to be determined when fitting the regressor via maximum likelihood. will instead fit a non-parametric isotonic regressor, which outputs a step-wise non-decreasing function (see sklearn.isotonic ). An already fitted classifier can be calibrated by setting . In this case, the data is only used to fit the regressor. It is up to the user make sure that the data used for fitting the classifier is disjoint from the data used for fitting the regressor. CalibratedClassifierCV can calibrate probabilities in a multiclass setting if the base estimator supports multiclass predictions. The classifier is calibrated first for each class separately in a one-vs-rest fashion 4 . When predicting probabilities, the calibrated probabilities for each class are predicted separately. As those probabilities do not necessarily sum to one, a postprocessing is performed to normalize them. The sklearn.metrics.brier_score_loss may be used to evaluate how well a classifier is calibrated. Examples: Probability Calibration curves Probability Calibration for 3-class classification Probability calibration of classifiers Comparison of Calibration of Classifiers References: 1 ( 1 , 2 ) Predicting Good Probabilities with Supervised Learning, A. Niculescu-Mizil & R. Caruana, ICML 2005 2 On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640–650., Wilks, D. S., 1990a 3 Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods, J. Platt, (1999) 4 Transforming Classifier Scores into Accurate Multiclass Probability Estimates, B. Zadrozny & C. Elkan, (KDD 2002) 