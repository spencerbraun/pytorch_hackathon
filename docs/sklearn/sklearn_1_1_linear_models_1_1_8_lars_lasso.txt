sklearn_1_1_linear_models
1.1. Linear Models
modules/linear_model.html
 1.1.8. LARS Lasso  LassoLars is a lasso model implemented using the LARS algorithm, and unlike the implementation based on coordinate descent, this yields the exact solution, which is piecewise linear as a function of the norm of its coefficients. Examples: Lasso path using LARS The Lars algorithm provides the full path of the coefficients along the regularization parameter almost for free, thus a common operation is to retrieve the path with one of the functions lars_path or lars_path_gram . 1.1.8.1. Mathematical formulation  The algorithm is similar to forward stepwise regression, but instead of including features at each step, the estimated coefficients are increased in a direction equiangular to each oneâ€™s correlations with the residual. Instead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the norm of the parameter vector. The full coefficients path is stored in the array , which has size (n_features, max_features+1). The first column is always zero. References: Original Algorithm is detailed in the paper Least Angle Regression by Hastie et al. 