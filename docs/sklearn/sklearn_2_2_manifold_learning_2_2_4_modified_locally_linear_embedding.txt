sklearn_2_2_manifold_learning
2.2. Manifold learning
modules/manifold.html
 2.2.4. Modified Locally Linear Embedding  One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter , which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as , the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for . This problem manifests itself in embeddings which distort the underlying geometry of the manifold. One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of modified locally linear embedding (MLLE). MLLE can be performed with function locally_linear_embedding or its object-oriented counterpart LocallyLinearEmbedding , with the keyword . It requires . 2.2.4.1. Complexity  The MLLE algorithm comprises three stages: Nearest Neighbors Search . Same as standard LLE Weight Matrix Construction . Approximately . The first term is exactly equivalent to that of standard LLE. The second term has to do with constructing the weight matrix from multiple weights. In practice, the added cost of constructing the MLLE weight matrix is relatively small compared to the cost of stages 1 and 3. Partial Eigenvalue Decomposition . Same as standard LLE The overall complexity of MLLE is . : number of training data points : input dimension : number of nearest neighbors : output dimension References: “MLLE: Modified Locally Linear Embedding Using Multiple Weights” Zhang, Z. & Wang, J. 