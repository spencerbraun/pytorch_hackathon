sklearn_2_3_clustering
2.3. Clustering
modules/clustering.html
 2.3.4. Mean Shift  MeanShift clustering aims to discover blobs in a smooth density of samples. It is a centroid based algorithm, which works by updating candidates for centroids to be the mean of the points within a given region. These candidates are then filtered in a post-processing stage to eliminate near-duplicates to form the final set of centroids. Given a candidate centroid for iteration , the candidate is updated according to the following equation: \[x_i^{t+1}  m(x_i^t)\] Where is the neighborhood of samples within a given distance around and is the mean shift vector that is computed for each centroid that points towards a region of the maximum increase in the density of points. This is computed using the following equation, effectively updating a centroid to be the mean of the samples within its neighborhood: \[m(x_i)  \frac{\sum_{x_j \in N(x_i)}K(x_j - x_i)x_j}{\sum_{x_j \in N(x_i)}K(x_j - x_i)}\] The algorithm automatically sets the number of clusters, instead of relying on a parameter , which dictates the size of the region to search through. This parameter can be set manually, but can be estimated using the provided function, which is called if the bandwidth is not set. The algorithm is not highly scalable, as it requires multiple nearest neighbor searches during the execution of the algorithm. The algorithm is guaranteed to converge, however the algorithm will stop iterating when the change in centroids is small. Labelling a new sample is performed by finding the nearest centroid for a given sample. Examples: A demo of the mean-shift clustering algorithm : Mean Shift clustering on a synthetic 2D datasets with 3 classes. References: “Mean shift: A robust approach toward feature space analysis.” D. Comaniciu and P. Meer, IEEE Transactions on Pattern Analysis and Machine Intelligence (2002) 