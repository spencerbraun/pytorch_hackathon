sklearn_3_1_cross-validation_evaluating_estimator_performance
3.1. Cross-validation: evaluating estimator performance
modules/cross_validation.html
 3.1.1. Computing cross-validated metrics  The simplest way to use cross-validation is to call the cross_val_score helper function on the estimator and the dataset. The following example demonstrates how to estimate the accuracy of a linear kernel support vector machine on the iris dataset by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time): The mean score and the 95% confidence interval of the score estimate are hence given by: By default, the score computed at each CV iteration is the method of the estimator. It is possible to change this by using the scoring parameter: See The scoring parameter: defining model evaluation rules for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal. When the argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin . It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance: Another option is to use an iterable yielding (train, test) splits as arrays of indices, for example: Data transformation with held out data Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar data transformations similarly should be learnt from a training set and applied to held-out data for prediction: A Pipeline makes it easier to compose estimators, providing this behavior under cross-validation: See Pipelines and composite estimators . 3.1.1.1. The cross_validate function and multiple metric evaluation  The cross_validate function differs from cross_val_score in two ways: It allows specifying multiple metrics for evaluation. It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score. For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be - And for multiple metric evaluation, the return value is a dict with the following keys - is set to by default to save computation time. To evaluate the scores on the training set as well you need to be set to . You may also retain the estimator fitted on each training set by setting . The multiple metrics can be specified either as a list, tuple or set of predefined scorer names: Or as a dict mapping scorer name to a predefined or custom scoring function: Here is an example of using a single metric: 3.1.1.2. Obtaining predictions by cross-validation  The function cross_val_predict has a similar interface to cross_val_score , but returns, for each element in the input, the prediction that was obtained for that element when it was in the test set. Only cross-validation strategies that assign all elements to a test set exactly once can be used (otherwise, an exception is raised). Warning Note on inappropriate usage of cross_val_predict The result of cross_val_predict may be different from those obtained using cross_val_score as the elements are grouped in different ways. The function cross_val_score takes an average over cross-validation folds, whereas cross_val_predict simply returns the labels (or probabilities) from several distinct models undistinguished. Thus, cross_val_predict is not an appropriate measure of generalisation error. The function cross_val_predict is appropriate for: Visualization of predictions obtained from different models. Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods. The available cross validation iterators are introduced in the following section. Examples Receiver Operating Characteristic (ROC) with cross validation , Recursive feature elimination with cross-validation , Parameter estimation using grid search with cross-validation , Sample pipeline for text feature extraction and evaluation , Plotting Cross-Validated Predictions , Nested versus non-nested cross-validation . 