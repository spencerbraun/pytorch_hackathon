sklearn_2_2_manifold_learning
2.2. Manifold learning
modules/manifold.html
 2.2.5. Hessian Eigenmapping  Hessian Eigenmapping (also known as Hessian-based LLE: HLLE) is another method of solving the regularization problem of LLE. It revolves around a hessian-based quadratic form at each neighborhood which is used to recover the locally linear structure. Though other implementations note its poor scaling with data size, implements some algorithmic improvements which make its cost comparable to that of other LLE variants for small output dimension. HLLE can be performed with function locally_linear_embedding or its object-oriented counterpart LocallyLinearEmbedding , with the keyword . It requires . 2.2.5.1. Complexity  The HLLE algorithm comprises three stages: Nearest Neighbors Search . Same as standard LLE Weight Matrix Construction . Approximately . The first term reflects a similar cost to that of standard LLE. The second term comes from a QR decomposition of the local hessian estimator. Partial Eigenvalue Decomposition . Same as standard LLE The overall complexity of standard HLLE is . : number of training data points : input dimension : number of nearest neighbors : output dimension References: “Hessian Eigenmaps: Locally linear embedding techniques for high-dimensional data” Donoho, D. & Grimes, C. Proc Natl Acad Sci USA. 100:5591 (2003) 