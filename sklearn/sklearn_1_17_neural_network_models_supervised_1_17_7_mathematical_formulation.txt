sklearn_1_17_neural_network_models_supervised
1.17. Neural network models (supervised)
modules/neural_networks_supervised.html
 1.17.7. Mathematical formulation  Given a set of training examples where and , a one hidden layer one hidden neuron MLP learns the function where and are model parameters. represent the weights of the input layer and hidden layer, respectively; and represent the bias added to the hidden layer and the output layer, respectively. is the activation function, set by default as the hyperbolic tan. It is given as, \[g(z) \frac{e^z-e^{-z}}{e^z+e^{-z}}\] For binary classification, passes through the logistic function to obtain output values between zero and one. A threshold, set to 0.5, would assign samples of outputs larger or equal 0.5 to the positive class, and the rest to the negative class. If there are more than two classes, itself would be a vector of size (n_classes,). Instead of passing through logistic function, it passes through the softmax function, which is written as, \[\text{softmax}(z)_i  \frac{\exp(z_i)}{\sum_{l1}^k\exp(z_l)}\] where represents the th element of the input to softmax, which corresponds to class , and is the number of classes. The result is a vector containing the probabilities that sample belong to each class. The output is the class with the highest probability. In regression, the output remains as ; therefore, output activation function is just the identity function. MLP uses different loss functions depending on the problem type. The loss function for classification is Cross-Entropy, which in binary case is given as, \[Loss(\hat{y},y,W)  -y \ln {\hat{y}} - (1-y) \ln{(1-\hat{y})} + \alpha ||W||_2^2\] where is an L2-regularization term (aka penalty) that penalizes complex models; and is a non-negative hyperparameter that controls the magnitude of the penalty. For regression, MLP uses the Square Error loss function; written as, \[Loss(\hat{y},y,W)  \frac{1}{2}||\hat{y} - y ||_2^2 + \frac{\alpha}{2} ||W||_2^2\] Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss. In gradient descent, the gradient of the loss with respect to the weights is computed and deducted from . More formally, this is expressed as, \[W^{i+1}  W^i - \epsilon \nabla {Loss}_{W}^{i}\] where is the iteration step, and is the learning rate with a value larger than 0. The algorithm stops when it reaches a preset maximum number of iterations; or when the improvement in loss is below a certain, small number. 