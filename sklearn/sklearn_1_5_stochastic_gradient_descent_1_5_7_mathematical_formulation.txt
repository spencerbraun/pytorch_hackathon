sklearn_1_5_stochastic_gradient_descent
1.5. Stochastic Gradient Descent
modules/sgd.html
 1.5.7. Mathematical formulation  We describe here the mathematical details of the SGD procedure. A good overview with convergence rates can be found in 12 . Given a set of training examples where and ( for classification), our goal is to learn a linear scoring function with model parameters and intercept . In order to make predictions for binary classification, we simply look at the sign of . To find the model parameters, we minimize the regularized training error given by \[E(w,b)  \frac{1}{n}\sum_{i1}^{n} L(y_i, f(x_i)) + \alpha R(w)\] where is a loss function that measures model (mis)fit and is a regularization term (aka penalty) that penalizes model complexity; is a non-negative hyperparameter that controls the regularization stength. Different choices for entail different classifiers or regressors: Hinge (soft-margin): equivalent to Support Vector Classification. . Perceptron: . Modified Huber: if , and otherwise. Log: equivalent to Logistic Regression. . Least-Squares: Linear regression (Ridge or Lasso depending on ). . Huber: less sensitive to outliers than least-squares. It is equivalent to least squares when , and otherwise. Epsilon-Insensitive: (soft-margin) equivalent to Support Vector Regression. . All of the above loss functions can be regarded as an upper bound on the misclassification error (Zero-one loss) as shown in the Figure below. Popular choices for the regularization term (the parameter) include: L2 norm: , L1 norm: , which leads to sparse solutions. Elastic Net: , a convex combination of L2 and L1, where is given by . The Figure below shows the contours of the different regularization terms in a 2-dimensional parameter space ( ) when . 1.5.7.1. SGD  Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of by considering a single training example at a time. The class SGDClassifier implements a first-order SGD learning routine. The algorithm iterates over the training examples and for each example updates the model parameters according to the update rule given by \[w \leftarrow w - \eta \left[\alpha \frac{\partial R(w)}{\partial w} + \frac{\partial L(w^T x_i + b, y_i)}{\partial w}\right]\] where is the learning rate which controls the step-size in the parameter space. The intercept is updated similarly but without regularization (and with additional decay for sparse matrices, as detailed in Implementation details ). The learning rate can be either constant or gradually decaying. For classification, the default learning rate schedule ( ) is given by \[\eta^{(t)}  \frac {1}{\alpha (t_0 + t)}\] where is the time step (there are a total of time steps), is determined based on a heuristic proposed by LÃ©on Bottou such that the expected initial updates are comparable with the expected size of the weights (this assuming that the norm of the training samples is approx. 1). The exact definition can be found in in BaseSGD . For regression the default learning rate schedule is inverse scaling ( ), given by \[\eta^{(t)}  \frac{eta_0}{t^{power\_t}}\] where and are hyperparameters chosen by the user via and , resp. For a constant learning rate use and use to specify the learning rate. For an adaptively decreasing learning rate, use and use to specify the starting learning rate. When the stopping criterion is reached, the learning rate is divided by 5, and the algorithm does not stop. The algorithm stops when the learning rate goes below 1e-6. The model parameters can be accessed through the and attributes: holds the weights and holds . When using Averaged SGD (with the parameter), is set to the average weight across all updates: , where is the total number of updates, found in the attribute. 