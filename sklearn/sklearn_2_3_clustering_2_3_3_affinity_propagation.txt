sklearn_2_3_clustering
2.3. Clustering
modules/clustering.html
 2.3.3. Affinity Propagation  AffinityPropagation creates clusters by sending messages between pairs of samples until convergence. A dataset is then described using a small number of exemplars, which are identified as those most representative of other samples. The messages sent between pairs represent the suitability for one sample to be the exemplar of the other, which is updated in response to the values from other pairs. This updating happens iteratively until convergence, at which point the final exemplars are chosen, and hence the final clustering is given. Affinity Propagation can be interesting as it chooses the number of clusters based on the data provided. For this purpose, the two important parameters are the preference , which controls how many exemplars are used, and the damping factor which damps the responsibility and availability messages to avoid numerical oscillations when updating these messages. The main drawback of Affinity Propagation is its complexity. The algorithm has a time complexity of the order , where is the number of samples and is the number of iterations until convergence. Further, the memory complexity is of the order if a dense similarity matrix is used, but reducible if a sparse similarity matrix is used. This makes Affinity Propagation most appropriate for small to medium sized datasets. Examples: Demo of affinity propagation clustering algorithm : Affinity Propagation on a synthetic 2D datasets with 3 classes. Visualizing the stock market structure Affinity Propagation on Financial time series to find groups of companies Algorithm description: The messages sent between points belong to one of two categories. The first is the responsibility , which is the accumulated evidence that sample should be the exemplar for sample . The second is the availability which is the accumulated evidence that sample should choose sample to be its exemplar, and considers the values for all other samples that should be an exemplar. In this way, exemplars are chosen by samples if they are (1) similar enough to many samples and (2) chosen by many samples to be representative of themselves. More formally, the responsibility of a sample to be the exemplar of sample is given by: \[r(i, k) \leftarrow s(i, k) - max [ a(i, k') + s(i, k') \forall k' \neq k ]\] Where is the similarity between samples and . The availability of sample to be the exemplar of sample is given by: \[a(i, k) \leftarrow min [0, r(k, k) + \sum_{i'~s.t.~i' \notin \{i, k\}}{r(i', k)}]\] To begin with, all values for and are set to zero, and the calculation of each iterates until convergence. As discussed above, in order to avoid numerical oscillations when updating the messages, the damping factor is introduced to iteration process: \[r_{t+1}(i, k)  \lambda\cdot r_{t}(i, k) + (1-\lambda)\cdot r_{t+1}(i, k)\] \[a_{t+1}(i, k)  \lambda\cdot a_{t}(i, k) + (1-\lambda)\cdot a_{t+1}(i, k)\] where indicates the iteration times. 