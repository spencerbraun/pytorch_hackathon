sklearn_1_10_decision_trees
1.10. Decision Trees
modules/tree.html
 1.10.1. Classification  DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset. As with other classifiers, DecisionTreeClassifier takes as input two arrays: an array X, sparse or dense, of size holding the training samples, and an array Y of integer values, size , holding the class labels for the training samples: After being fitted, the model can then be used to predict the class of samples: Alternatively, the probability of each class can be predicted, which is the fraction of training samples of the same class in a leaf: DecisionTreeClassifier is capable of both binary (where the labels are [-1, 1]) classification and multiclass (where the labels are [0, …, K-1]) classification. Using the Iris dataset, we can construct a tree as follows: Once trained, you can plot the tree with the plot_tree function: We can also export the tree in Graphviz format using the export_graphviz exporter. If you use the conda package manager, the graphviz binaries and the python package can be installed with . Alternatively binaries for graphviz can be downloaded from the graphviz project homepage, and the Python wrapper installed from pypi with . Below is an example graphviz export of the above tree trained on the entire iris dataset; the results are saved in an output file : The export_graphviz exporter also supports a variety of aesthetic options, including coloring nodes by their class (or value for regression) and using explicit variable and class names if desired. Jupyter notebooks also render these plots inline automatically: Alternatively, the tree can also be exported in textual format with the function export_text . This method doesn’t require the installation of external libraries and is more compact: Examples: Plot the decision surface of a decision tree on the iris dataset Understanding the decision tree structure 