sklearn_1_13_feature_selection
1.13. Feature selection
modules/feature_selection.html
 1.13.3. Recursive feature elimination  Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination ( RFE ) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a attribute or through a attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached. RFECV performs RFE in a cross-validation loop to find the optimal number of features. Examples: Recursive feature elimination : A recursive feature elimination example showing the relevance of pixels in a digit classification task. Recursive feature elimination with cross-validation : A recursive feature elimination example with automatic tuning of the number of features selected with cross-validation. 