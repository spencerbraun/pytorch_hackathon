sklearn_3_2_tuning_the_hyper-parameters_of_an_estimator
3.2. Tuning the hyper-parameters of an estimator
modules/grid_search.html
 3.2.1. Exhaustive Grid Search  The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the parameter. For instance, the following : specifies that two grids should be explored: one with a linear kernel and C values in [1, 10, 100, 1000], and the second one with an RBF kernel, and the cross-product of C values ranging in [1, 10, 100, 1000] and gamma values in [0.001, 0.0001]. The GridSearchCV instance implements the usual estimator API: when “fitting” it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained. Examples: See Parameter estimation using grid search with cross-validation for an example of Grid Search computation on the digits dataset. See Sample pipeline for text feature extraction and evaluation for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a pipeline.Pipeline instance. See Nested versus non-nested cross-validation for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search. See Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV for an example of GridSearchCV being used to evaluate multiple metrics simultaneously. See Balance model complexity and cross-validated score for an example of using interface in GridSearchCV . The example shows how this interface adds certain amount of flexibility in identifying the “best” estimator. This interface can also be used in multiple metrics evaluation. 