sklearn_1_4_support_vector_machines
1.4. Support Vector Machines
modules/svm.html
 1.4.2. Regression  The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression. The model produced by support vector classification (as described above) depends only on a subset of the training data, because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by Support Vector Regression depends only on a subset of the training data, because the cost function ignores samples whose prediction is close to their target. There are three different implementations of Support Vector Regression: SVR , NuSVR and LinearSVR . LinearSVR provides a faster implementation than SVR but only considers the linear kernel, while NuSVR implements a slightly different formulation than SVR and LinearSVR . See Implementation details for further details. As with classification classes, the fit method will take as argument vectors X, y, only that in this case y is expected to have floating point values instead of integer values: Examples: Support Vector Regression (SVR) using linear and non-linear kernels 