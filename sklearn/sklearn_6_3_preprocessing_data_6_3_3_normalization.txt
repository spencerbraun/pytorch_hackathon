sklearn_6_3_preprocessing_data
6.3. Preprocessing data
modules/preprocessing.html
 6.3.3. Normalization  Normalization is the process of scaling individual samples to have unit norm . This process can be useful if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples. This assumption is the base of the Vector Space Model often used in text classification and clustering contexts. The function normalize provides a quick and easy way to perform this operation on a single array-like dataset, either using the or norms: The module further provides a utility class Normalizer that implements the same operation using the API (even though the method is useless in this case: the class is stateless as this operation treats samples independently). This class is hence suitable for use in the early steps of a sklearn.pipeline.Pipeline : The normalizer instance can then be used on sample vectors as any transformer: Note: L2 normalization is also known as spatial sign preprocessing. Sparse input normalize and Normalizer accept both dense array-like and sparse matrices from scipy.sparse as input . For sparse input the data is converted to the Compressed Sparse Rows representation (see ) before being fed to efficient Cython routines. To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream. 