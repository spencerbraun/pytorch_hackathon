scipy_linear_algebra_scipy_linalg
Linear Algebra (scipy.linalg)
linalg.html
 Decompositions  In many applications, it is useful to decompose a matrix using other representations. There are several decompositions supported by SciPy. Eigenvalues and eigenvectors  The eigenvalue-eigenvector problem is one of the most commonly employed linear algebra operations. In one popular form, the eigenvalue-eigenvector problem is to find for some square matrix scalars and corresponding vectors , such that \[\mathbf{Av}\lambda\mathbf{v}.\] For an matrix, there are (not necessarily distinct) eigenvalues — roots of the (characteristic) polynomial \[\left|\mathbf{A}-\lambda\mathbf{I}\right|0.\] The eigenvectors, , are also sometimes called right eigenvectors to distinguish them from another set of left eigenvectors that satisfy \[\mathbf{v}_{L}^{H}\mathbf{A}\lambda\mathbf{v}_{L}^{H}\] or \[\mathbf{A}^{H}\mathbf{v}_{L}\lambda^{*}\mathbf{v}_{L}.\] With its default optional arguments, the command linalg.eig returns and However, it can also return and just by itself ( linalg.eigvals returns just as well). In addition, linalg.eig can also solve the more general eigenvalue problem \begin{eqnarray*} \mathbf{Av} &  & \lambda\mathbf{Bv}\\ \mathbf{A}^{H}\mathbf{v}_{L} &  & \lambda^{*}\mathbf{B}^{H}\mathbf{v}_{L}\end{eqnarray*} for square matrices and The standard eigenvalue problem is an example of the general eigenvalue problem for When a generalized eigenvalue problem can be solved, it provides a decomposition of as \[\mathbf{A}\mathbf{BV}\boldsymbol{\Lambda}\mathbf{V}^{-1},\] where is the collection of eigenvectors into columns and is a diagonal matrix of eigenvalues. By definition, eigenvectors are only defined up to a constant scale factor. In SciPy, the scaling factor for the eigenvectors is chosen so that As an example, consider finding the eigenvalues and eigenvectors of the matrix \[\begin{split}\mathbf{A}\left[\begin{array}{ccc} 1 & 5 & 2\\ 2 & 4 & 1\\ 3 & 6 & 2\end{array}\right].\end{split}\] The characteristic polynomial is \begin{eqnarray*} \left|\mathbf{A}-\lambda\mathbf{I}\right| &  & \left(1-\lambda\right)\left[\left(4-\lambda\right)\left(2-\lambda\right)-6\right]-\\ & & 5\left[2\left(2-\lambda\right)-3\right]+2\left[12-3\left(4-\lambda\right)\right]\\ &  & -\lambda^{3}+7\lambda^{2}+8\lambda-3.\end{eqnarray*} The roots of this polynomial are the eigenvalues of : \begin{eqnarray*} \lambda_{1} &  & 7.9579\\ \lambda_{2} &  & -1.2577\\ \lambda_{3} &  & 0.2997.\end{eqnarray*} The eigenvectors corresponding to each eigenvalue can be found using the original equation. The eigenvectors associated with these eigenvalues can then be found. Singular value decomposition  Singular value decomposition (SVD) can be thought of as an extension of the eigenvalue problem to matrices that are not square. Let be an matrix with and arbitrary. The matrices and are square hermitian matrices 1 of size and , respectively. It is known that the eigenvalues of square hermitian matrices are real and non-negative. In addition, there are at most identical non-zero eigenvalues of and Define these positive eigenvalues as The square-root of these are called singular values of The eigenvectors of are collected by columns into an unitary 2 matrix , while the eigenvectors of are collected by columns in the unitary matrix , the singular values are collected in an zero matrix with main diagonal entries set to the singular values. Then \[\mathbf{AU}\boldsymbol{\Sigma}\mathbf{V}^{H}\] is the singular value decomposition of Every matrix has a singular value decomposition. Sometimes, the singular values are called the spectrum of The command linalg.svd will return , , and as an array of the singular values. To obtain the matrix , use linalg.diagsvd . The following example illustrates the use of linalg.svd : 1 A hermitian matrix satisfies 2 A unitary matrix satisfies so that LU decomposition  The LU decomposition finds a representation for the matrix as \[\mathbf{A}\mathbf{P}\,\mathbf{L}\,\mathbf{U},\] where is an permutation matrix (a permutation of the rows of the identity matrix), is in lower triangular or trapezoidal matrix ( ) with unit-diagonal, and is an upper triangular or trapezoidal matrix. The SciPy command for this decomposition is linalg.lu . Such a decomposition is often useful for solving many simultaneous equations where the left-hand side does not change but the right-hand side does. For example, suppose we are going to solve \[\mathbf{A}\mathbf{x}_{i}\mathbf{b}_{i}\] for many different . The LU decomposition allows this to be written as \[\mathbf{PLUx}_{i}\mathbf{b}_{i}.\] Because is lower-triangular, the equation can be solved for and, finally, very rapidly using forward- and back-substitution. An initial time spent factoring allows for very rapid solution of similar systems of equations in the future. If the intent for performing LU decomposition is for solving linear systems, then the command linalg.lu_factor should be used followed by repeated applications of the command linalg.lu_solve to solve the system for each new right-hand side. Cholesky decomposition  Cholesky decomposition is a special case of LU decomposition applicable to Hermitian positive definite matrices. When and for all , then decompositions of can be found so that \begin{eqnarray*} \mathbf{A} &  & \mathbf{U}^{H}\mathbf{U}\\ \mathbf{A} &  & \mathbf{L}\mathbf{L}^{H}\end{eqnarray*}, where is lower triangular and is upper triangular. Notice that The command linalg.cholesky computes the Cholesky factorization. For using the Cholesky factorization to solve systems of equations, there are also linalg.cho_factor and linalg.cho_solve routines that work similarly to their LU decomposition counterparts. QR decomposition  The QR decomposition (sometimes called a polar decomposition) works for any array and finds an unitary matrix and an upper-trapezoidal matrix , such that \[\mathbf{AQR}.\] Notice that if the SVD of is known, then the QR decomposition can be found. \[\mathbf{A}\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^{H}\mathbf{QR}\] implies that and Note, however, that in SciPy independent algorithms are used to find QR and SVD decompositions. The command for QR decomposition is linalg.qr . Schur decomposition  For a square matrix, , the Schur decomposition finds (not necessarily unique) matrices and , such that \[\mathbf{A}\mathbf{ZT}\mathbf{Z}^{H},\] where is a unitary matrix and is either upper triangular or quasi upper triangular, depending on whether or not a real Schur form or complex Schur form is requested. For a real Schur form both and are real-valued when is real-valued. When is a real-valued matrix, the real Schur form is only quasi upper triangular because blocks extrude from the main diagonal corresponding to any complex-valued eigenvalues. The command linalg.schur finds the Schur decomposition, while the command linalg.rsf2csf converts and from a real Schur form to a complex Schur form. The Schur form is especially useful in calculating functions of matrices. The following example illustrates the Schur decomposition: Interpolative decomposition  scipy.linalg.interpolative contains routines for computing the interpolative decomposition (ID) of a matrix. For a matrix of rank this is a factorization \[A \Pi  \begin{bmatrix} A \Pi_{1} & A \Pi_{2} \end{bmatrix}  A \Pi_{1} \begin{bmatrix} I & T \end{bmatrix},\] where is a permutation matrix with , i.e., . This can equivalently be written as , where and are the skeleton and interpolation matrices , respectively. See also scipy.linalg.interpolative — for more information. 