{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import signal\n",
    "from math import ceil\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from numpy.random import choice\n",
    "from torchtext.data import Field, TabularDataset\n",
    "\n",
    "# from paragraphvec.utils import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(file_name):\n",
    "    \"\"\"Loads contents from a file in the *data* directory into a\n",
    "    torchtext.data.TabularDataset instance.\n",
    "    \"\"\"\n",
    "    file_path = join(DATA_DIR, file_name)\n",
    "    text_field = Field(pad_token=None, tokenize=_tokenize_str)\n",
    "\n",
    "    dataset = TabularDataset(\n",
    "        path=file_path,\n",
    "        format='csv',\n",
    "        fields=[('text', text_field)],\n",
    "        skip_header=True)\n",
    "\n",
    "    text_field.build_vocab(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def _tokenize_str(str_):\n",
    "    # keep only alphanumeric and punctations\n",
    "    str_ = re.sub(r'[^A-Za-z0-9(),.!?\\'`]', ' ', str_)\n",
    "    # remove multiple whitespace characters\n",
    "    str_ = re.sub(r'\\s{2,}', ' ', str_)\n",
    "    # punctations to tokens\n",
    "    str_ = re.sub(r'\\(', ' ( ', str_)\n",
    "    str_ = re.sub(r'\\)', ' ) ', str_)\n",
    "    str_ = re.sub(r',', ' , ', str_)\n",
    "    str_ = re.sub(r'\\.', ' . ', str_)\n",
    "    str_ = re.sub(r'!', ' ! ', str_)\n",
    "    str_ = re.sub(r'\\?', ' ? ', str_)\n",
    "    # split contractions into multiple tokens\n",
    "    str_ = re.sub(r'\\'s', ' \\'s', str_)\n",
    "    str_ = re.sub(r'\\'ve', ' \\'ve', str_)\n",
    "    str_ = re.sub(r'n\\'t', ' n\\'t', str_)\n",
    "    str_ = re.sub(r'\\'re', ' \\'re', str_)\n",
    "    str_ = re.sub(r'\\'d', ' \\'d', str_)\n",
    "    str_ = re.sub(r'\\'ll', ' \\'ll', str_)\n",
    "    # lower case\n",
    "    return str_.strip().lower().split()\n",
    "\n",
    "\n",
    "class NCEData(object):\n",
    "    \"\"\"An infinite, parallel (multiprocess) batch generator for\n",
    "    noise-contrastive estimation of word vector models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: torchtext.data.TabularDataset\n",
    "        Dataset from which examples are generated. A column labeled *text*\n",
    "        is expected and should be comprised of a list of tokens. Each row\n",
    "        should represent a single document.\n",
    "\n",
    "    batch_size: int\n",
    "        Number of examples per single gradient update.\n",
    "\n",
    "    context_size: int\n",
    "        Half the size of a neighbourhood of target words (i.e. how many\n",
    "        words left and right are regarded as context).\n",
    "\n",
    "    num_noise_words: int\n",
    "        Number of noise words to sample from the noise distribution.\n",
    "\n",
    "    max_size: int\n",
    "        Maximum number of pre-generated batches.\n",
    "\n",
    "    num_workers: int\n",
    "        Number of jobs to run in parallel. If value is set to -1, total number\n",
    "        of machine CPUs is used.\n",
    "    \"\"\"\n",
    "    # code inspired by parallel generators in https://github.com/fchollet/keras\n",
    "    def __init__(self, dataset, batch_size, context_size,\n",
    "                 num_noise_words, max_size, num_workers):\n",
    "        self.max_size = max_size\n",
    "\n",
    "        self.num_workers = num_workers if num_workers != -1 else os.cpu_count()\n",
    "        if self.num_workers is None:\n",
    "            self.num_workers = 1\n",
    "\n",
    "        self._generator = _NCEGenerator(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            context_size,\n",
    "            num_noise_words,\n",
    "            _NCEGeneratorState(context_size))\n",
    "\n",
    "        self._queue = []\n",
    "        self._stop_event = None\n",
    "        self._processes = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._generator)\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return self._generator.vocabulary_size()\n",
    "\n",
    "\n",
    "\n",
    "class _NCEGenerator(object):\n",
    "    \"\"\"An infinite, process-safe batch generator for noise-contrastive\n",
    "    estimation of word vector models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: paragraphvec.data._NCEGeneratorState\n",
    "        Initial (indexing) state of the generator.\n",
    "\n",
    "    For other parameters see the NCEData class.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, context_size,\n",
    "                 num_noise_words, state):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.context_size = context_size\n",
    "        self.num_noise_words = num_noise_words\n",
    "\n",
    "        self._vocabulary = self.dataset.fields['text'].vocab\n",
    "        self._sample_noise = None\n",
    "        self._init_noise_distribution()\n",
    "        self._state = state\n",
    "\n",
    "    def _init_noise_distribution(self):\n",
    "        # we use a unigram distribution raised to the 3/4rd power,\n",
    "        # as proposed by T. Mikolov et al. in Distributed Representations\n",
    "        # of Words and Phrases and their Compositionality\n",
    "        probs = np.zeros(len(self._vocabulary) - 1)\n",
    "\n",
    "        for word, freq in self._vocabulary.freqs.items():\n",
    "            probs[self._word_to_index(word)] = freq\n",
    "\n",
    "        probs = np.power(probs, 0.75)\n",
    "        probs /= np.sum(probs)\n",
    "\n",
    "        self._sample_noise = lambda: choice(\n",
    "            probs.shape[0], self.num_noise_words, p=probs).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        num_examples = sum(self._num_examples_in_doc(d) for d in self.dataset)\n",
    "        return ceil(num_examples / self.batch_size)\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return len(self._vocabulary) - 1\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Updates state for the next process in a process-safe manner\n",
    "        and generates the current batch.\"\"\"\n",
    "        prev_doc_id, prev_in_doc_pos = self._state.update_state(\n",
    "            self.dataset,\n",
    "            self.batch_size,\n",
    "            self.context_size,\n",
    "            self._num_examples_in_doc)\n",
    "\n",
    "        # generate the actual batch\n",
    "        batch = _NCEBatch(self.context_size)\n",
    "\n",
    "        while len(batch) < self.batch_size:\n",
    "            if prev_doc_id == len(self.dataset):\n",
    "                # last document exhausted\n",
    "                batch.torch_()\n",
    "                return batch\n",
    "            if prev_in_doc_pos <= (len(self.dataset[prev_doc_id].text) - 1\n",
    "                                   - self.context_size):\n",
    "                # more examples in the current document\n",
    "                self._add_example_to_batch(prev_doc_id, prev_in_doc_pos, batch)\n",
    "                prev_in_doc_pos += 1\n",
    "            else:\n",
    "                # go to the next document\n",
    "                prev_doc_id += 1\n",
    "                prev_in_doc_pos = self.context_size\n",
    "\n",
    "        batch.torch_()\n",
    "        return batch\n",
    "\n",
    "    def _num_examples_in_doc(self, doc, in_doc_pos=None):\n",
    "        if in_doc_pos is not None:\n",
    "            # number of remaining\n",
    "            if len(doc.text) - in_doc_pos >= self.context_size + 1:\n",
    "                return len(doc.text) - in_doc_pos - self.context_size\n",
    "            return 0\n",
    "\n",
    "        if len(doc.text) >= 2 * self.context_size + 1:\n",
    "            # total number\n",
    "            return len(doc.text) - 2 * self.context_size\n",
    "        return 0\n",
    "\n",
    "    def _add_example_to_batch(self, doc_id, in_doc_pos, batch):\n",
    "        doc = self.dataset[doc_id].text\n",
    "        batch.doc_ids.append(doc_id)\n",
    "\n",
    "        # sample from the noise distribution\n",
    "        current_noise = self._sample_noise()\n",
    "        current_noise.insert(0, self._word_to_index(doc[in_doc_pos]))\n",
    "        batch.target_noise_ids.append(current_noise)\n",
    "\n",
    "        if self.context_size == 0:\n",
    "            return\n",
    "\n",
    "        current_context = []\n",
    "        context_indices = (in_doc_pos + diff for diff in\n",
    "                           range(-self.context_size, self.context_size + 1)\n",
    "                           if diff != 0)\n",
    "\n",
    "        for i in context_indices:\n",
    "            context_id = self._word_to_index(doc[i])\n",
    "            current_context.append(context_id)\n",
    "        batch.context_ids.append(current_context)\n",
    "\n",
    "    def _word_to_index(self, word):\n",
    "        return self._vocabulary.stoi[word] - 1\n",
    "\n",
    "\n",
    "class _NCEGeneratorState(object):\n",
    "    \"\"\"Batch generator state that is represented with a document id and\n",
    "    in-document position. It abstracts a process-safe indexing mechanism.\"\"\"\n",
    "    def __init__(self, context_size):\n",
    "        # use raw values because both indices have\n",
    "        # to manually be locked together\n",
    "        self._doc_id = multiprocessing.RawValue('i', 0)\n",
    "        self._in_doc_pos = multiprocessing.RawValue('i', context_size)\n",
    "        self._lock = multiprocessing.Lock()\n",
    "\n",
    "    def update_state(self, dataset, batch_size,\n",
    "                     context_size, num_examples_in_doc):\n",
    "        \"\"\"Returns current indices and computes new indices for the\n",
    "        next process.\"\"\"\n",
    "        with self._lock:\n",
    "            doc_id = self._doc_id.value\n",
    "            in_doc_pos = self._in_doc_pos.value\n",
    "            self._advance_indices(\n",
    "                dataset, batch_size, context_size, num_examples_in_doc)\n",
    "            return doc_id, in_doc_pos\n",
    "\n",
    "    def _advance_indices(self, dataset, batch_size,\n",
    "                         context_size, num_examples_in_doc):\n",
    "        num_examples = num_examples_in_doc(\n",
    "            dataset[self._doc_id.value], self._in_doc_pos.value)\n",
    "\n",
    "        if num_examples > batch_size:\n",
    "            # more examples in the current document\n",
    "            self._in_doc_pos.value += batch_size\n",
    "            return\n",
    "\n",
    "        if num_examples == batch_size:\n",
    "            # just enough examples in the current document\n",
    "            if self._doc_id.value < len(dataset) - 1:\n",
    "                self._doc_id.value += 1\n",
    "            else:\n",
    "                self._doc_id.value = 0\n",
    "            self._in_doc_pos.value = context_size\n",
    "            return\n",
    "\n",
    "        while num_examples < batch_size:\n",
    "            if self._doc_id.value == len(dataset) - 1:\n",
    "                # last document: reset indices\n",
    "                self._doc_id.value = 0\n",
    "                self._in_doc_pos.value = context_size\n",
    "                return\n",
    "\n",
    "            self._doc_id.value += 1\n",
    "            num_examples += num_examples_in_doc(\n",
    "                dataset[self._doc_id.value])\n",
    "\n",
    "        self._in_doc_pos.value = (len(dataset[self._doc_id.value].text)\n",
    "                                  - context_size\n",
    "                                  - (num_examples - batch_size))\n",
    "\n",
    "\n",
    "class _NCEBatch(object):\n",
    "    def __init__(self, context_size):\n",
    "        self.context_ids = [] if context_size > 0 else None\n",
    "        self.doc_ids = []\n",
    "        self.target_noise_ids = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.doc_ids)\n",
    "\n",
    "    def torch_(self):\n",
    "        if self.context_ids is not None:\n",
    "            self.context_ids = torch.LongTensor(self.context_ids)\n",
    "        self.doc_ids = torch.LongTensor(self.doc_ids)\n",
    "        self.target_noise_ids = torch.LongTensor(self.target_noise_ids)\n",
    "\n",
    "    def cuda_(self):\n",
    "        if self.context_ids is not None:\n",
    "            self.context_ids = self.context_ids.cuda()\n",
    "        self.doc_ids = self.doc_ids.cuda()\n",
    "        self.target_noise_ids = self.target_noise_ids.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NegativeSampling(nn.Module):\n",
    "    \"\"\"Negative sampling loss as proposed by T. Mikolov et al. in Distributed\n",
    "    Representations of Words and Phrases and their Compositionality.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(NegativeSampling, self).__init__()\n",
    "        self._log_sigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, scores):\n",
    "        \"\"\"Computes the value of the loss function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        scores: autograd.Variable of size (batch_size, num_noise_words + 1)\n",
    "            Sparse unnormalized log probabilities. The first element in each\n",
    "            row is the ground truth score (i.e. the target), other elements\n",
    "            are scores of samples from the noise distribution.\n",
    "        \"\"\"\n",
    "        k = scores.size()[1] - 1\n",
    "        return -torch.sum(\n",
    "            self._log_sigmoid(scores[:, 0])\n",
    "            + torch.sum(self._log_sigmoid(-scores[:, 1:]), dim=1) / k\n",
    "        ) / scores.size()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DBOW(nn.Module):\n",
    "    \"\"\"Distributed Bag of Words version of Paragraph Vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec_dim: int\n",
    "        Dimensionality of vectors to be learned (for paragraphs and words).\n",
    "    num_docs: int\n",
    "        Number of documents in a dataset.\n",
    "    num_words: int\n",
    "        Number of distinct words in a daset (i.e. vocabulary size).\n",
    "    \"\"\"\n",
    "    def __init__(self, vec_dim, num_docs, num_words):\n",
    "        super(DBOW, self).__init__()\n",
    "        # paragraph matrix\n",
    "        self._D = nn.Parameter(\n",
    "            torch.randn(num_docs, vec_dim), requires_grad=True)\n",
    "        # output layer parameters\n",
    "        self._O = nn.Parameter(\n",
    "            torch.FloatTensor(vec_dim, num_words).zero_(), requires_grad=True)\n",
    "\n",
    "    def forward(self, doc_ids, target_noise_ids):\n",
    "        \"\"\"Sparse computation of scores (unnormalized log probabilities)\n",
    "        that should be passed to the negative sampling loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc_ids: torch.Tensor of size (batch_size,)\n",
    "            Document indices of paragraphs.\n",
    "        target_noise_ids: torch.Tensor of size (batch_size, num_noise_words + 1)\n",
    "            Vocabulary indices of target and noise words. The first element in\n",
    "            each row is the ground truth index (i.e. the target), other\n",
    "            elements are indices of samples from the noise distribution.\n",
    "        Returns\n",
    "        -------\n",
    "            autograd.Variable of size (batch_size, num_noise_words + 1)\n",
    "        \"\"\"\n",
    "        # sparse computation of scores (unnormalized log probabilities)\n",
    "        # for negative sampling\n",
    "        return torch.bmm(\n",
    "            self._D[doc_ids, :].unsqueeze(1),\n",
    "            self._O[:, target_noise_ids].permute(1, 0, 2)).squeeze()\n",
    "\n",
    "    def get_paragraph_vector(self, index):\n",
    "        return self._D[index, :].data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"paragraph_vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from os.path import join, dirname, isfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "_root_dir = \"paragraph_vectors\"\n",
    "\n",
    "DATA_DIR = join(_root_dir, 'data')\n",
    "MODELS_DIR = join(_root_dir, 'models')\n",
    "_DIAGNOSTICS_DIR = join(_root_dir, 'diagnostics')\n",
    "\n",
    "_DM_MODEL_NAME = (\"{:s}_model.{:s}.{:s}_contextsize.{:d}_numnoisewords.{:d}\"\n",
    "                  \"_vecdim.{:d}_batchsize.{:d}_lr.{:f}_epoch.{:d}_loss.{:f}\"\n",
    "                  \".pth.tar\")\n",
    "_DM_DIAGNOSTIC_FILE_NAME = (\"{:s}_model.{:s}.{:s}_contextsize.{:d}\"\n",
    "                            \"_numnoisewords.{:d}_vecdim.{:d}_batchsize.{:d}\"\n",
    "                            \"_lr.{:f}.csv\")\n",
    "_DBOW_MODEL_NAME = (\"{:s}_model.{:s}_numnoisewords.{:d}_vecdim.{:d}\"\n",
    "                    \"_batchsize.{:d}_lr.{:f}_epoch.{:d}_loss.{:f}.pth.tar\")\n",
    "_DBOW_DIAGNOSTIC_FILE_NAME = (\"{:s}_model.{:s}_numnoisewords.{:d}_vecdim.{:d}\"\n",
    "                              \"_batchsize.{:d}_lr.{:f}.csv\")\n",
    "\n",
    "\n",
    "def save_training_state(data_file_name,\n",
    "                        model_ver,\n",
    "                        vec_combine_method,\n",
    "                        context_size,\n",
    "                        num_noise_words,\n",
    "                        vec_dim,\n",
    "                        batch_size,\n",
    "                        lr,\n",
    "                        epoch_i,\n",
    "                        loss,\n",
    "                        model_state,\n",
    "                        save_all,\n",
    "                        generate_plot,\n",
    "                        is_best_loss,\n",
    "                        prev_model_file_path,\n",
    "                        model_ver_is_dbow):\n",
    "    \"\"\"Saves the state of the model. If generate_plot is True, it also\n",
    "    saves current epoch's loss value and generates a plot of all loss\n",
    "    values up to this epoch.\n",
    "    Returns\n",
    "    -------\n",
    "        str representing a model file path from the previous epoch\n",
    "    \"\"\"\n",
    "    if generate_plot:\n",
    "        diagnostic_file_name = _DBOW_DIAGNOSTIC_FILE_NAME.format(\n",
    "            data_file_name[:-4],\n",
    "            model_ver,\n",
    "            num_noise_words,\n",
    "            vec_dim,\n",
    "            batch_size,\n",
    "            lr)\n",
    "\n",
    "        diagnostic_file_path = join(_DIAGNOSTICS_DIR, diagnostic_file_name)\n",
    "\n",
    "        if epoch_i == 0 and isfile(diagnostic_file_path):\n",
    "            remove(diagnostic_file_path)\n",
    "\n",
    "        with open(diagnostic_file_path, 'a') as f:\n",
    "            f.write('{:f}\\n'.format(loss))\n",
    "\n",
    "        # generate a diagnostic loss plot\n",
    "        with open(diagnostic_file_path) as f:\n",
    "            loss_values = [float(l.rstrip()) for l in f.readlines()]\n",
    "\n",
    "        diagnostic_plot_file_path = diagnostic_file_path[:-3] + 'png'\n",
    "        fig = plt.figure()\n",
    "        plt.plot(range(1, epoch_i + 2), loss_values, color='r')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('training loss')\n",
    "        fig.savefig(diagnostic_plot_file_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # save the model\n",
    "\n",
    "    model_file_name = _DBOW_MODEL_NAME.format(\n",
    "        data_file_name[:-4],\n",
    "        model_ver,\n",
    "        num_noise_words,\n",
    "        vec_dim,\n",
    "        batch_size,\n",
    "        lr,\n",
    "        epoch_i + 1,\n",
    "        loss)\n",
    "    \n",
    "\n",
    "    model_file_path = join(MODELS_DIR, model_file_name)\n",
    "\n",
    "    if save_all:\n",
    "        torch.save(model_state, model_file_path)\n",
    "        return None\n",
    "    elif is_best_loss:\n",
    "        if prev_model_file_path is not None:\n",
    "            remove(prev_model_file_path)\n",
    "\n",
    "        torch.save(model_state, model_file_path)\n",
    "        return model_file_path\n",
    "    else:\n",
    "        return prev_model_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comprised of 4 documents.\n",
      "Vocabulary size is 109.\n",
      "\n",
      "Training started.\n",
      "Epoch 1 - 100% (0s) - loss: 1.3878\n",
      "Epoch 2 - 100% (0s) - loss: 1.3301\n",
      "Epoch 3 - 100% (0s) - loss: 1.2810\n",
      "Epoch 4 - 100% (0s) - loss: 1.2419\n",
      "Epoch 5 - 100% (0s) - loss: 1.2232\n",
      "Epoch 6 - 100% (0s) - loss: 1.2029\n",
      "Epoch 7 - 100% (0s) - loss: 1.1736\n",
      "Epoch 8 - 100% (0s) - loss: 1.1549\n",
      "Epoch 9 - 100% (0s) - loss: 1.1146\n",
      "Epoch 10 - 100% (0s) - loss: 1.1438\n",
      "Epoch 11 - 100% (0s) - loss: 1.1212\n",
      "Epoch 12 - 100% (0s) - loss: 1.0624\n",
      "Epoch 13 - 100% (0s) - loss: 1.0534\n",
      "Epoch 14 - 100% (0s) - loss: 1.0857\n",
      "Epoch 15 - 100% (0s) - loss: 1.1014\n",
      "Epoch 16 - 100% (0s) - loss: 1.0483\n",
      "Epoch 17 - 100% (0s) - loss: 1.0052\n",
      "Epoch 18 - 100% (0s) - loss: 1.0043\n",
      "Epoch 19 - 100% (0s) - loss: 1.0023\n",
      "Epoch 20 - 100% (0s) - loss: 1.0315\n",
      "Epoch 21 - 100% (0s) - loss: 1.0238\n",
      "Epoch 22 - 100% (0s) - loss: 1.0059\n",
      "Epoch 23 - 100% (0s) - loss: 1.0244\n",
      "Epoch 24 - 100% (0s) - loss: 0.9825\n",
      "Epoch 25 - 100% (0s) - loss: 0.9935\n",
      "Epoch 26 - 100% (0s) - loss: 1.0065\n",
      "Epoch 27 - 100% (0s) - loss: 0.9920\n",
      "Epoch 28 - 100% (0s) - loss: 0.9826\n",
      "Epoch 29 - 100% (0s) - loss: 1.0017\n",
      "Epoch 30 - 100% (0s) - loss: 0.9951\n",
      "Epoch 31 - 100% (0s) - loss: 0.9465\n",
      "Epoch 32 - 100% (0s) - loss: 0.9258\n",
      "Epoch 33 - 100% (0s) - loss: 0.9225\n",
      "Epoch 34 - 100% (0s) - loss: 0.9581\n",
      "Epoch 35 - 100% (0s) - loss: 0.9088\n",
      "Epoch 36 - 100% (0s) - loss: 1.0128\n",
      "Epoch 37 - 100% (0s) - loss: 0.9374\n",
      "Epoch 38 - 100% (0s) - loss: 0.9669\n",
      "Epoch 39 - 100% (0s) - loss: 0.9020\n",
      "Epoch 40 - 100% (0s) - loss: 0.8859\n",
      "Epoch 41 - 100% (0s) - loss: 0.9067\n",
      "Epoch 42 - 100% (0s) - loss: 0.8832\n",
      "Epoch 43 - 100% (0s) - loss: 0.9366\n",
      "Epoch 44 - 100% (0s) - loss: 0.9624\n",
      "Epoch 45 - 100% (0s) - loss: 1.0405\n",
      "Epoch 46 - 100% (0s) - loss: 0.9365\n",
      "Epoch 47 - 100% (0s) - loss: 0.9343\n",
      "Epoch 48 - 100% (0s) - loss: 0.9937\n",
      "Epoch 49 - 100% (0s) - loss: 0.8761\n",
      "Epoch 50 - 100% (0s) - loss: 0.9327\n",
      "Epoch 51 - 100% (0s) - loss: 0.8770\n",
      "Epoch 52 - 100% (0s) - loss: 0.8253\n",
      "Epoch 53 - 100% (0s) - loss: 0.9546\n",
      "Epoch 54 - 100% (0s) - loss: 0.9033\n",
      "Epoch 55 - 100% (0s) - loss: 0.9196\n",
      "Epoch 56 - 100% (0s) - loss: 0.8683\n",
      "Epoch 57 - 100% (0s) - loss: 0.9019\n",
      "Epoch 58 - 100% (0s) - loss: 0.8629\n",
      "Epoch 59 - 100% (0s) - loss: 0.8582\n",
      "Epoch 60 - 100% (0s) - loss: 0.9113\n",
      "Epoch 61 - 100% (0s) - loss: 0.8935\n",
      "Epoch 62 - 100% (0s) - loss: 0.8969\n",
      "Epoch 63 - 100% (0s) - loss: 0.9241\n",
      "Epoch 64 - 100% (0s) - loss: 0.8829\n",
      "Epoch 65 - 100% (0s) - loss: 0.8986\n",
      "Epoch 66 - 100% (0s) - loss: 0.8814\n",
      "Epoch 67 - 100% (1s) - loss: 0.8221\n",
      "Epoch 68 - 100% (1s) - loss: 0.9348\n",
      "Epoch 69 - 100% (1s) - loss: 0.9098\n",
      "Epoch 70 - 100% (0s) - loss: 0.9255\n",
      "Epoch 71 - 100% (0s) - loss: 0.8618\n",
      "Epoch 72 - 100% (0s) - loss: 0.8772\n",
      "Epoch 73 - 100% (0s) - loss: 0.9251\n",
      "Epoch 74 - 100% (0s) - loss: 0.9167\n",
      "Epoch 75 - 100% (0s) - loss: 0.9171\n",
      "Epoch 76 - 100% (0s) - loss: 0.8821\n",
      "Epoch 77 - 100% (0s) - loss: 0.8854\n",
      "Epoch 78 - 100% (0s) - loss: 0.9180\n",
      "Epoch 79 - 100% (0s) - loss: 0.8597\n",
      "Epoch 80 - 100% (0s) - loss: 0.8586\n",
      "Epoch 81 - 100% (0s) - loss: 0.9063\n",
      "Epoch 82 - 100% (0s) - loss: 0.8929\n",
      "Epoch 83 - 100% (0s) - loss: 0.8780\n",
      "Epoch 84 - 100% (0s) - loss: 0.9038\n",
      "Epoch 85 - 100% (0s) - loss: 0.8843\n",
      "Epoch 86 - 100% (0s) - loss: 0.9343\n",
      "Epoch 87 - 100% (0s) - loss: 0.9019\n",
      "Epoch 88 - 100% (1s) - loss: 0.9097\n",
      "Epoch 89 - 100% (0s) - loss: 0.8871\n",
      "Epoch 90 - 100% (0s) - loss: 0.9214\n",
      "Epoch 91 - 100% (1s) - loss: 0.8927\n",
      "Epoch 92 - 100% (1s) - loss: 0.9195\n",
      "Epoch 93 - 100% (0s) - loss: 0.8763\n",
      "Epoch 94 - 100% (0s) - loss: 0.8864\n",
      "Epoch 95 - 100% (0s) - loss: 0.9110\n",
      "Epoch 96 - 100% (0s) - loss: 0.8993\n",
      "Epoch 97 - 100% (0s) - loss: 0.8667\n",
      "Epoch 98 - 100% (0s) - loss: 0.8794\n",
      "Epoch 99 - 100% (1s) - loss: 0.8486\n",
      "Epoch 100 - 100% (0s) - loss: 0.9452\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sys import float_info, stdout\n",
    "\n",
    "import fire\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "data_file_name = 'example.csv' \n",
    "num_epochs = 100 \n",
    "batch_size = 32 \n",
    "num_noise_words = 2 \n",
    "vec_dim = 100 \n",
    "lr = 1e-3\n",
    "\n",
    "model_ver_is_dbow = True\n",
    "model_ver = 'dbow'\n",
    "\n",
    "context_size=0\n",
    "num_workers=1\n",
    "\n",
    "vec_combine_method='sum'\n",
    "save_all=False\n",
    "generate_plot=True\n",
    "max_generated_batches=5\n",
    "num_workers=1\n",
    "\n",
    "if vec_combine_method not in ('sum', 'concat'):\n",
    "    raise ValueError(\"Invalid method for combining paragraph and word \"\n",
    "                     \"vectors when using dm\")\n",
    "\n",
    "\n",
    "dataset = load_dataset(data_file_name)\n",
    "nce_data = NCEData(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    context_size,\n",
    "    num_noise_words,\n",
    "    max_generated_batches,\n",
    "    num_workers)\n",
    "\n",
    "data_generator = nce_data._generator\n",
    "\n",
    "\n",
    "num_batches = len(nce_data)\n",
    "vocabulary_size = nce_data.vocabulary_size()\n",
    "\n",
    "model = DBOW(vec_dim, num_docs=len(dataset), num_words=vocabulary_size)\n",
    "cost_func = NegativeSampling()\n",
    "optimizer = Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print(\"Dataset comprised of {:d} documents.\".format(len(dataset)))\n",
    "print(\"Vocabulary size is {:d}.\\n\".format(vocabulary_size))\n",
    "print(\"Training started.\")\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "prev_model_file_path = None\n",
    "\n",
    "for epoch_i in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    loss = []\n",
    "\n",
    "    for batch_i in range(num_batches):\n",
    "        batch = data_generator.next()\n",
    "        if torch.cuda.is_available():\n",
    "            batch.cuda_()\n",
    "\n",
    "\n",
    "        x = model.forward(batch.doc_ids, batch.target_noise_ids)\n",
    "        x = cost_func.forward(x)\n",
    "\n",
    "        loss.append(x.item())\n",
    "        model.zero_grad()\n",
    "        x.backward()\n",
    "        optimizer.step()\n",
    "        _print_progress(epoch_i, batch_i, num_batches)\n",
    "\n",
    "    # end of epoch\n",
    "    loss = torch.mean(torch.FloatTensor(loss))\n",
    "    is_best_loss = loss < best_loss\n",
    "    best_loss = min(loss, best_loss)\n",
    "\n",
    "    state = {\n",
    "        'epoch': epoch_i + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    prev_model_file_path = save_training_state(\n",
    "        data_file_name,\n",
    "        model_ver,\n",
    "        vec_combine_method,\n",
    "        context_size,\n",
    "        num_noise_words,\n",
    "        vec_dim,\n",
    "        batch_size,\n",
    "        lr,\n",
    "        epoch_i,\n",
    "        loss,\n",
    "        state,\n",
    "        save_all,\n",
    "        generate_plot,\n",
    "        is_best_loss,\n",
    "        prev_model_file_path,\n",
    "        model_ver_is_dbow)\n",
    "\n",
    "    epoch_total_time = round(time.time() - epoch_start_time)\n",
    "    print(\" ({:d}s) - loss: {:.4f}\".format(epoch_total_time, loss))\n",
    "\n",
    "\n",
    "def _print_progress(epoch_i, batch_i, num_batches):\n",
    "    progress = round((batch_i + 1) / num_batches * 100)\n",
    "    print(\"\\rEpoch {:d}\".format(epoch_i + 1), end='')\n",
    "    stdout.write(\" - {:d}%\".format(progress))\n",
    "    stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
