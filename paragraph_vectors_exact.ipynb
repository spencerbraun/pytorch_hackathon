{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.18.1)\n",
      "Requirement already satisfied: torch in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.6/site-packages (from torchtext) (4.48.2)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (2.23.0)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/.local/lib/python3.6/site-packages (from torchtext) (0.1.91)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (2020.4.5.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import signal\n",
    "from math import ceil\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from numpy.random import choice\n",
    "from torchtext.data import Field, TabularDataset\n",
    "\n",
    "# from paragraphvec.utils import DATA_DIR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(file_name):\n",
    "    \"\"\"Loads contents from a file in the *data* directory into a\n",
    "    torchtext.data.TabularDataset instance.\n",
    "    \"\"\"\n",
    "    file_path = join(DATA_DIR, file_name)\n",
    "    text_field = Field(pad_token=None, tokenize=_tokenize_str)\n",
    "\n",
    "    dataset = TabularDataset(\n",
    "        path=file_path,\n",
    "        format='csv',\n",
    "        fields=[('text', text_field)],\n",
    "        skip_header=True)\n",
    "\n",
    "    text_field.build_vocab(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def _tokenize_str(str_):\n",
    "    # keep only alphanumeric and punctations\n",
    "    str_ = re.sub(r'[^A-Za-z0-9(),.!?\\'`]', ' ', str_)\n",
    "    # remove multiple whitespace characters\n",
    "    str_ = re.sub(r'\\s{2,}', ' ', str_)\n",
    "    # punctations to tokens\n",
    "    str_ = re.sub(r'\\(', ' ( ', str_)\n",
    "    str_ = re.sub(r'\\)', ' ) ', str_)\n",
    "    str_ = re.sub(r',', ' , ', str_)\n",
    "    str_ = re.sub(r'\\.', ' . ', str_)\n",
    "    str_ = re.sub(r'!', ' ! ', str_)\n",
    "    str_ = re.sub(r'\\?', ' ? ', str_)\n",
    "    # split contractions into multiple tokens\n",
    "    str_ = re.sub(r'\\'s', ' \\'s', str_)\n",
    "    str_ = re.sub(r'\\'ve', ' \\'ve', str_)\n",
    "    str_ = re.sub(r'n\\'t', ' n\\'t', str_)\n",
    "    str_ = re.sub(r'\\'re', ' \\'re', str_)\n",
    "    str_ = re.sub(r'\\'d', ' \\'d', str_)\n",
    "    str_ = re.sub(r'\\'ll', ' \\'ll', str_)\n",
    "    # lower case\n",
    "    return str_.strip().lower().split()\n",
    "\n",
    "\n",
    "class NCEData(object):\n",
    "    \"\"\"An infinite, parallel (multiprocess) batch generator for\n",
    "    noise-contrastive estimation of word vector models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: torchtext.data.TabularDataset\n",
    "        Dataset from which examples are generated. A column labeled *text*\n",
    "        is expected and should be comprised of a list of tokens. Each row\n",
    "        should represent a single document.\n",
    "\n",
    "    batch_size: int\n",
    "        Number of examples per single gradient update.\n",
    "\n",
    "    context_size: int\n",
    "        Half the size of a neighbourhood of target words (i.e. how many\n",
    "        words left and right are regarded as context).\n",
    "\n",
    "    num_noise_words: int\n",
    "        Number of noise words to sample from the noise distribution.\n",
    "\n",
    "    max_size: int\n",
    "        Maximum number of pre-generated batches.\n",
    "\n",
    "    num_workers: int\n",
    "        Number of jobs to run in parallel. If value is set to -1, total number\n",
    "        of machine CPUs is used.\n",
    "    \"\"\"\n",
    "    # code inspired by parallel generators in https://github.com/fchollet/keras\n",
    "    def __init__(self, dataset, batch_size, context_size,\n",
    "                 num_noise_words, max_size, num_workers):\n",
    "        self.max_size = max_size\n",
    "\n",
    "        self.num_workers = num_workers if num_workers != -1 else os.cpu_count()\n",
    "        if self.num_workers is None:\n",
    "            self.num_workers = 1\n",
    "\n",
    "        self._generator = _NCEGenerator(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            context_size,\n",
    "            num_noise_words,\n",
    "            _NCEGeneratorState(context_size))\n",
    "\n",
    "        self._queue = []\n",
    "        self._stop_event = None\n",
    "        self._processes = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._generator)\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return self._generator.vocabulary_size()\n",
    "\n",
    "\n",
    "\n",
    "class _NCEGenerator(object):\n",
    "    \"\"\"An infinite, process-safe batch generator for noise-contrastive\n",
    "    estimation of word vector models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: paragraphvec.data._NCEGeneratorState\n",
    "        Initial (indexing) state of the generator.\n",
    "\n",
    "    For other parameters see the NCEData class.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, context_size,\n",
    "                 num_noise_words, state):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.context_size = context_size\n",
    "        self.num_noise_words = num_noise_words\n",
    "\n",
    "        self._vocabulary = self.dataset.fields['text'].vocab\n",
    "        self._sample_noise = None\n",
    "        self._init_noise_distribution()\n",
    "        self._state = state\n",
    "\n",
    "    def _init_noise_distribution(self):\n",
    "        # we use a unigram distribution raised to the 3/4rd power,\n",
    "        # as proposed by T. Mikolov et al. in Distributed Representations\n",
    "        # of Words and Phrases and their Compositionality\n",
    "        probs = np.zeros(len(self._vocabulary) - 1)\n",
    "\n",
    "        for word, freq in self._vocabulary.freqs.items():\n",
    "            probs[self._word_to_index(word)] = freq\n",
    "\n",
    "        probs = np.power(probs, 0.75)\n",
    "        probs /= np.sum(probs)\n",
    "\n",
    "        self._sample_noise = lambda: choice(\n",
    "            probs.shape[0], self.num_noise_words, p=probs).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        num_examples = sum(self._num_examples_in_doc(d) for d in self.dataset)\n",
    "        return ceil(num_examples / self.batch_size)\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return len(self._vocabulary) - 1\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Updates state for the next process in a process-safe manner\n",
    "        and generates the current batch.\"\"\"\n",
    "        prev_doc_id, prev_in_doc_pos = self._state.update_state(\n",
    "            self.dataset,\n",
    "            self.batch_size,\n",
    "            self.context_size,\n",
    "            self._num_examples_in_doc)\n",
    "\n",
    "        # generate the actual batch\n",
    "        batch = _NCEBatch(self.context_size)\n",
    "\n",
    "        while len(batch) < self.batch_size:\n",
    "            if prev_doc_id == len(self.dataset):\n",
    "                # last document exhausted\n",
    "                batch.torch_()\n",
    "                return batch\n",
    "            if prev_in_doc_pos <= (len(self.dataset[prev_doc_id].text) - 1\n",
    "                                   - self.context_size):\n",
    "                # more examples in the current document\n",
    "                self._add_example_to_batch(prev_doc_id, prev_in_doc_pos, batch)\n",
    "                prev_in_doc_pos += 1\n",
    "            else:\n",
    "                # go to the next document\n",
    "                prev_doc_id += 1\n",
    "                prev_in_doc_pos = self.context_size\n",
    "\n",
    "        batch.torch_()\n",
    "        return batch\n",
    "\n",
    "    def _num_examples_in_doc(self, doc, in_doc_pos=None):\n",
    "        if in_doc_pos is not None:\n",
    "            # number of remaining\n",
    "            if len(doc.text) - in_doc_pos >= self.context_size + 1:\n",
    "                return len(doc.text) - in_doc_pos - self.context_size\n",
    "            return 0\n",
    "\n",
    "        if len(doc.text) >= 2 * self.context_size + 1:\n",
    "            # total number\n",
    "            return len(doc.text) - 2 * self.context_size\n",
    "        return 0\n",
    "\n",
    "    def _add_example_to_batch(self, doc_id, in_doc_pos, batch):\n",
    "        doc = self.dataset[doc_id].text\n",
    "        batch.doc_ids.append(doc_id)\n",
    "\n",
    "        # sample from the noise distribution\n",
    "        current_noise = self._sample_noise()\n",
    "        current_noise.insert(0, self._word_to_index(doc[in_doc_pos]))\n",
    "        batch.target_noise_ids.append(current_noise)\n",
    "\n",
    "        if self.context_size == 0:\n",
    "            return\n",
    "\n",
    "        current_context = []\n",
    "        context_indices = (in_doc_pos + diff for diff in\n",
    "                           range(-self.context_size, self.context_size + 1)\n",
    "                           if diff != 0)\n",
    "\n",
    "        for i in context_indices:\n",
    "            context_id = self._word_to_index(doc[i])\n",
    "            current_context.append(context_id)\n",
    "        batch.context_ids.append(current_context)\n",
    "\n",
    "    def _word_to_index(self, word):\n",
    "        return self._vocabulary.stoi[word] - 1\n",
    "\n",
    "\n",
    "class _NCEGeneratorState(object):\n",
    "    \"\"\"Batch generator state that is represented with a document id and\n",
    "    in-document position. It abstracts a process-safe indexing mechanism.\"\"\"\n",
    "    def __init__(self, context_size):\n",
    "        # use raw values because both indices have\n",
    "        # to manually be locked together\n",
    "        self._doc_id = multiprocessing.RawValue('i', 0)\n",
    "        self._in_doc_pos = multiprocessing.RawValue('i', context_size)\n",
    "        self._lock = multiprocessing.Lock()\n",
    "\n",
    "    def update_state(self, dataset, batch_size,\n",
    "                     context_size, num_examples_in_doc):\n",
    "        \"\"\"Returns current indices and computes new indices for the\n",
    "        next process.\"\"\"\n",
    "        with self._lock:\n",
    "            doc_id = self._doc_id.value\n",
    "            in_doc_pos = self._in_doc_pos.value\n",
    "            self._advance_indices(\n",
    "                dataset, batch_size, context_size, num_examples_in_doc)\n",
    "            return doc_id, in_doc_pos\n",
    "\n",
    "    def _advance_indices(self, dataset, batch_size,\n",
    "                         context_size, num_examples_in_doc):\n",
    "        num_examples = num_examples_in_doc(\n",
    "            dataset[self._doc_id.value], self._in_doc_pos.value)\n",
    "\n",
    "        if num_examples > batch_size:\n",
    "            # more examples in the current document\n",
    "            self._in_doc_pos.value += batch_size\n",
    "            return\n",
    "\n",
    "        if num_examples == batch_size:\n",
    "            # just enough examples in the current document\n",
    "            if self._doc_id.value < len(dataset) - 1:\n",
    "                self._doc_id.value += 1\n",
    "            else:\n",
    "                self._doc_id.value = 0\n",
    "            self._in_doc_pos.value = context_size\n",
    "            return\n",
    "\n",
    "        while num_examples < batch_size:\n",
    "            if self._doc_id.value == len(dataset) - 1:\n",
    "                # last document: reset indices\n",
    "                self._doc_id.value = 0\n",
    "                self._in_doc_pos.value = context_size\n",
    "                return\n",
    "\n",
    "            self._doc_id.value += 1\n",
    "            num_examples += num_examples_in_doc(\n",
    "                dataset[self._doc_id.value])\n",
    "\n",
    "        self._in_doc_pos.value = (len(dataset[self._doc_id.value].text)\n",
    "                                  - context_size\n",
    "                                  - (num_examples - batch_size))\n",
    "\n",
    "\n",
    "class _NCEBatch(object):\n",
    "    def __init__(self, context_size):\n",
    "        self.context_ids = [] if context_size > 0 else None\n",
    "        self.doc_ids = []\n",
    "        self.target_noise_ids = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.doc_ids)\n",
    "\n",
    "    def torch_(self):\n",
    "        if self.context_ids is not None:\n",
    "            self.context_ids = torch.LongTensor(self.context_ids)\n",
    "        self.doc_ids = torch.LongTensor(self.doc_ids)\n",
    "        self.target_noise_ids = torch.LongTensor(self.target_noise_ids)\n",
    "\n",
    "    def cuda_(self):\n",
    "        if self.context_ids is not None:\n",
    "            self.context_ids = self.context_ids.cuda()\n",
    "        self.doc_ids = self.doc_ids.cuda()\n",
    "        self.target_noise_ids = self.target_noise_ids.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NegativeSampling(nn.Module):\n",
    "    \"\"\"Negative sampling loss as proposed by T. Mikolov et al. in Distributed\n",
    "    Representations of Words and Phrases and their Compositionality.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(NegativeSampling, self).__init__()\n",
    "        self._log_sigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, scores):\n",
    "        \"\"\"Computes the value of the loss function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        scores: autograd.Variable of size (batch_size, num_noise_words + 1)\n",
    "            Sparse unnormalized log probabilities. The first element in each\n",
    "            row is the ground truth score (i.e. the target), other elements\n",
    "            are scores of samples from the noise distribution.\n",
    "        \"\"\"\n",
    "        k = scores.size()[1] - 1\n",
    "        return -torch.sum(\n",
    "            self._log_sigmoid(scores[:, 0])\n",
    "            + torch.sum(self._log_sigmoid(-scores[:, 1:]), dim=1) / k\n",
    "        ) / scores.size()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DBOW(nn.Module):\n",
    "    \"\"\"Distributed Bag of Words version of Paragraph Vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec_dim: int\n",
    "        Dimensionality of vectors to be learned (for paragraphs and words).\n",
    "    num_docs: int\n",
    "        Number of documents in a dataset.\n",
    "    num_words: int\n",
    "        Number of distinct words in a daset (i.e. vocabulary size).\n",
    "    \"\"\"\n",
    "    def __init__(self, vec_dim, num_docs, num_words):\n",
    "        super(DBOW, self).__init__()\n",
    "        # paragraph matrix\n",
    "        self._D = nn.Parameter(\n",
    "            torch.randn(num_docs, vec_dim), requires_grad=True)\n",
    "        # output layer parameters\n",
    "        self._O = nn.Parameter(\n",
    "            torch.FloatTensor(vec_dim, num_words).zero_(), requires_grad=True)\n",
    "\n",
    "    def forward(self, doc_ids, target_noise_ids):\n",
    "        \"\"\"Sparse computation of scores (unnormalized log probabilities)\n",
    "        that should be passed to the negative sampling loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc_ids: torch.Tensor of size (batch_size,)\n",
    "            Document indices of paragraphs.\n",
    "        target_noise_ids: torch.Tensor of size (batch_size, num_noise_words + 1)\n",
    "            Vocabulary indices of target and noise words. The first element in\n",
    "            each row is the ground truth index (i.e. the target), other\n",
    "            elements are indices of samples from the noise distribution.\n",
    "        Returns\n",
    "        -------\n",
    "            autograd.Variable of size (batch_size, num_noise_words + 1)\n",
    "        \"\"\"\n",
    "        # sparse computation of scores (unnormalized log probabilities)\n",
    "        # for negative sampling\n",
    "        return torch.bmm(\n",
    "            self._D[doc_ids, :].unsqueeze(1),\n",
    "            self._O[:, target_noise_ids].permute(1, 0, 2)).squeeze()\n",
    "\n",
    "    def get_paragraph_vector(self, index):\n",
    "        return self._D[index, :].data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from os.path import join, dirname, isfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "_root_dir = \"model_data\"\n",
    "\n",
    "DATA_DIR = join(_root_dir, 'data')\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "MODELS_DIR = join(_root_dir, 'models')\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "_DIAGNOSTICS_DIR = join(_root_dir, 'diagnostics')\n",
    "if not os.path.exists(_DIAGNOSTICS_DIR):\n",
    "    os.mkdir(_DIAGNOSTICS_DIR)\n",
    "\n",
    "_DM_MODEL_NAME = (\"{:s}_model.{:s}.{:s}_contextsize.{:d}_numnoisewords.{:d}\"\n",
    "                  \"_vecdim.{:d}_batchsize.{:d}_lr.{:f}_epoch.{:d}_loss.{:f}\"\n",
    "                  \".pth.tar\")\n",
    "_DM_DIAGNOSTIC_FILE_NAME = (\"{:s}_model.{:s}.{:s}_contextsize.{:d}\"\n",
    "                            \"_numnoisewords.{:d}_vecdim.{:d}_batchsize.{:d}\"\n",
    "                            \"_lr.{:f}.csv\")\n",
    "_DBOW_MODEL_NAME = (\"{:s}_model.{:s}_numnoisewords.{:d}_vecdim.{:d}\"\n",
    "                    \"_batchsize.{:d}_lr.{:f}_epoch.{:d}_loss.{:f}2.pth.tar\")\n",
    "_DBOW_DIAGNOSTIC_FILE_NAME = (\"{:s}_model.{:s}_numnoisewords.{:d}_vecdim.{:d}\"\n",
    "                              \"_batchsize.{:d}_lr.{:f}.csv\")\n",
    "\n",
    "\n",
    "def save_training_state(data_file_name,\n",
    "                        model_ver,\n",
    "                        vec_combine_method,\n",
    "                        context_size,\n",
    "                        num_noise_words,\n",
    "                        vec_dim,\n",
    "                        batch_size,\n",
    "                        lr,\n",
    "                        epoch_i,\n",
    "                        loss,\n",
    "                        model_state,\n",
    "                        save_all,\n",
    "                        generate_plot,\n",
    "                        is_best_loss,\n",
    "                        prev_model_file_path,\n",
    "                        model_ver_is_dbow):\n",
    "    \"\"\"Saves the state of the model. If generate_plot is True, it also\n",
    "    saves current epoch's loss value and generates a plot of all loss\n",
    "    values up to this epoch.\n",
    "    Returns\n",
    "    -------\n",
    "        str representing a model file path from the previous epoch\n",
    "    \"\"\"\n",
    "    if generate_plot:\n",
    "        diagnostic_file_name = _DBOW_DIAGNOSTIC_FILE_NAME.format(\n",
    "            data_file_name[:-4],\n",
    "            model_ver,\n",
    "            num_noise_words,\n",
    "            vec_dim,\n",
    "            batch_size,\n",
    "            lr)\n",
    "\n",
    "        diagnostic_file_path = join(_DIAGNOSTICS_DIR, diagnostic_file_name)\n",
    "\n",
    "        if epoch_i == 0 and isfile(diagnostic_file_path):\n",
    "            remove(diagnostic_file_path)\n",
    "\n",
    "        with open(diagnostic_file_path, 'a') as f:\n",
    "            f.write('{:f}\\n'.format(loss))\n",
    "\n",
    "        # generate a diagnostic loss plot\n",
    "        with open(diagnostic_file_path) as f:\n",
    "            loss_values = [float(l.rstrip()) for l in f.readlines()]\n",
    "\n",
    "        diagnostic_plot_file_path = diagnostic_file_path[:-3] + 'png'\n",
    "        fig = plt.figure()\n",
    "        plt.plot(range(1, epoch_i + 2), loss_values, color='r')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('training loss')\n",
    "        fig.savefig(diagnostic_plot_file_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # save the model\n",
    "\n",
    "    model_file_name = _DBOW_MODEL_NAME.format(\n",
    "        data_file_name[:-4],\n",
    "        model_ver,\n",
    "        num_noise_words,\n",
    "        vec_dim,\n",
    "        batch_size,\n",
    "        lr,\n",
    "        epoch_i + 1,\n",
    "        loss)\n",
    "    \n",
    "\n",
    "    model_file_path = join(MODELS_DIR, model_file_name)\n",
    "\n",
    "    if save_all:\n",
    "        torch.save(model_state, model_file_path)\n",
    "        return None\n",
    "    elif is_best_loss:\n",
    "        if prev_model_file_path is not None:\n",
    "            remove(prev_model_file_path)\n",
    "\n",
    "        torch.save(model_state, model_file_path)\n",
    "        return model_file_path\n",
    "    else:\n",
    "        return prev_model_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def start(data_file_name, model_file_name):\n",
    "    \"\"\"Saves trained paragraph vectors to a csv file in the *data* directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_file_name: str\n",
    "        Name of a file in the *data* directory that was used during training.\n",
    "    model_file_name: str\n",
    "        Name of a file in the *models* directory (a model trained on\n",
    "        the *data_file_name* dataset).\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(data_file_name)\n",
    "\n",
    "    vec_dim = int(re.search('_vecdim\\.(\\d+)_', model_file_name).group(1))\n",
    "\n",
    "    model = _load_model(\n",
    "        model_file_name,\n",
    "        vec_dim,\n",
    "        num_docs=len(dataset),\n",
    "        num_words=len(dataset.fields['text'].vocab) - 1)\n",
    "\n",
    "    _write_to_file(data_file_name, model_file_name, model, vec_dim)\n",
    "\n",
    "\n",
    "def _load_model(model_file_name, vec_dim, num_docs, num_words):\n",
    "    model_ver = re.search('_model\\.(dm|dbow)', model_file_name).group(1)\n",
    "    if model_ver is None:\n",
    "        raise ValueError(\"Model file name contains an invalid\"\n",
    "                         \"version of the model\")\n",
    "\n",
    "    model_file_path = join(MODELS_DIR, model_file_name)\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(model_file_path)\n",
    "    except RuntimeError:\n",
    "        checkpoint = torch.load(\n",
    "            model_file_path,\n",
    "            map_location=lambda storage, location: storage)\n",
    "\n",
    "    if model_ver == 'dbow':\n",
    "        model = DBOW(vec_dim, num_docs, num_words)\n",
    "    else:\n",
    "        model = DM(vec_dim, num_docs, num_words)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def _write_to_file(data_file_name, model_file_name, model, vec_dim):\n",
    "    result_lines = []\n",
    "\n",
    "    with open(join(DATA_DIR, data_file_name)) as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for i, line in enumerate(reader):\n",
    "            # skip text\n",
    "            result_line = line[1:]\n",
    "            if i == 0:\n",
    "                # header line\n",
    "                result_line += [\"d{:d}\".format(x) for x in range(vec_dim)]\n",
    "            else:\n",
    "                vector = model.get_paragraph_vector(i - 1)\n",
    "                result_line += [str(x) for x in vector]\n",
    "\n",
    "            result_lines.append(result_line)\n",
    "\n",
    "    result_file_name = model_file_name[:-7] + 'csv'\n",
    "\n",
    "    with open(join(DATA_DIR, result_file_name), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(result_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _print_progress(epoch_i, batch_i, num_batches):\n",
    "    progress = round((batch_i + 1) / num_batches * 100)\n",
    "    print(\"\\rEpoch {:d}\".format(epoch_i + 1), end='')\n",
    "    stdout.write(\" - {:d}%\".format(progress))\n",
    "    stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sys import float_info, stdout\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "data_file_name = 'all_data.csv' \n",
    "\n",
    "num_epochs = 100 \n",
    "batch_size = 32 \n",
    "num_noise_words = 2 \n",
    "vec_dim = 100 \n",
    "lr = 1e-3\n",
    "\n",
    "model_ver_is_dbow = True\n",
    "model_ver = 'dbow'\n",
    "\n",
    "context_size=0\n",
    "num_workers=1\n",
    "\n",
    "vec_combine_method='sum'\n",
    "save_all=False\n",
    "generate_plot=True\n",
    "max_generated_batches=5\n",
    "num_workers=1\n",
    "\n",
    "if vec_combine_method not in ('sum', 'concat'):\n",
    "    raise ValueError(\"Invalid method for combining paragraph and word \"\n",
    "                     \"vectors when using dm\")\n",
    "\n",
    "\n",
    "dataset = load_dataset(data_file_name)\n",
    "nce_data = NCEData(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    context_size,\n",
    "    num_noise_words,\n",
    "    max_generated_batches,\n",
    "    num_workers)\n",
    "\n",
    "data_generator = nce_data._generator\n",
    "\n",
    "\n",
    "num_batches = len(nce_data)\n",
    "vocabulary_size = nce_data.vocabulary_size()\n",
    "\n",
    "model = DBOW(vec_dim, num_docs=len(dataset), num_words=vocabulary_size)\n",
    "cost_func = NegativeSampling()\n",
    "optimizer = Adam(params=model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comprised of 473 documents.\n",
      "Vocabulary size is 8413.\n",
      "\n",
      "Training started.\n",
      "Epoch 1 - 100% 2% - 6% - 6% - 6% - 7% - 8% - 9% - 10% - 16% - 16% - 16% - 16% - 17% - 17% - 20% - 20% - 22% - 25% - 25% - 26% - 26% - 26% - 26% - 26% - 28% - 28% - 29% - 30% - 32% - 32% - 33% - 33% - 35% - 36% - 36% - 38% - 39% - 39% - 40% - 40% - 40% - 43% - 47% - 47% - 47% - 49% - 52% - 52% - 52% - 53% - 53% - 54% - 57% - 60% - 62% - 62% - 64% - 66% - 66% - 67% - 67% - 67% - 67% - 67% - 70% - 70% - 70% - 71% - 72% - 73% - 73% - 73% - 76% - 77% - 77% - 77% - 77% - 79% - 79% - 81% - 84% - 85% - 85% - 90% - 90% - 91% - 93% - 99% - 99% - 99% - 100% (68s) - loss: 1.3271\n",
      "Epoch 2 - 100% 3% - 4% - 5% - 5% - 5% - 5% - 6% - 6% - 6% - 7% - 7% - 7% - 7% - 8% - 8% - 8% - 12% - 13% - 13% - 13% - 13% - 13% - 13% - 13% - 13% - 16% - 16% - 16% - 17% - 17% - 17% - 17% - 18% - 19% - 19% - 20% - 20% - 23% - 24% - 25% - 26% - 26% - 26% - 26% - 26% - 26% - 27% - 27% - 27% - 27% - 27% - 29% - 29% - 29% - 30% - 30% - 33% - 33% - 33% - 34% - 34% - 35% - 35% - 41% - 42% - 45% - 46% - 48% - 48% - 49% - 51% - 53% - 53% - 55% - 56% - 57% - 59% - 60% - 62% - 65% - 66% - 67% - 67% - 68% - 68% - 68% - 69% - 69% - 70% - 71% - 71% - 71% - 72% - 72% - 73% - 73% - 73% - 73% - 74% - 74% - 74% - 74% - 74% - 76% - 76% - 78% - 79% - 79% - 83% - 84% - 84% - 84% - 85% - 85% - 85% - 85% - 85% - 88% - 88% - 88% - 90% - 90% - 91% - 92% - 92% - 95% - 97% - 98% - 98% - 99% - 100% (68s) - loss: 1.1380\n",
      "Epoch 3 - 100% 2% - 4% - 5% - 6% - 6% - 7% - 7% - 8% - 8% - 8% - 9% - 9% - 11% - 11% - 15% - 15% - 16% - 16% - 16% - 19% - 20% - 20% - 21% - 21% - 21% - 23% - 25% - 26% - 27% - 27% - 31% - 31% - 31% - 32% - 32% - 32% - 32% - 33% - 33% - 34% - 40% - 41% - 46% - 46% - 46% - 49% - 51% - 52% - 53% - 56% - 56% - 56% - 59% - 59% - 60% - 60% - 61% - 61% - 61% - 61% - 62% - 62% - 62% - 65% - 65% - 68% - 70% - 71% - 71% - 71% - 71% - 72% - 73% - 74% - 74% - 74% - 78% - 79% - 83% - 83% - 84% - 84% - 84% - 84% - 85% - 85% - 85% - 86% - 87% - 88% - 88% - 88% - 90% - 91% - 92% - 92% - 92% - 92% - 92% - 92% - 93% - 93% - 99% (68s) - loss: 1.0135\n",
      "Epoch 4 - 100% 3% - 3% - 4% - 4% - 4% - 6% - 6% - 8% - 8% - 10% - 13% - 14% - 14% - 14% - 14% - 16% - 19% - 20% - 20% - 20% - 20% - 20% - 24% - 27% - 29% - 29% - 30% - 32% - 32% - 34% - 34% - 35% - 35% - 36% - 36% - 37% - 37% - 37% - 37% - 41% - 42% - 44% - 45% - 47% - 47% - 49% - 49% - 49% - 51% - 51% - 51% - 51% - 56% - 56% - 57% - 57% - 58% - 58% - 59% - 59% - 59% - 62% - 63% - 63% - 64% - 65% - 67% - 69% - 69% - 70% - 70% - 71% - 72% - 73% - 73% - 73% - 74% - 76% - 78% - 78% - 78% - 79% - 80% - 80% - 82% - 82% - 83% - 83% - 83% - 83% - 83% - 83% - 85% - 85% - 86% - 88% - 88% - 89% - 89% - 89% - 91% - 91% - 91% - 91% - 91% - 91% - 92% - 92% - 92% - 92% - 93% - 93% - 94% - 95% - 97% - 97% - 97% - 98% - 99% - 99% (69s) - loss: 0.9286\n",
      "Epoch 5 - 100% 0% - 0% - 2% - 3% - 3% - 8% - 8% - 8% - 8% - 8% - 8% - 9% - 9% - 10% - 10% - 10% - 11% - 13% - 13% - 14% - 14% - 14% - 14% - 15% - 17% - 17% - 18% - 18% - 19% - 19% - 20% - 20% - 23% - 24% - 24% - 24% - 24% - 28% - 29% - 29% - 29% - 29% - 29% - 29% - 30% - 30% - 30% - 31% - 31% - 35% - 35% - 36% - 39% - 39% - 40% - 40% - 41% - 43% - 44% - 46% - 51% - 51% - 52% - 54% - 54% - 55% - 56% - 56% - 57% - 59% - 60% - 62% - 64% - 65% - 65% - 66% - 67% - 68% - 69% - 72% - 72% - 72% - 73% - 74% - 74% - 75% - 75% - 75% - 77% - 77% - 77% - 78% - 78% - 78% - 78% - 78% - 78% - 79% - 81% - 82% - 84% - 84% - 86% - 87% - 90% - 90% - 90% - 91% - 92% - 93% - 93% - 94% - 96% - 98% - 98% - 98% - 99% - 99% - 99% - 100% (68s) - loss: 0.8767\n",
      "Epoch 6 - 100% 1% - 1% - 1% - 1% - 2% - 2% - 3% - 3% - 3% - 4% - 5% - 5% - 6% - 6% - 6% - 7% - 8% - 8% - 9% - 9% - 9% - 10% - 11% - 11% - 11% - 15% - 16% - 16% - 16% - 17% - 18% - 20% - 21% - 22% - 22% - 24% - 25% - 27% - 28% - 29% - 35% - 37% - 38% - 41% - 42% - 44% - 45% - 45% - 45% - 45% - 46% - 47% - 49% - 49% - 53% - 53% - 54% - 55% - 55% - 55% - 55% - 57% - 57% - 57% - 58% - 61% - 61% - 63% - 64% - 65% - 65% - 68% - 69% - 69% - 69% - 69% - 71% - 72% - 72% - 72% - 74% - 74% - 75% - 75% - 75% - 75% - 75% - 75% - 75% - 77% - 77% - 77% - 77% - 80% - 80% - 80% - 81% - 84% - 86% - 87% - 87% - 87% - 87% - 87% - 89% - 89% - 89% - 90% - 91% - 92% - 92% - 93% - 94% - 95% - 95% - 95% - 96% - 96% - 96% - 96% - 96% - 96% - 96% - 96% - 96% - 98% - 98% - 99% - 100% - 100% (68s) - loss: 0.8416\n",
      "Epoch 7 - 100% 0% - 2% - 2% - 6% - 8% - 9% - 9% - 11% - 11% - 11% - 15% - 15% - 16% - 16% - 16% - 17% - 18% - 20% - 20% - 20% - 20% - 21% - 23% - 27% - 27% - 27% - 33% - 33% - 33% - 33% - 34% - 35% - 36% - 39% - 40% - 40% - 41% - 41% - 42% - 43% - 43% - 44% - 44% - 45% - 45% - 45% - 45% - 45% - 46% - 46% - 46% - 50% - 51% - 54% - 54% - 54% - 56% - 56% - 56% - 57% - 57% - 57% - 57% - 57% - 57% - 57% - 57% - 57% - 59% - 59% - 60% - 60% - 60% - 60% - 61% - 65% - 65% - 66% - 66% - 66% - 67% - 67% - 68% - 75% - 75% - 76% - 76% - 76% - 77% - 79% - 82% - 83% - 83% - 83% - 83% - 86% - 86% - 87% - 89% - 89% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 96% - 96% - 96% - 97% - 98% - 98% - 98% - 98% - 98% - 99% - 99% - 99% (69s) - loss: 0.8193\n",
      "Epoch 8 - 100% 0% - 2% - 2% - 3% - 9% - 9% - 9% - 14% - 14% - 15% - 16% - 17% - 17% - 19% - 19% - 21% - 22% - 22% - 22% - 22% - 22% - 23% - 23% - 23% - 24% - 25% - 25% - 25% - 25% - 26% - 27% - 27% - 27% - 27% - 27% - 27% - 27% - 28% - 28% - 28% - 28% - 28% - 29% - 36% - 36% - 36% - 37% - 39% - 39% - 40% - 40% - 40% - 40% - 40% - 41% - 41% - 41% - 42% - 42% - 42% - 43% - 44% - 45% - 45% - 46% - 47% - 47% - 47% - 47% - 54% - 56% - 57% - 57% - 58% - 59% - 59% - 59% - 59% - 60% - 61% - 61% - 61% - 61% - 61% - 61% - 61% - 62% - 63% - 63% - 65% - 66% - 66% - 68% - 69% - 69% - 70% - 71% - 73% - 74% - 75% - 75% - 75% - 78% - 78% - 78% - 78% - 81% - 81% - 82% - 82% - 88% - 88% - 88% - 88% - 88% - 89% - 89% - 89% - 89% - 89% - 91% - 93% - 94% - 95% - 95% - 98% (68s) - loss: 0.8009\n",
      "Epoch 9 - 100% 3% - 3% - 3% - 3% - 3% - 4% - 4% - 5% - 5% - 5% - 5% - 6% - 7% - 7% - 7% - 8% - 8% - 9% - 9% - 10% - 10% - 11% - 11% - 12% - 12% - 12% - 13% - 14% - 14% - 15% - 16% - 16% - 16% - 17% - 18% - 19% - 19% - 19% - 22% - 23% - 23% - 24% - 25% - 26% - 27% - 28% - 28% - 28% - 28% - 29% - 29% - 32% - 33% - 34% - 37% - 37% - 37% - 37% - 37% - 38% - 39% - 39% - 41% - 42% - 43% - 44% - 44% - 46% - 46% - 47% - 47% - 47% - 47% - 48% - 52% - 55% - 55% - 57% - 59% - 59% - 59% - 60% - 60% - 61% - 64% - 65% - 68% - 69% - 69% - 69% - 69% - 69% - 70% - 70% - 74% - 79% - 79% - 79% - 82% - 83% - 83% - 83% - 83% - 85% - 86% - 87% - 87% - 88% - 88% - 89% - 89% - 90% - 91% - 91% - 91% - 92% - 92% - 93% - 93% - 93% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 96% - 98% - 98% - 99% (68s) - loss: 0.7888\n",
      "Epoch 10 - 100% 1% - 1% - 1% - 1% - 2% - 2% - 2% - 2% - 3% - 8% - 8% - 9% - 9% - 9% - 10% - 11% - 11% - 13% - 13% - 14% - 14% - 15% - 15% - 15% - 16% - 16% - 17% - 18% - 18% - 19% - 20% - 21% - 24% - 24% - 24% - 24% - 26% - 26% - 27% - 28% - 28% - 28% - 31% - 31% - 32% - 32% - 33% - 33% - 35% - 35% - 36% - 36% - 36% - 36% - 38% - 38% - 39% - 40% - 40% - 44% - 44% - 44% - 47% - 47% - 48% - 51% - 51% - 52% - 53% - 53% - 53% - 53% - 54% - 54% - 54% - 54% - 55% - 55% - 56% - 56% - 57% - 58% - 58% - 59% - 59% - 59% - 60% - 60% - 60% - 63% - 63% - 64% - 65% - 67% - 67% - 69% - 69% - 69% - 71% - 72% - 73% - 73% - 74% - 74% - 74% - 74% - 75% - 75% - 75% - 77% - 77% - 77% - 77% - 77% - 78% - 78% - 79% - 79% - 81% - 81% - 81% - 81% - 83% - 83% - 83% - 83% - 83% - 83% - 85% - 85% - 86% - 89% - 89% - 92% - 93% - 93% - 93% - 96% - 97% - 98% - 98% - 99% (69s) - loss: 0.7799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - 100% 3% - 5% - 6% - 7% - 8% - 8% - 10% - 11% - 12% - 12% - 12% - 13% - 13% - 16% - 16% - 16% - 17% - 18% - 19% - 19% - 19% - 20% - 21% - 21% - 21% - 22% - 23% - 24% - 26% - 26% - 28% - 28% - 28% - 28% - 29% - 30% - 30% - 30% - 32% - 37% - 37% - 38% - 38% - 39% - 39% - 39% - 39% - 39% - 40% - 41% - 41% - 41% - 42% - 42% - 42% - 43% - 43% - 43% - 43% - 43% - 44% - 44% - 45% - 45% - 45% - 46% - 47% - 49% - 50% - 50% - 54% - 55% - 59% - 59% - 60% - 60% - 63% - 63% - 64% - 64% - 65% - 65% - 65% - 66% - 66% - 69% - 70% - 70% - 70% - 71% - 71% - 72% - 72% - 74% - 74% - 75% - 76% - 78% - 78% - 79% - 80% - 80% - 81% - 82% - 83% - 83% - 83% - 83% - 87% - 88% - 88% - 89% - 90% - 91% - 91% - 91% - 92% - 92% - 92% - 96% - 97% - 98% - 98% - 98% - 98% - 98% - 98% - 98% (68s) - loss: 0.7713\n",
      "Epoch 12 - 100% 1% - 2% - 3% - 3% - 3% - 6% - 7% - 8% - 8% - 9% - 11% - 11% - 12% - 13% - 13% - 13% - 15% - 15% - 16% - 16% - 17% - 20% - 21% - 21% - 21% - 22% - 22% - 22% - 23% - 26% - 33% - 33% - 35% - 37% - 37% - 41% - 41% - 41% - 42% - 42% - 43% - 43% - 50% - 50% - 51% - 52% - 52% - 53% - 53% - 53% - 54% - 54% - 54% - 54% - 57% - 57% - 57% - 57% - 58% - 60% - 61% - 65% - 65% - 66% - 66% - 67% - 67% - 68% - 69% - 71% - 71% - 71% - 71% - 71% - 71% - 71% - 72% - 73% - 75% - 75% - 78% - 78% - 78% - 78% - 78% - 83% - 83% - 83% - 85% - 86% - 87% - 87% - 89% - 90% - 90% - 91% - 91% - 91% - 92% - 97% - 99% - 99% (68s) - loss: 0.7652\n",
      "Epoch 13 - 100% 1% - 1% - 3% - 4% - 4% - 6% - 6% - 6% - 8% - 8% - 9% - 9% - 9% - 9% - 12% - 12% - 12% - 15% - 15% - 15% - 17% - 18% - 18% - 19% - 19% - 20% - 20% - 21% - 21% - 21% - 24% - 24% - 25% - 26% - 27% - 27% - 27% - 30% - 31% - 34% - 34% - 34% - 34% - 36% - 38% - 42% - 42% - 42% - 43% - 43% - 44% - 44% - 44% - 44% - 44% - 45% - 46% - 47% - 48% - 48% - 49% - 49% - 49% - 49% - 50% - 52% - 53% - 53% - 53% - 54% - 55% - 55% - 55% - 55% - 56% - 56% - 56% - 57% - 57% - 57% - 57% - 58% - 59% - 59% - 62% - 62% - 63% - 64% - 64% - 65% - 65% - 65% - 67% - 67% - 68% - 68% - 68% - 69% - 71% - 71% - 73% - 73% - 74% - 77% - 77% - 78% - 79% - 80% - 81% - 81% - 82% - 82% - 89% - 90% - 90% - 91% - 91% - 91% - 91% - 91% - 91% - 91% - 93% - 93% - 94% - 95% - 95% - 96% - 96% - 97% - 97% - 98% - 99% - 100% - 100% - 100% (68s) - loss: 0.7587\n",
      "Epoch 14 - 100% 0% - 1% - 2% - 2% - 4% - 6% - 7% - 7% - 8% - 10% - 10% - 11% - 11% - 11% - 11% - 15% - 15% - 18% - 19% - 19% - 23% - 24% - 25% - 25% - 25% - 25% - 25% - 28% - 31% - 31% - 32% - 32% - 33% - 35% - 37% - 39% - 39% - 41% - 42% - 43% - 43% - 44% - 44% - 44% - 52% - 52% - 53% - 53% - 54% - 54% - 55% - 55% - 55% - 55% - 55% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 57% - 57% - 57% - 58% - 58% - 58% - 59% - 60% - 65% - 66% - 66% - 66% - 69% - 70% - 71% - 72% - 73% - 73% - 74% - 74% - 74% - 75% - 79% - 79% - 79% - 79% - 80% - 80% - 81% - 86% - 86% - 87% - 87% - 90% - 91% - 92% - 92% - 96% - 96% - 96% - 96% - 97% - 97% - 97% - 97% - 97% - 97% - 97% - 97% - 98% (68s) - loss: 0.7551\n",
      "Epoch 15 - 100% 2% - 2% - 2% - 2% - 2% - 4% - 4% - 4% - 5% - 6% - 7% - 7% - 8% - 9% - 9% - 12% - 13% - 15% - 15% - 15% - 16% - 16% - 16% - 16% - 17% - 18% - 18% - 18% - 21% - 21% - 25% - 25% - 25% - 25% - 26% - 29% - 30% - 32% - 33% - 33% - 33% - 34% - 35% - 36% - 36% - 36% - 37% - 37% - 41% - 41% - 42% - 43% - 43% - 45% - 45% - 48% - 49% - 49% - 53% - 54% - 56% - 56% - 56% - 56% - 58% - 58% - 59% - 59% - 59% - 60% - 60% - 60% - 61% - 62% - 63% - 65% - 66% - 66% - 66% - 67% - 70% - 72% - 73% - 73% - 75% - 77% - 78% - 79% - 79% - 79% - 80% - 80% - 82% - 82% - 83% - 83% - 83% - 84% - 87% - 88% - 88% - 89% - 90% - 90% - 90% - 91% - 92% - 94% - 94% - 95% - 96% - 97% - 98% - 99% - 99% - 99% - 100% (69s) - loss: 0.7486\n",
      "Epoch 16 - 100% 3% - 5% - 5% - 5% - 6% - 7% - 8% - 8% - 8% - 8% - 11% - 12% - 12% - 12% - 13% - 15% - 15% - 15% - 15% - 15% - 15% - 16% - 16% - 16% - 17% - 19% - 19% - 19% - 20% - 23% - 28% - 30% - 30% - 35% - 35% - 35% - 39% - 40% - 40% - 43% - 44% - 45% - 45% - 48% - 48% - 49% - 50% - 51% - 51% - 52% - 52% - 53% - 56% - 56% - 57% - 57% - 57% - 57% - 58% - 58% - 58% - 58% - 59% - 59% - 59% - 60% - 60% - 61% - 64% - 65% - 65% - 65% - 65% - 66% - 67% - 69% - 69% - 70% - 71% - 74% - 74% - 74% - 75% - 77% - 77% - 77% - 78% - 78% - 78% - 80% - 80% - 81% - 83% - 84% - 84% - 84% - 84% - 85% - 89% - 94% - 96% - 96% - 97% (68s) - loss: 0.7482\n",
      "Epoch 17 - 100% 1% - 2% - 3% - 3% - 4% - 4% - 5% - 5% - 7% - 7% - 7% - 8% - 8% - 11% - 12% - 12% - 12% - 13% - 15% - 15% - 15% - 15% - 15% - 18% - 19% - 19% - 20% - 21% - 21% - 22% - 25% - 30% - 30% - 30% - 32% - 32% - 33% - 34% - 34% - 34% - 34% - 34% - 34% - 34% - 35% - 36% - 36% - 36% - 37% - 37% - 38% - 38% - 38% - 38% - 38% - 38% - 39% - 39% - 39% - 40% - 40% - 40% - 42% - 42% - 42% - 43% - 43% - 44% - 45% - 47% - 47% - 48% - 50% - 53% - 54% - 54% - 54% - 54% - 55% - 55% - 57% - 58% - 59% - 59% - 59% - 60% - 61% - 61% - 67% - 70% - 74% - 74% - 75% - 76% - 76% - 76% - 78% - 79% - 79% - 79% - 82% - 86% - 86% - 90% - 90% - 90% - 90% - 90% - 90% - 90% - 91% - 91% - 91% - 92% - 93% - 93% - 93% - 99% - 100% (68s) - loss: 0.7427\n",
      "Epoch 18 - 100% 0% - 0% - 0% - 1% - 1% - 2% - 3% - 6% - 7% - 8% - 10% - 11% - 13% - 13% - 13% - 14% - 14% - 15% - 16% - 16% - 16% - 17% - 18% - 19% - 20% - 21% - 21% - 22% - 22% - 23% - 23% - 23% - 26% - 26% - 28% - 29% - 29% - 30% - 32% - 33% - 35% - 37% - 37% - 37% - 37% - 38% - 40% - 40% - 41% - 42% - 42% - 42% - 45% - 45% - 46% - 46% - 47% - 47% - 47% - 47% - 49% - 49% - 50% - 50% - 50% - 53% - 53% - 53% - 54% - 55% - 56% - 57% - 57% - 58% - 59% - 60% - 61% - 61% - 66% - 67% - 72% - 73% - 73% - 73% - 73% - 75% - 75% - 75% - 76% - 76% - 77% - 77% - 77% - 79% - 81% - 82% - 82% - 82% - 83% - 83% - 83% - 85% - 85% - 85% - 85% - 85% - 86% - 87% - 87% - 88% - 88% - 88% - 89% - 89% - 89% - 90% - 92% - 94% - 95% - 98% (68s) - loss: 0.7394\n",
      "Epoch 19 - 100% 0% - 2% - 2% - 2% - 2% - 2% - 2% - 5% - 5% - 5% - 6% - 6% - 6% - 6% - 6% - 6% - 6% - 7% - 11% - 13% - 14% - 15% - 15% - 15% - 16% - 16% - 16% - 17% - 17% - 17% - 18% - 18% - 18% - 18% - 18% - 22% - 22% - 22% - 23% - 24% - 28% - 28% - 31% - 31% - 32% - 32% - 32% - 33% - 33% - 33% - 33% - 34% - 34% - 35% - 43% - 44% - 46% - 51% - 54% - 55% - 55% - 55% - 55% - 57% - 58% - 58% - 58% - 59% - 59% - 59% - 59% - 63% - 63% - 63% - 63% - 66% - 69% - 70% - 70% - 71% - 77% - 77% - 78% - 81% - 82% - 82% - 88% - 90% - 91% - 91% - 91% - 91% - 91% - 91% - 91% - 91% - 93% - 94% - 94% - 95% - 95% - 95% (68s) - loss: 0.7358\n",
      "Epoch 20 - 100% 2% - 2% - 2% - 2% - 2% - 5% - 5% - 5% - 7% - 7% - 7% - 10% - 10% - 11% - 11% - 12% - 15% - 20% - 20% - 20% - 21% - 24% - 24% - 25% - 26% - 27% - 27% - 27% - 28% - 28% - 29% - 29% - 32% - 35% - 36% - 38% - 38% - 38% - 38% - 38% - 39% - 39% - 41% - 43% - 43% - 44% - 44% - 44% - 44% - 44% - 45% - 45% - 45% - 46% - 47% - 48% - 48% - 48% - 48% - 48% - 48% - 52% - 52% - 53% - 54% - 54% - 54% - 56% - 56% - 56% - 56% - 57% - 57% - 57% - 57% - 59% - 60% - 61% - 65% - 65% - 65% - 68% - 69% - 70% - 70% - 70% - 70% - 70% - 73% - 74% - 74% - 74% - 75% - 76% - 76% - 76% - 77% - 78% - 80% - 80% - 80% - 80% - 80% - 81% - 81% - 81% - 81% - 81% - 85% - 88% - 88% - 88% - 88% - 89% - 91% - 94% - 94% - 95% - 96% - 97% - 97% - 97% - 98% - 99% - 99% (69s) - loss: 0.7346\n",
      "Epoch 21 - 100% 1% - 1% - 1% - 1% - 1% - 2% - 2% - 2% - 3% - 4% - 5% - 7% - 8% - 8% - 8% - 8% - 8% - 9% - 10% - 10% - 11% - 11% - 12% - 12% - 13% - 13% - 14% - 14% - 15% - 19% - 20% - 23% - 23% - 23% - 23% - 29% - 30% - 31% - 31% - 33% - 33% - 33% - 34% - 34% - 34% - 34% - 34% - 35% - 35% - 35% - 39% - 39% - 39% - 39% - 42% - 42% - 42% - 43% - 44% - 44% - 46% - 47% - 47% - 47% - 47% - 47% - 47% - 47% - 47% - 51% - 52% - 54% - 54% - 54% - 54% - 56% - 57% - 57% - 57% - 57% - 59% - 59% - 60% - 61% - 66% - 66% - 66% - 67% - 70% - 73% - 74% - 74% - 76% - 76% - 76% - 78% - 81% - 81% - 82% - 82% - 83% - 83% - 83% - 83% - 85% - 86% - 90% - 90% - 91% - 92% - 92% - 93% - 93% - 93% - 93% - 96% - 97% - 100% (69s) - loss: 0.7316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - 100% 0% - 0% - 0% - 2% - 2% - 4% - 4% - 5% - 6% - 6% - 7% - 7% - 7% - 7% - 8% - 11% - 12% - 13% - 14% - 14% - 15% - 15% - 16% - 16% - 16% - 17% - 19% - 19% - 20% - 23% - 23% - 24% - 24% - 25% - 26% - 26% - 27% - 27% - 28% - 28% - 30% - 30% - 33% - 33% - 33% - 33% - 34% - 34% - 35% - 37% - 38% - 42% - 44% - 48% - 48% - 49% - 49% - 50% - 50% - 50% - 51% - 53% - 55% - 56% - 56% - 57% - 57% - 58% - 59% - 59% - 59% - 61% - 61% - 62% - 62% - 62% - 62% - 63% - 64% - 65% - 66% - 67% - 68% - 68% - 69% - 70% - 71% - 72% - 75% - 75% - 77% - 79% - 79% - 80% - 82% - 82% - 82% - 82% - 82% - 83% - 83% - 83% - 84% - 87% - 89% - 90% - 90% - 90% - 91% - 94% - 94% - 96% - 97% - 97% - 98% - 98% - 99% - 99% - 100% (69s) - loss: 0.7305\n",
      "Epoch 23 - 100% 1% - 3% - 4% - 4% - 4% - 4% - 4% - 5% - 5% - 7% - 8% - 8% - 10% - 10% - 15% - 16% - 16% - 16% - 17% - 17% - 17% - 17% - 22% - 22% - 23% - 26% - 26% - 27% - 27% - 28% - 30% - 30% - 30% - 30% - 30% - 30% - 31% - 34% - 34% - 34% - 39% - 40% - 41% - 42% - 42% - 43% - 45% - 45% - 45% - 47% - 48% - 48% - 50% - 50% - 50% - 51% - 52% - 52% - 52% - 52% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 57% - 57% - 57% - 57% - 57% - 59% - 59% - 59% - 59% - 62% - 63% - 63% - 65% - 67% - 68% - 68% - 72% - 72% - 73% - 73% - 73% - 75% - 75% - 76% - 76% - 76% - 76% - 77% - 77% - 77% - 80% - 80% - 82% - 84% - 85% - 86% - 87% - 88% - 90% - 91% - 91% - 93% - 93% - 95% - 96% - 96% - 98% - 98% - 99% - 100% - 100% (69s) - loss: 0.7251\n",
      "Epoch 24 - 100% 0% - 1% - 1% - 2% - 3% - 6% - 6% - 6% - 6% - 6% - 8% - 9% - 9% - 10% - 12% - 12% - 12% - 12% - 14% - 14% - 14% - 14% - 16% - 17% - 18% - 19% - 25% - 25% - 29% - 30% - 30% - 31% - 31% - 31% - 34% - 34% - 36% - 37% - 37% - 38% - 38% - 38% - 38% - 38% - 40% - 40% - 40% - 41% - 42% - 42% - 44% - 44% - 44% - 44% - 45% - 46% - 46% - 47% - 48% - 49% - 50% - 50% - 50% - 52% - 52% - 52% - 52% - 52% - 52% - 53% - 53% - 53% - 54% - 56% - 57% - 57% - 60% - 65% - 66% - 67% - 69% - 71% - 71% - 71% - 72% - 73% - 73% - 74% - 78% - 78% - 78% - 78% - 79% - 80% - 80% - 80% - 80% - 83% - 86% - 86% - 89% - 90% - 90% - 91% - 91% - 91% - 94% - 94% - 96% - 96% - 98% - 98% - 98% - 99% - 99% (68s) - loss: 0.7243\n",
      "Epoch 25 - 100% 1% - 4% - 5% - 5% - 5% - 8% - 8% - 9% - 9% - 11% - 11% - 11% - 11% - 12% - 13% - 13% - 17% - 19% - 21% - 25% - 26% - 27% - 27% - 27% - 29% - 29% - 32% - 33% - 38% - 38% - 38% - 39% - 42% - 43% - 47% - 48% - 49% - 51% - 51% - 51% - 52% - 54% - 56% - 58% - 58% - 59% - 62% - 62% - 62% - 62% - 63% - 64% - 64% - 64% - 66% - 67% - 68% - 68% - 71% - 73% - 73% - 73% - 73% - 73% - 75% - 75% - 76% - 78% - 79% - 81% - 81% - 83% - 84% - 84% - 86% - 86% - 90% - 91% - 96% - 96% - 97% (69s) - loss: 0.7213\n",
      "Epoch 26 - 100% 1% - 1% - 1% - 2% - 2% - 3% - 3% - 3% - 3% - 3% - 4% - 4% - 4% - 4% - 4% - 5% - 5% - 5% - 6% - 6% - 7% - 8% - 8% - 8% - 9% - 9% - 9% - 10% - 11% - 13% - 13% - 13% - 14% - 14% - 15% - 15% - 15% - 16% - 16% - 16% - 16% - 17% - 18% - 18% - 18% - 19% - 19% - 20% - 21% - 22% - 22% - 22% - 23% - 23% - 24% - 24% - 26% - 27% - 27% - 28% - 29% - 29% - 29% - 29% - 30% - 30% - 30% - 30% - 30% - 30% - 30% - 34% - 35% - 35% - 35% - 35% - 35% - 37% - 40% - 40% - 41% - 41% - 42% - 44% - 44% - 44% - 45% - 45% - 46% - 46% - 46% - 47% - 48% - 48% - 50% - 51% - 52% - 56% - 56% - 57% - 57% - 57% - 58% - 60% - 64% - 65% - 65% - 65% - 66% - 68% - 68% - 72% - 73% - 73% - 76% - 77% - 80% - 81% - 82% - 83% - 85% - 86% - 86% - 86% - 86% - 89% - 89% - 90% - 91% - 93% - 93% - 97% - 99% (68s) - loss: 0.7207\n",
      "Epoch 27 - 100% 2% - 2% - 2% - 5% - 7% - 7% - 7% - 8% - 8% - 10% - 12% - 12% - 12% - 12% - 12% - 12% - 13% - 13% - 13% - 13% - 14% - 14% - 15% - 15% - 15% - 16% - 18% - 18% - 18% - 19% - 20% - 20% - 21% - 25% - 25% - 25% - 26% - 28% - 28% - 29% - 29% - 30% - 31% - 32% - 33% - 33% - 34% - 35% - 36% - 38% - 39% - 39% - 40% - 40% - 42% - 43% - 43% - 44% - 44% - 45% - 46% - 48% - 48% - 49% - 50% - 50% - 50% - 50% - 50% - 53% - 53% - 54% - 58% - 58% - 59% - 59% - 60% - 61% - 61% - 61% - 63% - 65% - 66% - 66% - 67% - 69% - 69% - 70% - 71% - 72% - 75% - 78% - 78% - 79% - 81% - 81% - 84% - 84% - 84% - 84% - 85% - 85% - 86% - 90% - 92% - 92% - 92% - 92% - 96% - 98% - 99% (68s) - loss: 0.7210\n",
      "Epoch 28 - 100% 1% - 1% - 1% - 1% - 1% - 2% - 2% - 2% - 2% - 4% - 5% - 6% - 7% - 8% - 8% - 8% - 8% - 14% - 14% - 14% - 15% - 22% - 22% - 22% - 22% - 22% - 26% - 27% - 28% - 30% - 30% - 31% - 31% - 32% - 32% - 34% - 36% - 37% - 37% - 39% - 43% - 44% - 44% - 44% - 45% - 46% - 47% - 47% - 50% - 55% - 57% - 59% - 60% - 61% - 61% - 61% - 61% - 62% - 62% - 62% - 64% - 68% - 70% - 74% - 75% - 75% - 76% - 79% - 81% - 82% - 84% - 85% - 86% - 86% - 86% - 86% - 87% - 92% - 92% - 92% - 92% - 93% - 93% - 94% - 94% - 97% - 97% - 97% - 97% - 98% - 98% - 98% - 98% - 99% - 99% (69s) - loss: 0.7190\n",
      "Epoch 29 - 100% 2% - 4% - 5% - 6% - 6% - 6% - 7% - 8% - 11% - 11% - 11% - 11% - 11% - 13% - 15% - 15% - 16% - 18% - 20% - 22% - 23% - 23% - 23% - 23% - 24% - 24% - 26% - 26% - 28% - 28% - 29% - 30% - 30% - 30% - 30% - 33% - 34% - 34% - 34% - 35% - 35% - 35% - 37% - 38% - 38% - 38% - 38% - 38% - 38% - 38% - 38% - 39% - 40% - 40% - 41% - 43% - 44% - 45% - 45% - 45% - 45% - 46% - 46% - 47% - 47% - 47% - 48% - 48% - 50% - 51% - 52% - 54% - 55% - 57% - 57% - 58% - 58% - 60% - 61% - 62% - 63% - 63% - 63% - 64% - 64% - 64% - 65% - 66% - 66% - 67% - 69% - 69% - 69% - 70% - 70% - 70% - 71% - 73% - 73% - 73% - 73% - 73% - 74% - 75% - 75% - 76% - 77% - 77% - 77% - 77% - 79% - 80% - 80% - 80% - 82% - 83% - 83% - 83% - 85% - 88% - 89% - 89% - 92% - 94% - 95% - 95% - 95% - 95% - 95% - 97% - 99% - 99% - 99% - 99% - 100% (68s) - loss: 0.7165\n",
      "Epoch 30 - 100% 1% - 2% - 3% - 3% - 3% - 4% - 5% - 14% - 14% - 15% - 16% - 18% - 18% - 18% - 20% - 21% - 21% - 22% - 23% - 27% - 30% - 31% - 33% - 35% - 35% - 36% - 36% - 36% - 37% - 37% - 37% - 38% - 42% - 42% - 42% - 43% - 46% - 46% - 49% - 49% - 51% - 52% - 54% - 54% - 56% - 56% - 56% - 57% - 57% - 62% - 63% - 63% - 63% - 63% - 63% - 63% - 66% - 66% - 70% - 71% - 72% - 72% - 73% - 73% - 73% - 75% - 76% - 77% - 78% - 80% - 82% - 82% - 82% - 82% - 83% - 83% - 83% - 83% - 86% - 87% - 87% - 89% - 89% - 90% - 91% - 91% - 91% - 91% - 93% - 94% - 94% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 95% - 100% (68s) - loss: 0.7159\n",
      "Epoch 31 - 100% 2% - 3% - 3% - 4% - 4% - 5% - 5% - 5% - 5% - 5% - 6% - 10% - 10% - 11% - 11% - 11% - 12% - 15% - 15% - 15% - 15% - 16% - 16% - 17% - 18% - 18% - 18% - 21% - 22% - 22% - 24% - 26% - 26% - 26% - 27% - 27% - 30% - 32% - 37% - 37% - 39% - 39% - 40% - 40% - 40% - 40% - 45% - 45% - 49% - 49% - 49% - 50% - 50% - 54% - 56% - 57% - 57% - 59% - 62% - 63% - 64% - 64% - 64% - 65% - 65% - 66% - 66% - 68% - 68% - 69% - 70% - 70% - 70% - 70% - 70% - 71% - 71% - 72% - 74% - 75% - 77% - 77% - 77% - 79% - 80% - 82% - 82% - 83% - 83% - 83% - 85% - 87% - 89% - 89% - 91% - 91% - 93% - 93% - 95% - 95% - 96% - 96% - 98% - 98% (68s) - loss: 0.7142\n",
      "Epoch 32 - 100% 1% - 2% - 3% - 3% - 4% - 4% - 6% - 7% - 8% - 11% - 11% - 11% - 12% - 12% - 14% - 15% - 18% - 19% - 19% - 20% - 22% - 23% - 24% - 24% - 24% - 25% - 25% - 26% - 27% - 28% - 29% - 29% - 32% - 32% - 32% - 33% - 33% - 37% - 38% - 39% - 42% - 42% - 43% - 43% - 45% - 47% - 51% - 51% - 51% - 52% - 52% - 53% - 53% - 55% - 55% - 57% - 57% - 58% - 58% - 62% - 62% - 62% - 62% - 64% - 65% - 65% - 65% - 65% - 66% - 66% - 67% - 68% - 68% - 68% - 68% - 68% - 70% - 70% - 70% - 71% - 71% - 71% - 71% - 72% - 74% - 75% - 75% - 76% - 76% - 77% - 78% - 79% - 80% - 81% - 81% - 83% - 84% - 86% - 87% - 87% - 88% - 88% - 88% - 88% - 89% - 89% - 94% - 97% - 97% - 97% (68s) - loss: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 - 100% 1% - 1% - 4% - 5% - 5% - 5% - 7% - 7% - 8% - 10% - 11% - 12% - 13% - 13% - 14% - 14% - 14% - 16% - 16% - 22% - 22% - 22% - 23% - 26% - 26% - 27% - 27% - 27% - 27% - 29% - 29% - 30% - 34% - 34% - 34% - 35% - 36% - 37% - 38% - 38% - 40% - 40% - 42% - 42% - 42% - 45% - 46% - 47% - 47% - 47% - 48% - 48% - 48% - 48% - 48% - 48% - 48% - 49% - 50% - 50% - 53% - 57% - 57% - 59% - 61% - 61% - 62% - 63% - 67% - 67% - 67% - 68% - 69% - 71% - 72% - 73% - 73% - 74% - 74% - 74% - 75% - 75% - 75% - 75% - 75% - 77% - 77% - 77% - 78% - 80% - 80% - 81% - 81% - 81% - 84% - 85% - 86% - 87% - 87% - 87% - 89% - 90% - 90% - 90% - 90% - 91% - 91% - 91% - 91% - 91% - 92% - 93% - 93% - 96% - 96% - 97% - 99% - 99% - 100% (69s) - loss: 0.7129\n",
      "Epoch 34 - 100% 2% - 3% - 3% - 3% - 3% - 5% - 5% - 5% - 5% - 9% - 10% - 10% - 10% - 10% - 10% - 11% - 11% - 11% - 11% - 12% - 13% - 13% - 15% - 15% - 16% - 16% - 16% - 16% - 18% - 18% - 21% - 21% - 21% - 21% - 21% - 21% - 22% - 24% - 25% - 25% - 26% - 28% - 28% - 29% - 30% - 31% - 31% - 33% - 35% - 38% - 39% - 39% - 39% - 39% - 39% - 39% - 39% - 40% - 40% - 40% - 41% - 42% - 42% - 45% - 46% - 49% - 52% - 52% - 53% - 58% - 58% - 62% - 62% - 63% - 63% - 63% - 64% - 64% - 66% - 67% - 67% - 70% - 71% - 72% - 74% - 74% - 75% - 76% - 76% - 76% - 76% - 77% - 77% - 78% - 81% - 84% - 85% - 86% - 86% - 87% - 88% - 88% - 88% - 88% - 94% - 95% - 95% - 97% - 98% (68s) - loss: 0.7107\n",
      "Epoch 35 - 100% 1% - 1% - 6% - 7% - 7% - 7% - 7% - 9% - 10% - 10% - 15% - 15% - 15% - 15% - 15% - 15% - 21% - 21% - 22% - 23% - 26% - 26% - 28% - 29% - 30% - 30% - 31% - 31% - 31% - 35% - 35% - 36% - 37% - 39% - 39% - 42% - 42% - 44% - 44% - 44% - 45% - 48% - 48% - 48% - 52% - 52% - 52% - 53% - 54% - 54% - 57% - 58% - 59% - 59% - 59% - 61% - 61% - 62% - 62% - 67% - 67% - 67% - 70% - 71% - 71% - 72% - 72% - 75% - 76% - 76% - 76% - 77% - 77% - 77% - 78% - 78% - 78% - 80% - 81% - 81% - 83% - 83% - 83% - 83% - 83% - 83% - 85% - 85% - 85% - 85% - 86% - 86% - 86% - 87% - 88% - 88% - 89% - 89% - 90% - 90% - 90% - 93% - 93% - 94% - 95% - 96% - 98% - 98% - 99% (68s) - loss: 0.7085\n",
      "Epoch 36 - 100% 0% - 0% - 2% - 4% - 8% - 8% - 9% - 11% - 11% - 11% - 12% - 13% - 13% - 16% - 17% - 20% - 20% - 21% - 21% - 21% - 22% - 22% - 22% - 22% - 22% - 22% - 24% - 24% - 26% - 26% - 26% - 27% - 28% - 28% - 33% - 33% - 34% - 34% - 34% - 34% - 34% - 35% - 35% - 35% - 37% - 37% - 38% - 39% - 39% - 40% - 40% - 40% - 41% - 41% - 45% - 45% - 48% - 48% - 49% - 49% - 49% - 49% - 49% - 50% - 54% - 58% - 59% - 59% - 59% - 59% - 59% - 59% - 59% - 59% - 59% - 59% - 60% - 60% - 61% - 61% - 61% - 61% - 61% - 61% - 61% - 63% - 64% - 64% - 65% - 65% - 67% - 71% - 72% - 74% - 75% - 75% - 76% - 76% - 79% - 79% - 79% - 79% - 79% - 80% - 82% - 83% - 83% - 86% - 86% - 86% - 87% - 87% - 88% - 89% - 89% - 90% - 90% - 93% - 93% - 94% - 94% - 94% - 94% - 95% - 96% - 97% - 97% (68s) - loss: 0.7088\n",
      "Epoch 37 - 100% 1% - 3% - 3% - 4% - 6% - 9% - 9% - 9% - 10% - 10% - 10% - 10% - 10% - 10% - 11% - 11% - 13% - 13% - 13% - 14% - 15% - 15% - 15% - 15% - 15% - 15% - 15% - 15% - 15% - 16% - 17% - 18% - 19% - 19% - 19% - 23% - 26% - 26% - 26% - 27% - 29% - 29% - 29% - 29% - 29% - 29% - 29% - 29% - 29% - 35% - 36% - 36% - 37% - 37% - 38% - 38% - 41% - 43% - 43% - 43% - 43% - 43% - 44% - 46% - 47% - 47% - 47% - 47% - 47% - 47% - 48% - 48% - 49% - 50% - 50% - 51% - 51% - 52% - 52% - 52% - 53% - 53% - 53% - 55% - 56% - 56% - 56% - 57% - 57% - 57% - 58% - 59% - 61% - 61% - 62% - 64% - 65% - 67% - 67% - 67% - 69% - 70% - 70% - 71% - 71% - 71% - 71% - 73% - 73% - 73% - 74% - 74% - 74% - 74% - 76% - 76% - 76% - 76% - 76% - 82% - 82% - 83% - 83% - 84% - 84% - 84% - 86% - 89% - 90% - 91% - 92% - 93% - 96% - 96% - 97% - 97% - 97% - 97% - 98% - 98% - 99% - 100% (69s) - loss: 0.7076\n",
      "Epoch 38 - 100% 0% - 0% - 2% - 2% - 2% - 4% - 5% - 5% - 6% - 6% - 6% - 6% - 7% - 7% - 7% - 9% - 9% - 12% - 12% - 12% - 12% - 12% - 12% - 13% - 13% - 17% - 18% - 18% - 19% - 21% - 21% - 22% - 22% - 22% - 23% - 23% - 24% - 25% - 26% - 28% - 28% - 29% - 30% - 35% - 37% - 39% - 40% - 40% - 40% - 40% - 40% - 40% - 40% - 40% - 41% - 41% - 43% - 44% - 45% - 47% - 47% - 48% - 49% - 51% - 51% - 51% - 51% - 52% - 52% - 54% - 54% - 56% - 58% - 59% - 61% - 63% - 64% - 64% - 64% - 66% - 66% - 67% - 67% - 68% - 69% - 69% - 69% - 70% - 70% - 70% - 70% - 72% - 73% - 74% - 74% - 75% - 77% - 77% - 77% - 77% - 78% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 82% - 82% - 83% - 83% - 85% - 86% - 88% - 89% - 89% - 90% - 90% - 92% - 92% - 92% - 96% - 96% - 98% - 98% (68s) - loss: 0.7066\n",
      "Epoch 39 - 100% 0% - 2% - 4% - 4% - 6% - 6% - 7% - 7% - 7% - 12% - 15% - 17% - 17% - 17% - 17% - 17% - 17% - 18% - 19% - 20% - 21% - 21% - 22% - 24% - 24% - 25% - 25% - 25% - 26% - 27% - 27% - 27% - 28% - 28% - 28% - 28% - 29% - 29% - 29% - 30% - 30% - 30% - 32% - 32% - 33% - 33% - 33% - 35% - 38% - 40% - 40% - 44% - 45% - 46% - 46% - 47% - 48% - 53% - 54% - 54% - 56% - 56% - 57% - 57% - 57% - 57% - 62% - 62% - 64% - 65% - 65% - 65% - 65% - 65% - 66% - 66% - 67% - 68% - 68% - 69% - 70% - 70% - 70% - 71% - 71% - 72% - 72% - 72% - 72% - 72% - 73% - 73% - 76% - 76% - 77% - 78% - 78% - 78% - 79% - 82% - 84% - 85% - 89% - 90% - 90% - 92% - 93% - 95% - 96% - 98% - 99% - 99% - 100% - 100% (68s) - loss: 0.7075\n",
      "Epoch 40 - 100% 0% - 0% - 1% - 1% - 1% - 2% - 2% - 2% - 3% - 4% - 5% - 7% - 7% - 10% - 10% - 11% - 12% - 12% - 13% - 13% - 13% - 13% - 14% - 16% - 16% - 17% - 19% - 20% - 20% - 21% - 21% - 21% - 23% - 23% - 23% - 24% - 24% - 24% - 25% - 25% - 27% - 27% - 27% - 28% - 29% - 29% - 30% - 30% - 30% - 31% - 32% - 32% - 32% - 33% - 36% - 37% - 40% - 40% - 43% - 44% - 45% - 46% - 46% - 46% - 47% - 49% - 49% - 49% - 51% - 54% - 54% - 55% - 55% - 55% - 56% - 56% - 58% - 58% - 58% - 59% - 59% - 62% - 62% - 63% - 65% - 65% - 66% - 66% - 67% - 70% - 71% - 72% - 72% - 72% - 72% - 72% - 72% - 73% - 76% - 76% - 76% - 77% - 77% - 78% - 78% - 79% - 79% - 80% - 80% - 83% - 84% - 84% - 84% - 84% - 85% - 85% - 87% - 88% - 88% - 89% - 89% - 89% - 89% - 90% - 90% - 90% - 91% - 91% - 91% - 91% - 92% - 94% - 95% - 96% - 96% - 96% - 96% - 97% - 99% - 99% - 100% (68s) - loss: 0.7066\n",
      "Epoch 41 - 100% 3% - 3% - 3% - 3% - 3% - 3% - 4% - 4% - 6% - 7% - 8% - 10% - 12% - 13% - 14% - 14% - 17% - 17% - 17% - 19% - 19% - 19% - 22% - 24% - 25% - 25% - 26% - 27% - 27% - 28% - 28% - 28% - 29% - 34% - 34% - 34% - 35% - 35% - 37% - 37% - 38% - 38% - 39% - 39% - 39% - 41% - 42% - 42% - 42% - 44% - 45% - 45% - 46% - 46% - 47% - 49% - 50% - 50% - 50% - 52% - 54% - 55% - 57% - 58% - 58% - 59% - 59% - 61% - 62% - 62% - 64% - 64% - 65% - 65% - 65% - 66% - 67% - 68% - 70% - 70% - 70% - 72% - 72% - 72% - 73% - 74% - 75% - 75% - 75% - 76% - 77% - 78% - 79% - 79% - 81% - 81% - 82% - 82% - 85% - 87% - 87% - 87% - 88% - 91% - 92% - 94% - 95% - 96% - 97% (69s) - loss: 0.7024\n",
      "Epoch 42 - 100% 6% - 6% - 6% - 7% - 7% - 7% - 7% - 7% - 8% - 8% - 11% - 11% - 11% - 12% - 12% - 12% - 12% - 12% - 12% - 14% - 17% - 19% - 19% - 19% - 20% - 20% - 20% - 21% - 22% - 23% - 24% - 27% - 27% - 27% - 27% - 27% - 27% - 29% - 29% - 29% - 29% - 31% - 33% - 33% - 33% - 33% - 34% - 34% - 34% - 34% - 34% - 34% - 35% - 37% - 37% - 37% - 37% - 38% - 40% - 40% - 42% - 44% - 46% - 46% - 47% - 47% - 47% - 48% - 48% - 50% - 51% - 52% - 56% - 57% - 59% - 59% - 62% - 62% - 62% - 62% - 62% - 63% - 63% - 64% - 67% - 68% - 68% - 68% - 69% - 71% - 71% - 72% - 73% - 73% - 75% - 75% - 76% - 78% - 79% - 79% - 79% - 79% - 80% - 80% - 81% - 83% - 87% - 87% - 88% - 88% - 91% - 91% - 92% - 92% - 95% - 95% - 96% - 97% - 97% - 97% - 97% - 97% - 97% - 97% - 97% (69s) - loss: 0.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 - 100% 0% - 0% - 1% - 2% - 3% - 3% - 4% - 4% - 4% - 6% - 6% - 7% - 8% - 8% - 9% - 9% - 10% - 12% - 14% - 14% - 17% - 17% - 17% - 17% - 17% - 18% - 19% - 22% - 23% - 23% - 23% - 24% - 25% - 28% - 29% - 30% - 30% - 31% - 31% - 31% - 31% - 32% - 33% - 33% - 35% - 36% - 36% - 38% - 38% - 40% - 42% - 43% - 43% - 43% - 44% - 44% - 45% - 46% - 46% - 47% - 48% - 48% - 48% - 50% - 50% - 50% - 51% - 52% - 52% - 52% - 52% - 54% - 57% - 58% - 62% - 62% - 63% - 64% - 64% - 64% - 64% - 64% - 67% - 67% - 67% - 68% - 68% - 71% - 72% - 74% - 75% - 76% - 76% - 76% - 77% - 79% - 80% - 81% - 82% - 82% - 86% - 87% - 87% - 88% - 88% - 88% - 89% - 90% - 90% - 91% - 92% - 94% - 95% - 95% - 95% - 95% - 97% - 99% - 99% - 99% (68s) - loss: 0.7038\n",
      "Epoch 44 - 100% 1% - 2% - 4% - 4% - 4% - 5% - 5% - 6% - 6% - 7% - 8% - 8% - 8% - 10% - 11% - 14% - 14% - 16% - 16% - 16% - 16% - 17% - 18% - 18% - 19% - 20% - 20% - 21% - 21% - 23% - 23% - 23% - 31% - 31% - 37% - 39% - 40% - 41% - 42% - 42% - 43% - 43% - 43% - 43% - 43% - 44% - 45% - 45% - 45% - 45% - 46% - 46% - 47% - 48% - 48% - 48% - 48% - 49% - 49% - 49% - 49% - 49% - 50% - 50% - 51% - 52% - 53% - 56% - 57% - 57% - 58% - 58% - 60% - 60% - 60% - 60% - 64% - 66% - 66% - 66% - 67% - 67% - 67% - 67% - 67% - 67% - 69% - 69% - 71% - 74% - 74% - 78% - 78% - 81% - 81% - 81% - 82% - 82% - 82% - 82% - 83% - 83% - 83% - 83% - 84% - 84% - 85% - 85% - 87% - 87% - 87% - 87% - 87% - 90% - 90% - 90% - 94% - 97% - 98% - 98% - 98% - 99% - 99% - 99% - 99% - 99% - 99% (69s) - loss: 0.7000\n",
      "Epoch 45 - 100% 1% - 1% - 1% - 1% - 1% - 3% - 3% - 4% - 4% - 4% - 5% - 7% - 7% - 7% - 7% - 8% - 8% - 9% - 10% - 10% - 10% - 10% - 10% - 10% - 10% - 10% - 10% - 12% - 12% - 14% - 14% - 14% - 15% - 15% - 16% - 18% - 22% - 22% - 23% - 24% - 25% - 25% - 25% - 26% - 26% - 29% - 29% - 29% - 30% - 30% - 30% - 34% - 37% - 37% - 37% - 37% - 37% - 39% - 40% - 41% - 41% - 41% - 41% - 42% - 44% - 45% - 46% - 47% - 47% - 50% - 50% - 51% - 53% - 53% - 53% - 54% - 54% - 54% - 58% - 58% - 59% - 59% - 59% - 60% - 61% - 61% - 62% - 63% - 65% - 68% - 69% - 69% - 69% - 69% - 69% - 69% - 69% - 71% - 71% - 71% - 71% - 72% - 72% - 72% - 72% - 72% - 73% - 75% - 75% - 75% - 75% - 76% - 76% - 77% - 77% - 77% - 77% - 80% - 80% - 80% - 80% - 80% - 81% - 83% - 84% - 85% - 85% - 85% - 87% - 87% - 88% - 88% - 88% - 89% - 90% - 90% - 90% - 91% - 91% - 91% - 92% - 97% - 99% - 100% (68s) - loss: 0.7002\n",
      "Epoch 46 - 100% 1% - 1% - 3% - 4% - 4% - 4% - 4% - 5% - 8% - 10% - 12% - 12% - 12% - 14% - 14% - 17% - 17% - 19% - 19% - 19% - 21% - 21% - 22% - 22% - 22% - 24% - 26% - 27% - 28% - 28% - 29% - 29% - 29% - 34% - 37% - 39% - 39% - 39% - 39% - 40% - 41% - 46% - 48% - 49% - 51% - 51% - 51% - 53% - 54% - 54% - 54% - 54% - 55% - 55% - 56% - 58% - 59% - 60% - 60% - 60% - 61% - 61% - 61% - 62% - 64% - 68% - 68% - 71% - 71% - 72% - 72% - 73% - 74% - 75% - 78% - 78% - 79% - 84% - 85% - 85% - 88% - 88% - 88% - 88% - 89% - 92% - 93% - 96% - 96% - 98% (68s) - loss: 0.7021\n",
      "Epoch 47 - 100% 1% - 1% - 3% - 4% - 4% - 4% - 4% - 5% - 6% - 8% - 9% - 10% - 10% - 11% - 13% - 14% - 14% - 15% - 15% - 15% - 16% - 17% - 17% - 17% - 18% - 18% - 18% - 18% - 18% - 18% - 19% - 19% - 19% - 21% - 26% - 26% - 27% - 29% - 32% - 33% - 35% - 36% - 36% - 36% - 36% - 36% - 36% - 37% - 37% - 39% - 39% - 39% - 42% - 48% - 48% - 48% - 49% - 49% - 49% - 51% - 51% - 51% - 51% - 52% - 52% - 53% - 53% - 53% - 54% - 55% - 55% - 56% - 56% - 61% - 61% - 63% - 64% - 64% - 64% - 64% - 64% - 64% - 64% - 64% - 66% - 66% - 66% - 67% - 68% - 69% - 71% - 71% - 71% - 71% - 71% - 71% - 72% - 72% - 74% - 76% - 76% - 76% - 77% - 77% - 77% - 77% - 77% - 79% - 81% - 81% - 81% - 82% - 84% - 84% - 85% - 85% - 85% - 85% - 87% - 89% - 90% - 90% - 91% - 94% - 94% - 94% - 95% - 96% - 97% - 97% - 97% - 97% - 97% - 99% - 99% - 100% - 100% (68s) - loss: 0.6986\n",
      "Epoch 48 - 100% 1% - 1% - 1% - 1% - 2% - 2% - 7% - 9% - 9% - 9% - 9% - 9% - 12% - 12% - 12% - 12% - 12% - 13% - 13% - 13% - 14% - 14% - 14% - 15% - 16% - 16% - 17% - 17% - 17% - 22% - 24% - 24% - 25% - 26% - 26% - 26% - 26% - 26% - 26% - 27% - 27% - 29% - 29% - 29% - 30% - 30% - 30% - 34% - 34% - 35% - 35% - 35% - 36% - 37% - 38% - 38% - 39% - 39% - 40% - 40% - 40% - 41% - 44% - 44% - 50% - 50% - 50% - 50% - 51% - 51% - 51% - 52% - 52% - 57% - 57% - 60% - 61% - 62% - 62% - 63% - 63% - 63% - 63% - 64% - 66% - 66% - 66% - 67% - 67% - 69% - 69% - 73% - 73% - 77% - 77% - 79% - 80% - 80% - 84% - 86% - 87% - 87% - 92% - 92% - 93% - 93% - 94% - 94% - 96% - 98% (68s) - loss: 0.6998\n",
      "Epoch 49 - 100% 0% - 0% - 4% - 4% - 5% - 6% - 6% - 6% - 7% - 7% - 8% - 10% - 10% - 11% - 12% - 12% - 12% - 15% - 17% - 18% - 21% - 22% - 23% - 23% - 23% - 25% - 26% - 26% - 26% - 28% - 29% - 29% - 29% - 36% - 36% - 37% - 37% - 37% - 40% - 43% - 44% - 44% - 46% - 52% - 52% - 52% - 52% - 55% - 55% - 56% - 59% - 60% - 60% - 60% - 60% - 60% - 62% - 62% - 63% - 66% - 67% - 69% - 70% - 71% - 71% - 72% - 72% - 74% - 74% - 75% - 77% - 77% - 85% - 86% - 86% - 86% - 86% - 86% - 88% - 89% - 89% - 89% - 89% - 89% - 89% - 89% - 89% - 90% - 91% - 91% - 95% - 95% - 95% - 96% - 98% - 98% (69s) - loss: 0.6982\n",
      "Epoch 50 - 100% 1% - 2% - 3% - 3% - 3% - 5% - 5% - 6% - 6% - 6% - 8% - 9% - 9% - 11% - 11% - 11% - 12% - 15% - 15% - 15% - 16% - 17% - 17% - 18% - 18% - 20% - 20% - 22% - 22% - 25% - 29% - 31% - 32% - 32% - 32% - 33% - 33% - 33% - 33% - 35% - 36% - 37% - 37% - 37% - 37% - 38% - 39% - 41% - 41% - 44% - 44% - 44% - 44% - 44% - 44% - 45% - 45% - 46% - 46% - 48% - 48% - 48% - 50% - 50% - 50% - 50% - 51% - 51% - 51% - 53% - 53% - 55% - 57% - 57% - 57% - 60% - 60% - 60% - 61% - 61% - 62% - 62% - 62% - 62% - 65% - 66% - 67% - 67% - 68% - 70% - 70% - 72% - 74% - 74% - 76% - 76% - 76% - 76% - 76% - 77% - 77% - 77% - 77% - 79% - 79% - 80% - 80% - 83% - 83% - 84% - 85% - 85% - 86% - 86% - 86% - 88% - 88% - 88% - 90% - 92% - 93% - 93% - 94% - 95% - 95% - 97% - 99% - 99% - 99% - 99% (69s) - loss: 0.6983\n",
      "Epoch 51 - 100% 1% - 1% - 1% - 3% - 3% - 3% - 4% - 5% - 5% - 5% - 5% - 6% - 7% - 7% - 7% - 7% - 9% - 9% - 9% - 9% - 10% - 10% - 11% - 11% - 11% - 11% - 12% - 12% - 15% - 15% - 16% - 16% - 16% - 18% - 23% - 23% - 24% - 26% - 26% - 27% - 28% - 28% - 28% - 28% - 30% - 31% - 32% - 33% - 34% - 34% - 34% - 35% - 39% - 42% - 42% - 42% - 43% - 43% - 44% - 45% - 45% - 45% - 45% - 46% - 47% - 47% - 49% - 50% - 50% - 51% - 52% - 53% - 55% - 55% - 55% - 55% - 56% - 56% - 56% - 57% - 57% - 59% - 59% - 60% - 61% - 61% - 61% - 61% - 61% - 61% - 61% - 61% - 63% - 63% - 63% - 68% - 68% - 69% - 69% - 73% - 73% - 74% - 75% - 76% - 76% - 79% - 79% - 79% - 81% - 82% - 82% - 83% - 83% - 83% - 83% - 84% - 86% - 86% - 91% - 91% - 93% - 93% - 93% - 96% - 96% - 96% - 96% - 97% - 97% - 97% - 97% - 97% - 97% - 98% (69s) - loss: 0.6963\n",
      "Epoch 52 - 100% 0% - 1% - 5% - 5% - 6% - 6% - 7% - 8% - 8% - 9% - 10% - 10% - 11% - 12% - 12% - 14% - 15% - 15% - 17% - 18% - 18% - 18% - 18% - 18% - 20% - 21% - 22% - 22% - 22% - 23% - 25% - 25% - 26% - 26% - 28% - 28% - 30% - 30% - 30% - 31% - 31% - 31% - 32% - 32% - 33% - 34% - 34% - 34% - 34% - 38% - 39% - 40% - 41% - 41% - 41% - 44% - 44% - 48% - 48% - 48% - 49% - 49% - 49% - 51% - 51% - 51% - 51% - 51% - 52% - 52% - 53% - 53% - 53% - 55% - 57% - 57% - 58% - 59% - 59% - 60% - 60% - 61% - 63% - 63% - 63% - 63% - 65% - 65% - 65% - 65% - 66% - 70% - 70% - 71% - 72% - 75% - 76% - 78% - 78% - 78% - 78% - 78% - 82% - 82% - 82% - 83% - 85% - 87% - 88% - 88% - 90% - 91% - 93% - 95% - 95% - 95% - 96% - 97% - 97% - 100% (69s) - loss: 0.6979\n",
      "Epoch 53 - 100% 0% - 2% - 2% - 4% - 4% - 4% - 5% - 5% - 8% - 9% - 9% - 10% - 11% - 12% - 13% - 13% - 13% - 15% - 15% - 16% - 18% - 20% - 21% - 21% - 24% - 25% - 26% - 26% - 26% - 27% - 28% - 29% - 32% - 32% - 34% - 36% - 36% - 37% - 38% - 38% - 43% - 43% - 43% - 43% - 43% - 43% - 43% - 44% - 45% - 46% - 46% - 47% - 47% - 47% - 47% - 48% - 49% - 49% - 49% - 49% - 50% - 51% - 51% - 52% - 52% - 53% - 55% - 55% - 55% - 55% - 56% - 57% - 57% - 59% - 59% - 62% - 63% - 64% - 64% - 65% - 65% - 67% - 67% - 67% - 68% - 69% - 70% - 70% - 70% - 71% - 73% - 75% - 75% - 76% - 76% - 77% - 77% - 78% - 79% - 80% - 83% - 83% - 83% - 84% - 84% - 85% - 86% - 87% - 87% - 91% - 93% - 95% - 96% - 96% - 96% - 96% - 97% - 98% - 99% (68s) - loss: 0.6963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 - 100% 1% - 2% - 2% - 2% - 5% - 5% - 7% - 10% - 12% - 13% - 18% - 20% - 20% - 20% - 21% - 21% - 21% - 21% - 21% - 21% - 23% - 23% - 24% - 24% - 27% - 27% - 27% - 28% - 30% - 32% - 33% - 33% - 33% - 33% - 35% - 35% - 37% - 37% - 42% - 44% - 45% - 45% - 45% - 45% - 46% - 48% - 50% - 52% - 52% - 53% - 55% - 56% - 57% - 57% - 58% - 58% - 59% - 60% - 63% - 65% - 67% - 67% - 67% - 68% - 68% - 68% - 68% - 68% - 68% - 68% - 68% - 68% - 68% - 68% - 69% - 71% - 71% - 73% - 74% - 74% - 75% - 75% - 75% - 75% - 75% - 75% - 75% - 78% - 79% - 79% - 80% - 80% - 82% - 84% - 89% - 91% - 91% - 93% - 93% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 97% - 97% - 97% - 98% - 99% (69s) - loss: 0.6954\n",
      "Epoch 55 - 100% 2% - 3% - 6% - 6% - 8% - 8% - 11% - 11% - 12% - 12% - 13% - 13% - 14% - 14% - 14% - 14% - 15% - 17% - 20% - 21% - 22% - 26% - 26% - 26% - 27% - 28% - 28% - 28% - 31% - 31% - 32% - 36% - 38% - 39% - 39% - 40% - 40% - 40% - 41% - 41% - 43% - 43% - 43% - 43% - 43% - 43% - 44% - 44% - 46% - 46% - 47% - 47% - 47% - 47% - 47% - 47% - 50% - 51% - 54% - 54% - 54% - 54% - 55% - 55% - 56% - 57% - 57% - 61% - 65% - 65% - 69% - 70% - 71% - 73% - 73% - 78% - 78% - 79% - 79% - 80% - 80% - 80% - 80% - 81% - 83% - 87% - 89% - 89% - 89% - 91% - 91% - 91% - 91% - 91% - 95% - 95% - 95% - 95% - 95% - 95% - 96% - 97% - 99% - 99% (69s) - loss: 0.6981\n",
      "Epoch 56 - 100% 0% - 0% - 1% - 2% - 2% - 2% - 2% - 2% - 2% - 2% - 5% - 6% - 6% - 8% - 8% - 8% - 9% - 9% - 9% - 9% - 10% - 14% - 15% - 15% - 15% - 15% - 16% - 17% - 19% - 20% - 20% - 20% - 21% - 22% - 22% - 26% - 27% - 27% - 28% - 30% - 30% - 30% - 30% - 31% - 32% - 32% - 32% - 32% - 35% - 36% - 36% - 36% - 37% - 37% - 37% - 37% - 37% - 39% - 39% - 45% - 46% - 49% - 50% - 50% - 50% - 57% - 58% - 58% - 58% - 59% - 60% - 60% - 61% - 61% - 61% - 62% - 64% - 64% - 64% - 64% - 65% - 66% - 68% - 69% - 70% - 70% - 71% - 73% - 74% - 76% - 76% - 78% - 78% - 78% - 79% - 80% - 80% - 80% - 82% - 82% - 82% - 82% - 83% - 83% - 84% - 84% - 86% - 87% - 88% - 88% - 89% - 89% - 89% - 91% - 91% - 91% - 96% - 97% - 98% - 99% (68s) - loss: 0.6971\n",
      "Epoch 57 - 100% 3% - 3% - 4% - 4% - 5% - 5% - 5% - 6% - 7% - 7% - 7% - 7% - 7% - 9% - 10% - 12% - 13% - 14% - 14% - 15% - 17% - 18% - 18% - 18% - 20% - 20% - 22% - 24% - 28% - 28% - 28% - 28% - 31% - 32% - 34% - 35% - 35% - 35% - 36% - 36% - 37% - 38% - 38% - 39% - 39% - 39% - 39% - 41% - 41% - 42% - 43% - 44% - 44% - 49% - 49% - 50% - 50% - 52% - 52% - 52% - 54% - 54% - 54% - 55% - 55% - 58% - 61% - 64% - 65% - 65% - 65% - 65% - 65% - 66% - 66% - 68% - 68% - 69% - 69% - 69% - 70% - 70% - 70% - 72% - 72% - 73% - 79% - 81% - 81% - 81% - 82% - 82% - 82% - 83% - 83% - 83% - 83% - 83% - 88% - 88% - 92% - 92% - 93% - 93% - 93% - 95% - 96% - 96% - 97% - 97% - 97% - 97% - 99% - 99% - 99% - 99% (69s) - loss: 0.6950\n",
      "Epoch 58 - 100% 2% - 3% - 3% - 6% - 7% - 7% - 7% - 8% - 8% - 9% - 9% - 10% - 10% - 10% - 10% - 10% - 10% - 10% - 10% - 10% - 14% - 14% - 18% - 20% - 22% - 22% - 25% - 26% - 26% - 26% - 26% - 26% - 27% - 29% - 29% - 29% - 29% - 31% - 31% - 31% - 31% - 32% - 33% - 36% - 36% - 36% - 36% - 37% - 37% - 37% - 37% - 38% - 41% - 42% - 42% - 43% - 44% - 46% - 46% - 47% - 47% - 48% - 48% - 48% - 48% - 48% - 50% - 52% - 52% - 53% - 53% - 56% - 56% - 58% - 59% - 60% - 61% - 63% - 63% - 63% - 64% - 65% - 67% - 67% - 70% - 71% - 73% - 73% - 73% - 75% - 76% - 76% - 78% - 80% - 81% - 84% - 84% - 85% - 86% - 86% - 87% - 87% - 87% - 88% - 89% - 89% - 89% - 89% - 91% - 91% - 93% - 97% - 98% - 98% - 98% (68s) - loss: 0.6944\n",
      "Epoch 59 - 100% 1% - 1% - 1% - 2% - 6% - 6% - 9% - 9% - 9% - 10% - 11% - 11% - 11% - 13% - 14% - 14% - 15% - 19% - 20% - 20% - 21% - 21% - 21% - 23% - 24% - 24% - 24% - 24% - 26% - 26% - 26% - 28% - 29% - 29% - 30% - 30% - 31% - 33% - 33% - 34% - 34% - 34% - 35% - 38% - 39% - 40% - 40% - 40% - 41% - 41% - 41% - 41% - 41% - 44% - 44% - 45% - 47% - 48% - 48% - 48% - 48% - 48% - 50% - 50% - 54% - 54% - 55% - 56% - 58% - 60% - 60% - 62% - 62% - 62% - 62% - 62% - 62% - 63% - 63% - 63% - 64% - 69% - 72% - 72% - 75% - 75% - 75% - 75% - 79% - 80% - 80% - 80% - 81% - 81% - 85% - 86% - 86% - 86% - 86% - 86% - 87% - 87% - 90% - 91% - 92% - 94% - 94% - 94% - 95% - 95% - 96% - 100% (68s) - loss: 0.6952\n",
      "Epoch 60 - 100% 0% - 2% - 3% - 3% - 5% - 5% - 5% - 6% - 6% - 7% - 9% - 9% - 10% - 10% - 11% - 11% - 13% - 14% - 14% - 14% - 14% - 14% - 14% - 18% - 19% - 21% - 21% - 21% - 22% - 22% - 22% - 25% - 25% - 26% - 27% - 27% - 27% - 31% - 32% - 33% - 33% - 34% - 34% - 35% - 35% - 35% - 35% - 36% - 37% - 37% - 38% - 39% - 39% - 39% - 39% - 40% - 40% - 41% - 41% - 41% - 42% - 43% - 44% - 44% - 44% - 45% - 47% - 47% - 47% - 49% - 49% - 51% - 52% - 52% - 52% - 53% - 56% - 56% - 58% - 59% - 59% - 59% - 60% - 61% - 61% - 61% - 63% - 63% - 63% - 64% - 67% - 67% - 68% - 70% - 70% - 70% - 71% - 73% - 76% - 77% - 77% - 78% - 79% - 80% - 80% - 82% - 87% - 88% - 88% - 88% - 88% - 90% - 96% - 96% - 96% - 96% - 96% - 98% - 98% - 98% - 98% - 98% - 99% (69s) - loss: 0.6956\n",
      "Epoch 61 - 100% 0% - 0% - 1% - 1% - 1% - 1% - 2% - 2% - 4% - 4% - 6% - 7% - 11% - 13% - 13% - 13% - 14% - 14% - 14% - 16% - 18% - 18% - 19% - 20% - 20% - 20% - 21% - 21% - 21% - 21% - 23% - 23% - 23% - 24% - 24% - 26% - 26% - 27% - 28% - 29% - 30% - 30% - 30% - 31% - 31% - 32% - 34% - 35% - 35% - 36% - 38% - 42% - 43% - 43% - 43% - 44% - 44% - 44% - 44% - 44% - 48% - 48% - 48% - 49% - 52% - 52% - 53% - 54% - 55% - 56% - 56% - 56% - 58% - 59% - 60% - 60% - 60% - 60% - 61% - 64% - 65% - 65% - 69% - 72% - 73% - 73% - 79% - 80% - 81% - 81% - 81% - 82% - 83% - 83% - 83% - 83% - 83% - 84% - 86% - 87% - 87% - 87% - 87% - 87% - 87% - 88% - 88% - 88% - 89% - 89% - 89% - 89% - 89% - 89% - 89% - 91% - 93% - 95% - 100% (68s) - loss: 0.6938\n",
      "Epoch 62 - 100% 1% - 1% - 2% - 6% - 10% - 11% - 12% - 12% - 13% - 13% - 13% - 13% - 13% - 13% - 14% - 20% - 21% - 21% - 22% - 23% - 24% - 25% - 25% - 25% - 25% - 25% - 26% - 26% - 26% - 26% - 27% - 28% - 28% - 31% - 31% - 31% - 34% - 34% - 40% - 41% - 42% - 43% - 43% - 43% - 43% - 44% - 44% - 44% - 49% - 51% - 51% - 51% - 51% - 54% - 54% - 54% - 54% - 56% - 57% - 57% - 58% - 59% - 60% - 60% - 61% - 62% - 62% - 63% - 63% - 64% - 64% - 65% - 65% - 65% - 65% - 65% - 66% - 66% - 67% - 67% - 67% - 67% - 68% - 68% - 68% - 68% - 69% - 72% - 74% - 75% - 76% - 78% - 78% - 79% - 79% - 81% - 81% - 83% - 84% - 84% - 84% - 84% - 84% - 85% - 89% - 89% - 91% - 92% - 93% - 94% - 96% - 96% - 96% - 97% - 97% - 99% - 99% - 99% - 99% - 99% - 100% (68s) - loss: 0.6946\n",
      "Epoch 63 - 100% 0% - 1% - 1% - 2% - 2% - 4% - 6% - 6% - 6% - 7% - 7% - 7% - 8% - 14% - 15% - 15% - 16% - 18% - 18% - 19% - 20% - 22% - 23% - 24% - 25% - 26% - 26% - 27% - 27% - 27% - 27% - 27% - 29% - 29% - 30% - 30% - 32% - 32% - 32% - 32% - 34% - 35% - 35% - 35% - 36% - 37% - 37% - 37% - 39% - 39% - 39% - 39% - 39% - 40% - 41% - 41% - 41% - 42% - 42% - 42% - 44% - 44% - 44% - 44% - 47% - 47% - 49% - 50% - 50% - 50% - 51% - 52% - 52% - 53% - 53% - 54% - 55% - 55% - 56% - 58% - 61% - 61% - 61% - 62% - 64% - 69% - 69% - 72% - 72% - 73% - 75% - 75% - 76% - 76% - 76% - 78% - 79% - 80% - 80% - 80% - 80% - 81% - 82% - 82% - 84% - 84% - 85% - 85% - 85% - 86% - 86% - 86% - 86% - 86% - 86% - 86% - 87% - 87% - 87% - 88% - 89% - 89% - 89% - 89% - 91% - 91% - 91% - 92% - 92% - 92% - 92% - 92% - 93% - 94% - 96% - 96% - 96% - 98% - 99% - 100% (68s) - loss: 0.6946\n",
      "Epoch 64 - 100% 0% - 0% - 0% - 1% - 3% - 3% - 3% - 3% - 4% - 5% - 5% - 6% - 6% - 7% - 8% - 9% - 9% - 9% - 9% - 10% - 14% - 15% - 15% - 16% - 17% - 17% - 18% - 19% - 21% - 23% - 23% - 23% - 23% - 23% - 23% - 23% - 24% - 24% - 24% - 24% - 24% - 25% - 26% - 29% - 30% - 32% - 34% - 35% - 35% - 39% - 39% - 39% - 39% - 40% - 40% - 40% - 42% - 44% - 46% - 46% - 46% - 47% - 49% - 49% - 51% - 51% - 53% - 53% - 53% - 56% - 57% - 57% - 58% - 58% - 61% - 61% - 62% - 62% - 63% - 64% - 64% - 65% - 65% - 68% - 68% - 70% - 74% - 75% - 76% - 77% - 79% - 79% - 80% - 80% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 82% - 82% - 82% - 83% - 83% - 84% - 86% - 89% - 93% - 93% - 94% - 94% - 95% - 96% (68s) - loss: 0.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 - 100% 2% - 3% - 4% - 5% - 5% - 5% - 5% - 5% - 9% - 10% - 10% - 10% - 10% - 13% - 13% - 14% - 14% - 18% - 23% - 23% - 25% - 25% - 25% - 27% - 28% - 28% - 28% - 31% - 31% - 31% - 31% - 34% - 34% - 34% - 34% - 34% - 34% - 35% - 37% - 38% - 38% - 40% - 40% - 40% - 43% - 48% - 51% - 52% - 53% - 54% - 57% - 57% - 59% - 60% - 61% - 62% - 63% - 63% - 63% - 63% - 63% - 64% - 70% - 71% - 71% - 73% - 73% - 73% - 74% - 74% - 74% - 74% - 74% - 79% - 79% - 80% - 80% - 81% - 82% - 82% - 83% - 83% - 83% - 83% - 84% - 84% - 85% - 85% - 86% - 86% - 88% - 88% - 88% - 89% - 89% - 89% - 89% - 91% - 94% - 95% - 97% - 97% - 97% - 98% - 98% - 100% - 100% (68s) - loss: 0.6939\n",
      "Epoch 67 - 100% 1% - 1% - 2% - 2% - 2% - 3% - 3% - 3% - 3% - 3% - 3% - 3% - 3% - 4% - 5% - 5% - 5% - 5% - 7% - 7% - 7% - 11% - 12% - 13% - 13% - 13% - 14% - 14% - 14% - 14% - 16% - 17% - 17% - 19% - 91% - 93% - 93% - 93% - 93% - 93% - 94% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 96% - 97% - 97% - 97% - 97% - 98% (68s) - loss: 0.6919\n",
      "Epoch 68 - 26%- 1% - 1% - 1% - 4% - 4% - 4% - 4% - 4% - 8% - 11% - 11% - 11% - 11% - 12% - 12% - 12% - 12% - 13% - 13% - 15% - 16% - 16% - 16% - 19% - 19% - 19% - 21% - 21% - 23% - 25%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 - 100%- 79% - 79% - 79% - 79% - 80% - 81% - 82% - 82% - 82% - 82% - 82% - 82% - 82% - 82% - 82% - 84% - 86% - 86% - 86% - 87% - 95% - 95% - 97% - 97% - 97% - 97% - 97% - 98% - 98% - 99% (68s) - loss: 0.6915\n",
      "Epoch 69 - 13%- 1% - 1% - 4% - 4% - 4% - 4% - 4% - 12% - 12% - 13%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 - 100%- 65% - 66% - 66% - 66% - 66% - 67% - 68% - 68% - 68% - 69% - 69% - 70% - 70% - 72% - 74% - 74% - 76% - 76% - 78% - 78% - 79% - 80% - 80% - 80% - 80% - 80% - 80% - 80% - 80% - 81% - 81% - 82% - 82% - 82% - 83% - 85% - 85% - 85% - 85% - 89% - 90% - 93% - 93% - 93% - 93% - 93% - 93% - 93% - 94% - 95% - 95% - 99% - 99% - 99% (68s) - loss: 0.6915\n",
      "Epoch 70 - 0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - 88% - 53% - 56% - 56% - 56% - 56% - 56% - 56% - 57% - 58% - 59% - 60% - 60% - 62% - 63% - 63% - 63% - 63% - 63% - 64% - 64% - 65% - 66% - 67% - 74% - 75% - 75% - 75% - 76% - 86% - 86% - 87%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 - 75% - 42% - 43% - 43% - 47% - 48% - 48% - 48% - 49% - 49% - 49% - 49% - 49% - 50% - 50% - 50% - 52% - 53% - 53% - 53% - 53% - 54% - 54% - 54% - 54% - 54% - 56% - 57% - 59% - 59% - 59% - 60% - 60% - 61% - 61% - 63% - 63% - 63% - 64% - 64% - 66% - 66% - 66% - 66% - 68% - 72% - 72% - 72% - 72% - 72% - 72% - 73% - 73% - 75%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 - 63% - 30% - 30% - 33% - 34% - 34% - 38% - 39% - 39% - 40% - 40% - 41% - 41% - 42% - 42% - 43% - 43% - 43% - 45% - 45% - 49% - 49% - 50% - 51% - 51% - 53% - 53% - 53% - 53% - 53% - 54% - 54% - 57% - 59% - 59% - 62% - 62% - 63%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 - 50% - 16% - 16% - 20% - 20% - 20% - 21% - 21% - 22% - 23% - 23% - 23% - 23% - 23% - 23% - 23% - 25% - 28% - 28% - 29% - 31% - 33% - 33% - 34% - 36% - 37% - 40% - 40% - 40% - 41% - 42% - 42% - 44% - 44%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 - 38%- 3% - 3% - 4% - 4% - 4% - 4% - 6% - 8% - 9% - 13% - 13% - 13% - 13% - 15% - 16% - 19% - 21% - 21% - 21% - 27% - 27% - 27% - 27% - 27% - 27% - 27% - 27% - 27% - 30% - 34% - 36% - 37%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 - 100%- 90% - 90% - 90% - 90% - 90% - 90% - 90% - 90% - 90% - 92% - 92% - 94% - 97% - 98% - 98% - 98% - 99% - 99% - 99% (67s) - loss: 0.6908\n",
      "Epoch 75 - 25%- 1% - 1% - 1% - 2% - 2% - 2% - 2% - 2% - 2% - 3% - 3% - 5% - 5% - 11% - 11% - 12% - 12% - 13% - 13% - 14% - 15% - 15% - 15% - 15% - 17% - 18% - 18% - 24% - 24% - 25% - 25%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 - 74% - 68% - 68% - 70% - 70% - 70% - 73%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 - 100%- 85% - 85% - 87% - 87% - 95% - 95% - 95% - 95% - 95% - 96% - 96% - 96% - 96% - 97% - 97% - 97% - 97% - 97% - 98% (68s) - loss: 0.6915\n",
      "Epoch 76 - 12%- 2% - 2% - 2% - 2% - 2% - 2% - 3% - 3% - 3% - 3% - 3% - 3% - 6% - 11% - 11% - 11% - 11% - 11% - 12%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 - 61% - 54% - 55% - 55% - 55% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 57% - 57% - 60%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 - 99% - 72% - 73% - 75% - 76% - 76% - 79% - 79% - 80% - 80% - 81% - 83% - 83% - 84% - 87% - 87% - 88% - 93% - 94% - 94% - 97% - 98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 - 48% - 42% - 42% - 44%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 - 86% - 60% - 62% - 62% - 63% - 63% - 64% - 66% - 68% - 70% - 70% - 70% - 70% - 70% - 70% - 70% - 75% - 75% - 75% - 76% - 77% - 85% - 85% - 85%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 - 35% - 28% - 28% - 28% - 28% - 31% - 31% - 32% - 32% - 32% - 34% - 35%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 - 73% - 47% - 47% - 47% - 47% - 48% - 48% - 49% - 49% - 50% - 54% - 58% - 58% - 59% - 59% - 59% - 60% - 60% - 60% - 61% - 63% - 63% - 64% - 67% - 68% - 68% - 69% - 69% - 70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 - 22% - 16% - 17% - 17% - 18% - 18% - 18% - 21% - 22% - 22% - 22% - 22%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 - 60% - 33% - 36% - 36% - 36% - 36% - 36% - 36% - 36% - 37% - 37% - 37% - 40% - 40% - 41% - 41% - 41% - 42% - 44% - 46% - 48% - 51% - 53% - 54% - 54% - 55% - 55% - 55% - 55% - 56%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - 9% - 7% - 7%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - 47% - 21% - 23% - 23% - 23% - 23% - 26% - 30% - 30% - 30% - 30% - 30% - 31% - 31% - 32% - 33% - 34% - 36% - 40% - 40% - 40% - 41% - 41% - 41% - 42% - 46% - 46% - 47% - 47% - 47% - 47%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - 83% - 76% - 76% - 78% - 78% - 78% - 78% - 78% - 81% - 81% - 81% - 82% - 82%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - 100%- 94% - 95% - 95% - 95% - 95% - 96% - 97% - 97% - 99% (67s) - loss: 0.6905\n",
      "Epoch 81 - 9% - 1% - 3% - 3% - 8% - 9%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 - 34% - 23% - 24% - 27% - 31% - 33%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 - 70% - 67% - 67% - 67% - 69% - 69%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 - 96% - 81% - 82% - 82% - 82% - 82% - 84% - 86% - 86% - 86% - 86% - 86% - 91%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 - 21%- 9% - 9% - 12% - 12% - 12% - 12% - 12% - 12% - 13% - 13% - 13% - 13% - 14% - 19% - 19% - 19% - 19% - 19%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 - 57% - 55%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 - 83% - 69% - 69% - 69% - 69% - 70% - 70% - 70% - 74% - 79% - 79% - 79% - 79% - 80% - 80% - 82% - 82% - 82% - 83% - 83%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 - 100%- 96% - 96% - 96% - 96% - 97% - 98% - 100% (67s) - loss: 0.6878\n",
      "Epoch 83 - 8% - 1% - 6% - 6% - 6% - 6% - 6% - 7%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 - 44% - 40% - 40% - 40% - 41% - 41% - 41% - 42% - 43%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 - 70% - 55% - 56% - 57% - 57% - 57% - 57% - 57% - 57% - 57% - 58% - 59% - 59% - 60% - 63% - 63% - 63% - 66% - 67% - 69% - 69% - 70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 - 95% - 86% - 86% - 88% - 92%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 - 31% - 25% - 25% - 26% - 28% - 28%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 - 57% - 43% - 44% - 45% - 45% - 45% - 45% - 45% - 45% - 47% - 47% - 47% - 48% - 48% - 48% - 48% - 48% - 48% - 48% - 49% - 49% - 50% - 50% - 51% - 53% - 54% - 54% - 54% - 55% - 56% - 56% - 57%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 - 81% - 69% - 73% - 74% - 74% - 75% - 75% - 75% - 75% - 77% - 81% - 81% - 81%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 - 17% - 10% - 10% - 12% - 12% - 12% - 13% - 13% - 15% - 15% - 15%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 - 44% - 30% - 30% - 31% - 41% - 41%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 - 68% - 57% - 59% - 59% - 60% - 60% - 60% - 62% - 62% - 62% - 64% - 64% - 65% - 66% - 67% - 67% - 67% - 67% - 68% - 68% - 68%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 - 100%- 97% - 99% - 100% (68s) - loss: 0.6887\n",
      "Epoch 86 - 4% - 1% - 2% - 2% - 2% - 2% - 2% - 3% - 3% - 3% - 3% - 3% - 3% - 3% - 3% - 3% - 4%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 - 31% - 16% - 20% - 21% - 21% - 21% - 21% - 21% - 21% - 30% - 30% - 31%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 - 55% - 44% - 45% - 45% - 45% - 50% - 50% - 50% - 50% - 52% - 53%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 - 91% - 85% - 85% - 85% - 87% - 88% - 89% - 91%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 - 30%- 4% - 4% - 4% - 5% - 7% - 12% - 14% - 16% - 16% - 16% - 18% - 18% - 19% - 19% - 19% - 19% - 19% - 20% - 21% - 21% - 22% - 22% - 23% - 25% - 25% - 25% - 26% - 26% - 26% - 26% - 27% - 27% - 29% - 29% - 29% - 30% - 30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 - 64% - 56% - 56% - 60% - 61% - 61% - 62% - 62% - 63% - 64%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 - 88% - 75% - 75% - 77% - 81% - 82% - 82% - 82% - 82% - 86% - 87% - 88% - 88%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 - 16%- 2% - 3% - 3% - 3% - 4% - 4% - 4% - 6% - 6% - 6% - 8% - 8% - 13% - 13% - 13% - 13% - 13% - 13% - 13% - 13% - 14% - 15% - 15% - 16% - 16% - 16% - 16% - 16% - 16% - 16%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 - 50% - 44% - 46% - 46% - 47% - 47%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 - 75% - 66% - 66% - 66% - 69% - 69% - 69% - 69% - 69% - 70% - 70% - 71% - 71% - 72% - 73% - 74% - 74%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 - 100%- 90% - 90% - 91% - 91% - 91% - 91% - 91% - 91% - 92% - 93% - 93% - 93% - 94% - 95% - 95% - 95% - 96% - 96% - 96% - 96% - 98% - 98% - 98% - 98% - 98% - 99% (68s) - loss: 0.6891\n",
      "Epoch 89 - 3% - 1% - 1% - 1% - 2% - 2%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 - 37% - 29% - 30% - 30% - 30% - 31% - 31% - 32% - 32% - 32% - 33% - 33% - 36% - 36%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 - 61% - 48% - 49% - 52% - 56% - 57% - 58%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 - 90% - 75% - 78% - 80% - 80% - 80% - 81% - 82% - 83% - 84% - 84% - 85% - 85% - 85% - 85% - 86% - 86% - 86% - 87% - 87% - 88%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 - 23% - 15% - 16% - 16% - 16% - 16% - 16% - 17% - 17% - 19% - 19% - 20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 - 48% - 35% - 35% - 36% - 36% - 36% - 36% - 36% - 36% - 37% - 43% - 43% - 44% - 44% - 47%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 - 76% - 63% - 64% - 64% - 64% - 64% - 64% - 66% - 66% - 66% - 66% - 67% - 68% - 69% - 70% - 70% - 70% - 71% - 71% - 71% - 72% - 73% - 74% - 74% - 74% - 74% - 74%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 - 9% - 2% - 3% - 3% - 7% - 7%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 - 34% - 21% - 24% - 24% - 25% - 25% - 27% - 27% - 28% - 28% - 28% - 30% - 31% - 32% - 32% - 32% - 32% - 32% - 34% - 34%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 - 62% - 48% - 48% - 51% - 51% - 51% - 54% - 56% - 56% - 57% - 59% - 59% - 60% - 61% - 62% - 62% - 62%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 - 96% - 88% - 88% - 92% - 92%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 - 20%- 8% - 9% - 9% - 10% - 11% - 11% - 11% - 14% - 14% - 14% - 15% - 15% - 15% - 15% - 15% - 18% - 18% - 20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 - 49% - 36% - 36% - 38% - 40% - 41% - 41% - 41% - 42% - 42% - 42% - 42% - 45% - 45%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 - 82% - 76% - 77% - 77% - 77% - 77% - 78% - 78% - 78% - 78% - 79% - 80% - 80% - 81% - 81% - 82% - 82%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print(\"Dataset comprised of {:d} documents.\".format(len(dataset)))\n",
    "print(\"Vocabulary size is {:d}.\\n\".format(vocabulary_size))\n",
    "print(\"Training started.\")\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "prev_model_file_path = None\n",
    "\n",
    "for epoch_i in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    loss = []\n",
    "\n",
    "    for batch_i in range(num_batches):\n",
    "        batch = data_generator.next()\n",
    "        if torch.cuda.is_available():\n",
    "            batch.cuda_()\n",
    "\n",
    "\n",
    "        x = model.forward(batch.doc_ids, batch.target_noise_ids)\n",
    "        x = cost_func.forward(x)\n",
    "\n",
    "        loss.append(x.item())\n",
    "        model.zero_grad()\n",
    "        x.backward()\n",
    "        optimizer.step()\n",
    "        _print_progress(epoch_i, batch_i, num_batches)\n",
    "\n",
    "    # end of epoch\n",
    "    loss = torch.mean(torch.FloatTensor(loss))\n",
    "    is_best_loss = loss < best_loss\n",
    "    best_loss = min(loss, best_loss)\n",
    "\n",
    "    state = {\n",
    "        'epoch': epoch_i + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    prev_model_file_path = save_training_state(\n",
    "        data_file_name,\n",
    "        model_ver,\n",
    "        vec_combine_method,\n",
    "        context_size,\n",
    "        num_noise_words,\n",
    "        vec_dim,\n",
    "        batch_size,\n",
    "        lr,\n",
    "        epoch_i,\n",
    "        loss,\n",
    "        state,\n",
    "        save_all,\n",
    "        generate_plot,\n",
    "        is_best_loss,\n",
    "        prev_model_file_path,\n",
    "        model_ver_is_dbow)\n",
    "\n",
    "    epoch_total_time = round(time.time() - epoch_start_time)\n",
    "    print(\" ({:d}s) - loss: {:.4f}\".format(epoch_total_time, loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d866708b7b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.listdir(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"all_data_model.dbow_numnoisewords.2_vecdim.100_batchsize.32_lr.0.001000_epoch.95_loss.0.755801.pth.tar\"\n",
    "model_root = model_file_name.replace(\".pth.tar\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = 'all_data.csv' \n",
    "start(data_file_name, model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
