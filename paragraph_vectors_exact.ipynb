{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.7.0)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/.local/lib/python3.6/site-packages (from torchtext) (0.1.91)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.6/site-packages (from torchtext) (4.48.2)\n",
      "Requirement already satisfied: torch in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.4.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (2.23.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (2020.4.5.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import signal\n",
    "from math import ceil\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from numpy.random import choice\n",
    "from torchtext.data import Field, TabularDataset\n",
    "\n",
    "# from paragraphvec.utils import DATA_DIR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(file_name):\n",
    "    \"\"\"Loads contents from a file in the *data* directory into a\n",
    "    torchtext.data.TabularDataset instance.\n",
    "    \"\"\"\n",
    "    file_path = join(DATA_DIR, file_name)\n",
    "    text_field = Field(pad_token=None, tokenize=_tokenize_str)\n",
    "\n",
    "    dataset = TabularDataset(\n",
    "        path=file_path,\n",
    "        format='csv',\n",
    "        fields=[('text', text_field)],\n",
    "        skip_header=True)\n",
    "\n",
    "    text_field.build_vocab(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def _tokenize_str(str_):\n",
    "    # keep only alphanumeric and punctations\n",
    "    str_ = re.sub(r'[^A-Za-z0-9(),.!?\\'`]', ' ', str_)\n",
    "    # remove multiple whitespace characters\n",
    "    str_ = re.sub(r'\\s{2,}', ' ', str_)\n",
    "    # punctations to tokens\n",
    "    str_ = re.sub(r'\\(', ' ( ', str_)\n",
    "    str_ = re.sub(r'\\)', ' ) ', str_)\n",
    "    str_ = re.sub(r',', ' , ', str_)\n",
    "    str_ = re.sub(r'\\.', ' . ', str_)\n",
    "    str_ = re.sub(r'!', ' ! ', str_)\n",
    "    str_ = re.sub(r'\\?', ' ? ', str_)\n",
    "    # split contractions into multiple tokens\n",
    "    str_ = re.sub(r'\\'s', ' \\'s', str_)\n",
    "    str_ = re.sub(r'\\'ve', ' \\'ve', str_)\n",
    "    str_ = re.sub(r'n\\'t', ' n\\'t', str_)\n",
    "    str_ = re.sub(r'\\'re', ' \\'re', str_)\n",
    "    str_ = re.sub(r'\\'d', ' \\'d', str_)\n",
    "    str_ = re.sub(r'\\'ll', ' \\'ll', str_)\n",
    "    # lower case\n",
    "    return str_.strip().lower().split()\n",
    "\n",
    "\n",
    "class NCEData(object):\n",
    "    \"\"\"An infinite, parallel (multiprocess) batch generator for\n",
    "    noise-contrastive estimation of word vector models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: torchtext.data.TabularDataset\n",
    "        Dataset from which examples are generated. A column labeled *text*\n",
    "        is expected and should be comprised of a list of tokens. Each row\n",
    "        should represent a single document.\n",
    "\n",
    "    batch_size: int\n",
    "        Number of examples per single gradient update.\n",
    "\n",
    "    context_size: int\n",
    "        Half the size of a neighbourhood of target words (i.e. how many\n",
    "        words left and right are regarded as context).\n",
    "\n",
    "    num_noise_words: int\n",
    "        Number of noise words to sample from the noise distribution.\n",
    "\n",
    "    max_size: int\n",
    "        Maximum number of pre-generated batches.\n",
    "\n",
    "    num_workers: int\n",
    "        Number of jobs to run in parallel. If value is set to -1, total number\n",
    "        of machine CPUs is used.\n",
    "    \"\"\"\n",
    "    # code inspired by parallel generators in https://github.com/fchollet/keras\n",
    "    def __init__(self, dataset, batch_size, context_size,\n",
    "                 num_noise_words, max_size, num_workers):\n",
    "        self.max_size = max_size\n",
    "\n",
    "        self.num_workers = num_workers if num_workers != -1 else os.cpu_count()\n",
    "        if self.num_workers is None:\n",
    "            self.num_workers = 1\n",
    "\n",
    "        self._generator = _NCEGenerator(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            context_size,\n",
    "            num_noise_words,\n",
    "            _NCEGeneratorState(context_size))\n",
    "\n",
    "        self._queue = []\n",
    "        self._stop_event = None\n",
    "        self._processes = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._generator)\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return self._generator.vocabulary_size()\n",
    "\n",
    "\n",
    "\n",
    "class _NCEGenerator(object):\n",
    "    \"\"\"An infinite, process-safe batch generator for noise-contrastive\n",
    "    estimation of word vector models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state: paragraphvec.data._NCEGeneratorState\n",
    "        Initial (indexing) state of the generator.\n",
    "\n",
    "    For other parameters see the NCEData class.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, context_size,\n",
    "                 num_noise_words, state):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.context_size = context_size\n",
    "        self.num_noise_words = num_noise_words\n",
    "\n",
    "        self._vocabulary = self.dataset.fields['text'].vocab\n",
    "        self._sample_noise = None\n",
    "        self._init_noise_distribution()\n",
    "        self._state = state\n",
    "\n",
    "    def _init_noise_distribution(self):\n",
    "        # we use a unigram distribution raised to the 3/4rd power,\n",
    "        # as proposed by T. Mikolov et al. in Distributed Representations\n",
    "        # of Words and Phrases and their Compositionality\n",
    "        probs = np.zeros(len(self._vocabulary) - 1)\n",
    "\n",
    "        for word, freq in self._vocabulary.freqs.items():\n",
    "            probs[self._word_to_index(word)] = freq\n",
    "\n",
    "        probs = np.power(probs, 0.75)\n",
    "        probs /= np.sum(probs)\n",
    "\n",
    "        self._sample_noise = lambda: choice(\n",
    "            probs.shape[0], self.num_noise_words, p=probs).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        num_examples = sum(self._num_examples_in_doc(d) for d in self.dataset)\n",
    "        return ceil(num_examples / self.batch_size)\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return len(self._vocabulary) - 1\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Updates state for the next process in a process-safe manner\n",
    "        and generates the current batch.\"\"\"\n",
    "        prev_doc_id, prev_in_doc_pos = self._state.update_state(\n",
    "            self.dataset,\n",
    "            self.batch_size,\n",
    "            self.context_size,\n",
    "            self._num_examples_in_doc)\n",
    "\n",
    "        # generate the actual batch\n",
    "        batch = _NCEBatch(self.context_size)\n",
    "\n",
    "        while len(batch) < self.batch_size:\n",
    "            if prev_doc_id == len(self.dataset):\n",
    "                # last document exhausted\n",
    "                batch.torch_()\n",
    "                return batch\n",
    "            if prev_in_doc_pos <= (len(self.dataset[prev_doc_id].text) - 1\n",
    "                                   - self.context_size):\n",
    "                # more examples in the current document\n",
    "                self._add_example_to_batch(prev_doc_id, prev_in_doc_pos, batch)\n",
    "                prev_in_doc_pos += 1\n",
    "            else:\n",
    "                # go to the next document\n",
    "                prev_doc_id += 1\n",
    "                prev_in_doc_pos = self.context_size\n",
    "\n",
    "        batch.torch_()\n",
    "        return batch\n",
    "\n",
    "    def _num_examples_in_doc(self, doc, in_doc_pos=None):\n",
    "        if in_doc_pos is not None:\n",
    "            # number of remaining\n",
    "            if len(doc.text) - in_doc_pos >= self.context_size + 1:\n",
    "                return len(doc.text) - in_doc_pos - self.context_size\n",
    "            return 0\n",
    "\n",
    "        if len(doc.text) >= 2 * self.context_size + 1:\n",
    "            # total number\n",
    "            return len(doc.text) - 2 * self.context_size\n",
    "        return 0\n",
    "\n",
    "    def _add_example_to_batch(self, doc_id, in_doc_pos, batch):\n",
    "        doc = self.dataset[doc_id].text\n",
    "        batch.doc_ids.append(doc_id)\n",
    "\n",
    "        # sample from the noise distribution\n",
    "        current_noise = self._sample_noise()\n",
    "        current_noise.insert(0, self._word_to_index(doc[in_doc_pos]))\n",
    "        batch.target_noise_ids.append(current_noise)\n",
    "\n",
    "        if self.context_size == 0:\n",
    "            return\n",
    "\n",
    "        current_context = []\n",
    "        context_indices = (in_doc_pos + diff for diff in\n",
    "                           range(-self.context_size, self.context_size + 1)\n",
    "                           if diff != 0)\n",
    "\n",
    "        for i in context_indices:\n",
    "            context_id = self._word_to_index(doc[i])\n",
    "            current_context.append(context_id)\n",
    "        batch.context_ids.append(current_context)\n",
    "\n",
    "    def _word_to_index(self, word):\n",
    "        return self._vocabulary.stoi[word] - 1\n",
    "\n",
    "\n",
    "class _NCEGeneratorState(object):\n",
    "    \"\"\"Batch generator state that is represented with a document id and\n",
    "    in-document position. It abstracts a process-safe indexing mechanism.\"\"\"\n",
    "    def __init__(self, context_size):\n",
    "        # use raw values because both indices have\n",
    "        # to manually be locked together\n",
    "        self._doc_id = multiprocessing.RawValue('i', 0)\n",
    "        self._in_doc_pos = multiprocessing.RawValue('i', context_size)\n",
    "        self._lock = multiprocessing.Lock()\n",
    "\n",
    "    def update_state(self, dataset, batch_size,\n",
    "                     context_size, num_examples_in_doc):\n",
    "        \"\"\"Returns current indices and computes new indices for the\n",
    "        next process.\"\"\"\n",
    "        with self._lock:\n",
    "            doc_id = self._doc_id.value\n",
    "            in_doc_pos = self._in_doc_pos.value\n",
    "            self._advance_indices(\n",
    "                dataset, batch_size, context_size, num_examples_in_doc)\n",
    "            return doc_id, in_doc_pos\n",
    "\n",
    "    def _advance_indices(self, dataset, batch_size,\n",
    "                         context_size, num_examples_in_doc):\n",
    "        num_examples = num_examples_in_doc(\n",
    "            dataset[self._doc_id.value], self._in_doc_pos.value)\n",
    "\n",
    "        if num_examples > batch_size:\n",
    "            # more examples in the current document\n",
    "            self._in_doc_pos.value += batch_size\n",
    "            return\n",
    "\n",
    "        if num_examples == batch_size:\n",
    "            # just enough examples in the current document\n",
    "            if self._doc_id.value < len(dataset) - 1:\n",
    "                self._doc_id.value += 1\n",
    "            else:\n",
    "                self._doc_id.value = 0\n",
    "            self._in_doc_pos.value = context_size\n",
    "            return\n",
    "\n",
    "        while num_examples < batch_size:\n",
    "            if self._doc_id.value == len(dataset) - 1:\n",
    "                # last document: reset indices\n",
    "                self._doc_id.value = 0\n",
    "                self._in_doc_pos.value = context_size\n",
    "                return\n",
    "\n",
    "            self._doc_id.value += 1\n",
    "            num_examples += num_examples_in_doc(\n",
    "                dataset[self._doc_id.value])\n",
    "\n",
    "        self._in_doc_pos.value = (len(dataset[self._doc_id.value].text)\n",
    "                                  - context_size\n",
    "                                  - (num_examples - batch_size))\n",
    "\n",
    "\n",
    "class _NCEBatch(object):\n",
    "    def __init__(self, context_size):\n",
    "        self.context_ids = [] if context_size > 0 else None\n",
    "        self.doc_ids = []\n",
    "        self.target_noise_ids = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.doc_ids)\n",
    "\n",
    "    def torch_(self):\n",
    "        if self.context_ids is not None:\n",
    "            self.context_ids = torch.LongTensor(self.context_ids)\n",
    "        self.doc_ids = torch.LongTensor(self.doc_ids)\n",
    "        self.target_noise_ids = torch.LongTensor(self.target_noise_ids)\n",
    "\n",
    "    def cuda_(self):\n",
    "        if self.context_ids is not None:\n",
    "            self.context_ids = self.context_ids.cuda()\n",
    "        self.doc_ids = self.doc_ids.cuda()\n",
    "        self.target_noise_ids = self.target_noise_ids.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NegativeSampling(nn.Module):\n",
    "    \"\"\"Negative sampling loss as proposed by T. Mikolov et al. in Distributed\n",
    "    Representations of Words and Phrases and their Compositionality.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(NegativeSampling, self).__init__()\n",
    "        self._log_sigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, scores):\n",
    "        \"\"\"Computes the value of the loss function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        scores: autograd.Variable of size (batch_size, num_noise_words + 1)\n",
    "            Sparse unnormalized log probabilities. The first element in each\n",
    "            row is the ground truth score (i.e. the target), other elements\n",
    "            are scores of samples from the noise distribution.\n",
    "        \"\"\"\n",
    "        k = scores.size()[1] - 1\n",
    "        return -torch.sum(\n",
    "            self._log_sigmoid(scores[:, 0])\n",
    "            + torch.sum(self._log_sigmoid(-scores[:, 1:]), dim=1) / k\n",
    "        ) / scores.size()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DBOW(nn.Module):\n",
    "    \"\"\"Distributed Bag of Words version of Paragraph Vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec_dim: int\n",
    "        Dimensionality of vectors to be learned (for paragraphs and words).\n",
    "    num_docs: int\n",
    "        Number of documents in a dataset.\n",
    "    num_words: int\n",
    "        Number of distinct words in a daset (i.e. vocabulary size).\n",
    "    \"\"\"\n",
    "    def __init__(self, vec_dim, num_docs, num_words):\n",
    "        super(DBOW, self).__init__()\n",
    "        # paragraph matrix\n",
    "        self._D = nn.Parameter(\n",
    "            torch.randn(num_docs, vec_dim), requires_grad=True)\n",
    "        # output layer parameters\n",
    "        self._O = nn.Parameter(\n",
    "            torch.FloatTensor(vec_dim, num_words).zero_(), requires_grad=True)\n",
    "\n",
    "    def forward(self, doc_ids, target_noise_ids):\n",
    "        \"\"\"Sparse computation of scores (unnormalized log probabilities)\n",
    "        that should be passed to the negative sampling loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc_ids: torch.Tensor of size (batch_size,)\n",
    "            Document indices of paragraphs.\n",
    "        target_noise_ids: torch.Tensor of size (batch_size, num_noise_words + 1)\n",
    "            Vocabulary indices of target and noise words. The first element in\n",
    "            each row is the ground truth index (i.e. the target), other\n",
    "            elements are indices of samples from the noise distribution.\n",
    "        Returns\n",
    "        -------\n",
    "            autograd.Variable of size (batch_size, num_noise_words + 1)\n",
    "        \"\"\"\n",
    "        # sparse computation of scores (unnormalized log probabilities)\n",
    "        # for negative sampling\n",
    "        return torch.bmm(\n",
    "            self._D[doc_ids, :].unsqueeze(1),\n",
    "            self._O[:, target_noise_ids].permute(1, 0, 2)).squeeze()\n",
    "\n",
    "    def get_paragraph_vector(self, index):\n",
    "        return self._D[index, :].data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from os.path import join, dirname, isfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "_root_dir = \"model_data\"\n",
    "\n",
    "DATA_DIR = join(_root_dir, 'data')\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "MODELS_DIR = join(_root_dir, 'models')\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "_DIAGNOSTICS_DIR = join(_root_dir, 'diagnostics')\n",
    "if not os.path.exists(_DIAGNOSTICS_DIR):\n",
    "    os.mkdir(_DIAGNOSTICS_DIR)\n",
    "\n",
    "_DM_MODEL_NAME = (\"{:s}_model.{:s}.{:s}_contextsize.{:d}_numnoisewords.{:d}\"\n",
    "                  \"_vecdim.{:d}_batchsize.{:d}_lr.{:f}_epoch.{:d}_loss.{:f}\"\n",
    "                  \".pth.tar\")\n",
    "_DM_DIAGNOSTIC_FILE_NAME = (\"{:s}_model.{:s}.{:s}_contextsize.{:d}\"\n",
    "                            \"_numnoisewords.{:d}_vecdim.{:d}_batchsize.{:d}\"\n",
    "                            \"_lr.{:f}.csv\")\n",
    "_DBOW_MODEL_NAME = (\"{:s}_model.{:s}_numnoisewords.{:d}_vecdim.{:d}\"\n",
    "                    \"_batchsize.{:d}_lr.{:f}_epoch.{:d}_loss.{:f}.pth.tar\")\n",
    "_DBOW_DIAGNOSTIC_FILE_NAME = (\"{:s}_model.{:s}_numnoisewords.{:d}_vecdim.{:d}\"\n",
    "                              \"_batchsize.{:d}_lr.{:f}.csv\")\n",
    "\n",
    "\n",
    "def save_training_state(data_file_name,\n",
    "                        model_ver,\n",
    "                        vec_combine_method,\n",
    "                        context_size,\n",
    "                        num_noise_words,\n",
    "                        vec_dim,\n",
    "                        batch_size,\n",
    "                        lr,\n",
    "                        epoch_i,\n",
    "                        loss,\n",
    "                        model_state,\n",
    "                        save_all,\n",
    "                        generate_plot,\n",
    "                        is_best_loss,\n",
    "                        prev_model_file_path,\n",
    "                        model_ver_is_dbow):\n",
    "    \"\"\"Saves the state of the model. If generate_plot is True, it also\n",
    "    saves current epoch's loss value and generates a plot of all loss\n",
    "    values up to this epoch.\n",
    "    Returns\n",
    "    -------\n",
    "        str representing a model file path from the previous epoch\n",
    "    \"\"\"\n",
    "    if generate_plot:\n",
    "        diagnostic_file_name = _DBOW_DIAGNOSTIC_FILE_NAME.format(\n",
    "            data_file_name[:-4],\n",
    "            model_ver,\n",
    "            num_noise_words,\n",
    "            vec_dim,\n",
    "            batch_size,\n",
    "            lr)\n",
    "\n",
    "        diagnostic_file_path = join(_DIAGNOSTICS_DIR, diagnostic_file_name)\n",
    "\n",
    "        if epoch_i == 0 and isfile(diagnostic_file_path):\n",
    "            remove(diagnostic_file_path)\n",
    "\n",
    "        with open(diagnostic_file_path, 'a') as f:\n",
    "            f.write('{:f}\\n'.format(loss))\n",
    "\n",
    "        # generate a diagnostic loss plot\n",
    "        with open(diagnostic_file_path) as f:\n",
    "            loss_values = [float(l.rstrip()) for l in f.readlines()]\n",
    "\n",
    "        diagnostic_plot_file_path = diagnostic_file_path[:-3] + 'png'\n",
    "        fig = plt.figure()\n",
    "        plt.plot(range(1, epoch_i + 2), loss_values, color='r')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('training loss')\n",
    "        fig.savefig(diagnostic_plot_file_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # save the model\n",
    "\n",
    "    model_file_name = _DBOW_MODEL_NAME.format(\n",
    "        data_file_name[:-4],\n",
    "        model_ver,\n",
    "        num_noise_words,\n",
    "        vec_dim,\n",
    "        batch_size,\n",
    "        lr,\n",
    "        epoch_i + 1,\n",
    "        loss)\n",
    "    \n",
    "\n",
    "    model_file_path = join(MODELS_DIR, model_file_name)\n",
    "\n",
    "    if save_all:\n",
    "        torch.save(model_state, model_file_path)\n",
    "        return None\n",
    "    elif is_best_loss:\n",
    "        if prev_model_file_path is not None:\n",
    "            remove(prev_model_file_path)\n",
    "\n",
    "        torch.save(model_state, model_file_path)\n",
    "        return model_file_path\n",
    "    else:\n",
    "        return prev_model_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def start(data_file_name, model_file_name):\n",
    "    \"\"\"Saves trained paragraph vectors to a csv file in the *data* directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_file_name: str\n",
    "        Name of a file in the *data* directory that was used during training.\n",
    "    model_file_name: str\n",
    "        Name of a file in the *models* directory (a model trained on\n",
    "        the *data_file_name* dataset).\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(data_file_name)\n",
    "\n",
    "    vec_dim = int(re.search('_vecdim\\.(\\d+)_', model_file_name).group(1))\n",
    "\n",
    "    model = _load_model(\n",
    "        model_file_name,\n",
    "        vec_dim,\n",
    "        num_docs=len(dataset),\n",
    "        num_words=len(dataset.fields['text'].vocab) - 1)\n",
    "\n",
    "    _write_to_file(data_file_name, model_file_name, model, vec_dim)\n",
    "\n",
    "\n",
    "def _load_model(model_file_name, vec_dim, num_docs, num_words):\n",
    "    model_ver = re.search('_model\\.(dm|dbow)', model_file_name).group(1)\n",
    "    if model_ver is None:\n",
    "        raise ValueError(\"Model file name contains an invalid\"\n",
    "                         \"version of the model\")\n",
    "\n",
    "    model_file_path = join(MODELS_DIR, model_file_name)\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(model_file_path)\n",
    "    except RuntimeError:\n",
    "        checkpoint = torch.load(\n",
    "            model_file_path,\n",
    "            map_location=lambda storage, location: storage)\n",
    "\n",
    "    if model_ver == 'dbow':\n",
    "        model = DBOW(vec_dim, num_docs, num_words)\n",
    "    else:\n",
    "        model = DM(vec_dim, num_docs, num_words)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def _write_to_file(data_file_name, model_file_name, model, vec_dim):\n",
    "    result_lines = []\n",
    "\n",
    "    with open(join(DATA_DIR, data_file_name)) as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for i, line in enumerate(reader):\n",
    "            # skip text\n",
    "            result_line = line[1:]\n",
    "            if i == 0:\n",
    "                # header line\n",
    "                result_line += [\"d{:d}\".format(x) for x in range(vec_dim)]\n",
    "            else:\n",
    "                vector = model.get_paragraph_vector(i - 1)\n",
    "                result_line += [str(x) for x in vector]\n",
    "\n",
    "            result_lines.append(result_line)\n",
    "\n",
    "    result_file_name = model_file_name[:-7] + 'csv'\n",
    "\n",
    "    with open(join(DATA_DIR, result_file_name), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(result_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _print_progress(epoch_i, batch_i, num_batches):\n",
    "    progress = round((batch_i + 1) / num_batches * 100)\n",
    "    print(\"\\rEpoch {:d}\".format(epoch_i + 1), end='')\n",
    "    stdout.write(\" - {:d}%\".format(progress))\n",
    "    stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comprised of 485 documents.\n",
      "Vocabulary size is 6433.\n",
      "\n",
      "Training started.\n",
      "Epoch 1 - 100% 1% - 1% - 1% - 2% - 2% - 3% - 3% - 4% - 4% - 4% - 4% - 4% - 9% - 11% - 15% - 15% - 15% - 16% - 16% - 19% - 21% - 21% - 21% - 21% - 21% - 21% - 21% - 21% - 23% - 24% - 25% - 25% - 25% - 25% - 27% - 28% - 28% - 28% - 28% - 30% - 31% - 31% - 31% - 32% - 34% - 34% - 35% - 36% - 37% - 37% - 37% - 38% - 38% - 38% - 38% - 38% - 42% - 44% - 45% - 45% - 46% - 46% - 46% - 46% - 46% - 47% - 48% - 48% - 49% - 51% - 51% - 57% - 58% - 58% - 58% - 58% - 58% - 60% - 60% - 60% - 60% - 60% - 61% - 61% - 63% - 64% - 65% - 65% - 68% - 68% - 71% - 71% - 72% - 72% - 72% - 72% - 73% - 78% - 78% - 79% - 79% - 79% - 79% - 81% - 88% - 88% - 88% - 89% - 89% - 89% - 89% - 90% - 91% - 92% - 92% - 92% - 93% - 93% - 95% - 98% - 99% - 99% - 99% - 100% (80s) - loss: 1.3556\n",
      "Epoch 2 - 100% 3% - 4% - 4% - 6% - 7% - 10% - 12% - 14% - 15% - 17% - 17% - 17% - 18% - 18% - 18% - 18% - 19% - 21% - 22% - 22% - 22% - 22% - 23% - 24% - 24% - 24% - 24% - 25% - 26% - 26% - 26% - 26% - 28% - 28% - 29% - 29% - 29% - 29% - 29% - 29% - 30% - 40% - 40% - 40% - 42% - 43% - 45% - 45% - 49% - 50% - 50% - 50% - 51% - 51% - 51% - 51% - 51% - 52% - 53% - 53% - 55% - 55% - 55% - 55% - 55% - 56% - 56% - 56% - 57% - 57% - 57% - 57% - 57% - 57% - 58% - 59% - 60% - 62% - 63% - 70% - 75% - 75% - 75% - 75% - 76% - 76% - 76% - 80% - 80% - 81% - 89% - 91% - 94% - 95% - 97% - 97% - 98% - 98% (78s) - loss: 1.1701\n",
      "Epoch 3 - 100% 4% - 4% - 4% - 7% - 7% - 9% - 9% - 9% - 9% - 12% - 13% - 14% - 18% - 24% - 27% - 28% - 33% - 35% - 35% - 37% - 39% - 39% - 39% - 40% - 41% - 41% - 43% - 43% - 43% - 45% - 47% - 47% - 49% - 51% - 53% - 58% - 60% - 62% - 63% - 64% - 64% - 64% - 64% - 70% - 70% - 70% - 71% - 71% - 71% - 73% - 73% - 73% - 73% - 76% - 76% - 78% - 78% - 90% - 94% - 96% - 97% - 97% - 99% (78s) - loss: 1.0444\n",
      "Epoch 4 - 100% 2% - 2% - 4% - 5% - 13% - 14% - 14% - 15% - 16% - 16% - 23% - 23% - 23% - 25% - 25% - 25% - 28% - 29% - 29% - 29% - 29% - 29% - 29% - 29% - 30% - 31% - 31% - 32% - 32% - 32% - 33% - 36% - 37% - 37% - 39% - 39% - 45% - 48% - 50% - 52% - 53% - 53% - 54% - 56% - 56% - 56% - 57% - 58% - 58% - 59% - 59% - 59% - 59% - 59% - 59% - 59% - 60% - 62% - 63% - 63% - 65% - 65% - 65% - 68% - 68% - 71% - 72% - 72% - 73% - 74% - 75% - 75% - 79% - 79% - 79% - 81% - 81% - 81% - 81% - 85% - 86% - 86% - 86% - 86% - 86% - 87% - 90% - 90% - 90% - 90% - 90% - 90% - 91% - 91% - 92% - 94% - 94% - 94% - 94% - 94% - 94% - 94% - 94% - 96% - 98% - 98% - 99% - 100% - 100% (78s) - loss: 0.9639\n",
      "Epoch 5 - 100% 5% - 5% - 5% - 8% - 12% - 16% - 21% - 21% - 21% - 21% - 22% - 27% - 30% - 37% - 37% - 41% - 43% - 44% - 45% - 45% - 45% - 45% - 51% - 52% - 53% - 53% - 54% - 55% - 55% - 55% - 56% - 56% - 57% - 57% - 58% - 58% - 58% - 60% - 60% - 60% - 60% - 65% - 67% - 71% - 72% - 73% - 81% - 81% - 87% - 88% - 88% - 90% - 90% - 91% - 91% - 91% - 92% - 92% - 93% - 93% - 95% - 95% - 96% - 96% - 96% (78s) - loss: 0.9180\n",
      "Epoch 6 - 100% 1% - 2% - 2% - 2% - 2% - 4% - 4% - 7% - 8% - 8% - 10% - 10% - 10% - 10% - 10% - 10% - 10% - 11% - 12% - 12% - 13% - 13% - 16% - 17% - 18% - 18% - 18% - 19% - 19% - 23% - 24% - 24% - 24% - 24% - 26% - 29% - 30% - 39% - 41% - 42% - 42% - 42% - 43% - 43% - 44% - 44% - 45% - 45% - 45% - 45% - 45% - 45% - 45% - 45% - 45% - 46% - 47% - 48% - 48% - 50% - 51% - 51% - 52% - 57% - 58% - 59% - 64% - 65% - 69% - 69% - 70% - 73% - 73% - 74% - 74% - 74% - 76% - 78% - 78% - 82% - 85% - 87% - 87% - 88% - 91% - 92% - 92% - 92% - 93% - 98% - 99% (78s) - loss: 0.8887\n",
      "Epoch 7 - 100% 1% - 1% - 5% - 6% - 7% - 10% - 10% - 11% - 11% - 11% - 14% - 15% - 15% - 18% - 18% - 18% - 20% - 21% - 21% - 22% - 23% - 29% - 31% - 32% - 40% - 41% - 42% - 42% - 42% - 43% - 45% - 46% - 47% - 49% - 51% - 51% - 51% - 52% - 54% - 55% - 55% - 56% - 57% - 57% - 60% - 61% - 61% - 62% - 62% - 62% - 63% - 67% - 67% - 67% - 79% - 82% - 83% - 83% - 85% - 87% - 87% - 90% - 91% - 91% - 93% - 96% - 96% - 96% - 96% - 99% - 99% - 99% - 99% - 99% - 99% (78s) - loss: 0.8664\n",
      "Epoch 8 - 100% 1% - 1% - 1% - 2% - 4% - 5% - 5% - 5% - 6% - 7% - 9% - 9% - 9% - 9% - 9% - 10% - 11% - 11% - 12% - 12% - 14% - 14% - 14% - 15% - 15% - 16% - 16% - 19% - 20% - 20% - 23% - 25% - 25% - 25% - 26% - 26% - 27% - 27% - 27% - 27% - 27% - 28% - 28% - 28% - 29% - 29% - 30% - 32% - 33% - 34% - 34% - 34% - 35% - 35% - 39% - 39% - 42% - 47% - 47% - 47% - 47% - 47% - 47% - 52% - 54% - 56% - 58% - 60% - 61% - 62% - 62% - 62% - 63% - 63% - 63% - 64% - 66% - 66% - 67% - 67% - 67% - 67% - 67% - 67% - 68% - 68% - 75% - 75% - 75% - 76% - 76% - 76% - 76% - 77% - 77% - 77% - 79% - 79% - 79% - 80% - 83% - 84% - 85% - 87% - 88% - 89% - 90% - 91% - 91% - 91% - 92% - 92% - 93% - 94% - 95% - 96% - 99% (78s) - loss: 0.8529\n",
      "Epoch 9 - 100% 0% - 2% - 3% - 3% - 4% - 4% - 5% - 5% - 5% - 6% - 6% - 6% - 6% - 7% - 7% - 8% - 8% - 9% - 12% - 14% - 16% - 17% - 17% - 18% - 19% - 20% - 23% - 23% - 24% - 26% - 26% - 26% - 26% - 29% - 39% - 39% - 41% - 41% - 42% - 42% - 42% - 42% - 43% - 45% - 45% - 45% - 47% - 47% - 51% - 57% - 57% - 61% - 62% - 64% - 65% - 67% - 69% - 72% - 74% - 77% - 78% - 83% - 83% - 83% - 84% - 84% - 84% - 84% - 84% - 87% - 88% - 88% - 88% - 88% - 89% - 89% - 89% - 91% - 92% - 92% - 92% - 92% - 93% - 93% - 93% - 93% - 93% - 94% - 94% - 94% - 94% - 94% - 96% - 97% (78s) - loss: 0.8407\n",
      "Epoch 10 - 100% 1% - 2% - 5% - 7% - 9% - 9% - 11% - 11% - 12% - 15% - 16% - 16% - 16% - 17% - 17% - 17% - 17% - 19% - 19% - 20% - 20% - 22% - 22% - 23% - 23% - 26% - 26% - 26% - 26% - 26% - 28% - 29% - 29% - 29% - 29% - 31% - 31% - 32% - 32% - 32% - 32% - 32% - 34% - 34% - 34% - 38% - 38% - 39% - 42% - 42% - 43% - 44% - 45% - 46% - 47% - 50% - 50% - 50% - 50% - 50% - 50% - 52% - 52% - 53% - 56% - 56% - 56% - 58% - 58% - 62% - 64% - 67% - 67% - 68% - 68% - 68% - 68% - 68% - 68% - 68% - 68% - 69% - 73% - 74% - 74% - 76% - 76% - 78% - 79% - 80% - 86% - 86% - 87% - 88% - 88% - 88% - 89% - 89% - 94% (78s) - loss: 0.8337\n",
      "Epoch 11 - 100% 1% - 2% - 2% - 2% - 2% - 2% - 2% - 2% - 6% - 6% - 8% - 8% - 8% - 8% - 8% - 8% - 8% - 8% - 8% - 8% - 9% - 9% - 12% - 13% - 13% - 14% - 14% - 14% - 14% - 14% - 14% - 14% - 15% - 15% - 18% - 19% - 20% - 25% - 25% - 25% - 30% - 31% - 34% - 34% - 38% - 39% - 40% - 41% - 41% - 41% - 41% - 42% - 42% - 45% - 45% - 45% - 47% - 47% - 47% - 48% - 55% - 55% - 56% - 57% - 58% - 59% - 62% - 69% - 69% - 69% - 74% - 79% - 88% - 89% - 90% - 90% - 90% - 91% - 91% - 92% - 92% - 92% - 92% - 95% - 95% - 95% - 97% - 98% (78s) - loss: 0.8265\n",
      "Epoch 12 - 100% 2% - 2% - 5% - 5% - 5% - 5% - 7% - 8% - 9% - 9% - 9% - 9% - 9% - 11% - 11% - 13% - 14% - 14% - 15% - 19% - 20% - 20% - 20% - 20% - 20% - 21% - 21% - 21% - 21% - 28% - 28% - 28% - 30% - 30% - 31% - 32% - 36% - 37% - 37% - 41% - 42% - 42% - 42% - 44% - 44% - 47% - 48% - 50% - 51% - 51% - 52% - 52% - 53% - 53% - 53% - 54% - 57% - 57% - 59% - 60% - 63% - 63% - 64% - 64% - 66% - 69% - 70% - 70% - 70% - 72% - 73% - 75% - 76% - 76% - 77% - 78% - 79% - 79% - 79% - 79% - 79% - 79% - 79% - 80% - 80% - 80% - 81% - 83% - 83% - 85% - 86% - 86% - 87% - 90% - 90% - 90% - 91% - 91% - 92% - 94% - 94% - 94% - 95% - 96% - 97% - 97% - 97% - 97% - 97% - 98% - 99% (78s) - loss: 0.8189\n",
      "Epoch 13 - 100% 1% - 1% - 1% - 2% - 4% - 5% - 6% - 10% - 12% - 12% - 13% - 14% - 14% - 14% - 17% - 18% - 18% - 18% - 19% - 19% - 24% - 25% - 26% - 27% - 27% - 30% - 30% - 30% - 30% - 32% - 32% - 32% - 32% - 32% - 32% - 34% - 35% - 35% - 36% - 36% - 37% - 37% - 41% - 41% - 41% - 42% - 42% - 42% - 45% - 45% - 51% - 55% - 55% - 56% - 56% - 57% - 58% - 60% - 63% - 63% - 63% - 73% - 75% - 75% - 75% - 75% - 83% - 83% - 85% - 86% - 86% - 86% - 86% - 86% - 88% - 88% - 88% - 88% - 89% - 91% - 92% - 92% - 93% - 94% - 95% - 98% - 99% (78s) - loss: 0.8140\n",
      "Epoch 14 - 100% 0% - 2% - 4% - 4% - 4% - 4% - 5% - 5% - 5% - 5% - 5% - 6% - 7% - 8% - 11% - 11% - 11% - 12% - 12% - 12% - 15% - 15% - 15% - 15% - 19% - 23% - 26% - 28% - 28% - 28% - 34% - 34% - 35% - 37% - 37% - 39% - 40% - 40% - 41% - 41% - 41% - 41% - 41% - 41% - 46% - 47% - 47% - 48% - 49% - 50% - 52% - 55% - 56% - 56% - 56% - 57% - 58% - 58% - 60% - 60% - 60% - 60% - 60% - 60% - 63% - 63% - 63% - 65% - 66% - 66% - 67% - 67% - 67% - 68% - 68% - 68% - 69% - 70% - 71% - 71% - 74% - 75% - 76% - 77% - 78% - 78% - 78% - 80% - 80% - 80% - 81% - 82% - 82% - 82% - 83% - 83% - 83% - 83% - 84% - 84% - 85% - 85% - 85% - 86% - 87% - 88% - 90% - 90% - 92% - 93% - 93% - 93% - 93% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 95% - 95% - 96% - 96% - 96% - 96% - 97% - 99% - 99% (79s) - loss: 0.8093\n",
      "Epoch 15 - 100% 0% - 1% - 2% - 2% - 4% - 4% - 5% - 6% - 8% - 9% - 9% - 9% - 9% - 9% - 9% - 10% - 12% - 12% - 13% - 15% - 15% - 15% - 16% - 17% - 17% - 17% - 17% - 17% - 17% - 17% - 21% - 23% - 23% - 24% - 26% - 27% - 27% - 28% - 28% - 28% - 28% - 28% - 28% - 33% - 36% - 37% - 38% - 38% - 39% - 39% - 42% - 42% - 42% - 42% - 45% - 46% - 46% - 49% - 52% - 52% - 55% - 55% - 60% - 63% - 63% - 66% - 68% - 68% - 71% - 71% - 71% - 75% - 75% - 76% - 78% - 78% - 78% - 78% - 78% - 78% - 78% - 78% - 79% - 79% - 80% - 80% - 81% - 81% - 82% - 82% - 84% - 86% - 87% - 89% - 89% - 89% - 90% - 90% - 90% - 91% - 93% - 93% - 93% - 93% - 93% - 93% - 94% - 95% - 97% - 97% - 99% - 99% - 99% - 99% (78s) - loss: 0.8061\n",
      "Epoch 16 - 100% 2% - 2% - 3% - 3% - 4% - 4% - 4% - 5% - 5% - 6% - 8% - 11% - 14% - 15% - 15% - 18% - 18% - 19% - 29% - 31% - 33% - 33% - 33% - 33% - 34% - 52% - 52% - 55% - 55% - 56% - 56% - 56% - 56% - 57% - 59% - 59% - 61% - 62% - 63% - 63% - 63% - 64% - 64% - 64% - 66% - 67% - 68% - 68% - 69% - 72% - 80% - 80% - 80% - 80% - 81% - 81% - 82% - 82% - 83% - 86% - 88% - 88% - 88% - 88% - 96% - 96% - 96% - 97% - 97% (77s) - loss: 0.8004\n",
      "Epoch 17 - 100% 2% - 2% - 3% - 3% - 4% - 4% - 4% - 7% - 8% - 10% - 14% - 17% - 18% - 20% - 20% - 22% - 24% - 24% - 24% - 24% - 25% - 29% - 29% - 29% - 29% - 31% - 35% - 36% - 36% - 36% - 39% - 40% - 40% - 43% - 43% - 45% - 45% - 48% - 48% - 50% - 51% - 51% - 51% - 51% - 51% - 54% - 54% - 55% - 56% - 57% - 58% - 61% - 62% - 63% - 64% - 64% - 64% - 64% - 64% - 66% - 67% - 71% - 72% - 73% - 73% - 73% - 73% - 75% - 75% - 75% - 75% - 75% - 75% - 76% - 76% - 78% - 79% - 81% - 82% - 84% - 84% - 85% - 85% - 85% - 85% - 87% - 87% - 87% - 88% - 88% - 88% - 88% - 92% - 92% - 92% - 93% - 93% - 97% - 97% (78s) - loss: 0.7990\n",
      "Epoch 18 - 100% 1% - 1% - 1% - 1% - 1% - 1% - 6% - 10% - 10% - 10% - 10% - 10% - 17% - 18% - 21% - 24% - 26% - 26% - 27% - 27% - 27% - 29% - 29% - 31% - 31% - 31% - 32% - 34% - 34% - 34% - 35% - 35% - 37% - 39% - 41% - 41% - 42% - 42% - 42% - 42% - 42% - 42% - 43% - 43% - 43% - 45% - 45% - 49% - 49% - 51% - 52% - 52% - 52% - 53% - 58% - 61% - 62% - 64% - 65% - 67% - 67% - 68% - 73% - 77% - 77% - 77% - 77% - 77% - 77% - 81% - 87% - 88% - 90% - 94% - 94% - 94% - 95% - 95% - 95% - 98% (78s) - loss: 0.7964\n",
      "Epoch 19 - 100% 3% - 3% - 3% - 3% - 3% - 5% - 6% - 7% - 7% - 9% - 15% - 15% - 16% - 16% - 18% - 23% - 23% - 23% - 23% - 25% - 25% - 25% - 29% - 29% - 29% - 30% - 30% - 32% - 32% - 33% - 33% - 34% - 36% - 36% - 36% - 36% - 37% - 37% - 37% - 38% - 41% - 42% - 42% - 43% - 43% - 52% - 55% - 57% - 57% - 64% - 64% - 67% - 67% - 67% - 67% - 68% - 69% - 69% - 69% - 69% - 71% - 72% - 76% - 78% - 81% - 82% - 82% - 82% - 82% - 82% - 82% - 82% - 87% - 89% - 91% - 94% - 95% - 97% (78s) - loss: 0.7913\n",
      "Epoch 20 - 100% 1% - 1% - 1% - 1% - 1% - 3% - 4% - 4% - 5% - 6% - 6% - 7% - 7% - 10% - 12% - 12% - 12% - 14% - 14% - 14% - 15% - 15% - 16% - 18% - 19% - 20% - 21% - 22% - 23% - 23% - 23% - 23% - 24% - 25% - 25% - 25% - 26% - 27% - 27% - 27% - 29% - 29% - 29% - 30% - 31% - 31% - 32% - 32% - 33% - 33% - 33% - 35% - 36% - 36% - 37% - 38% - 38% - 39% - 39% - 39% - 39% - 39% - 41% - 41% - 42% - 42% - 43% - 44% - 44% - 45% - 48% - 48% - 48% - 49% - 49% - 49% - 49% - 50% - 50% - 50% - 51% - 51% - 52% - 53% - 53% - 53% - 53% - 53% - 55% - 55% - 55% - 55% - 56% - 56% - 56% - 57% - 58% - 58% - 59% - 60% - 60% - 60% - 60% - 61% - 61% - 61% - 61% - 62% - 62% - 64% - 65% - 66% - 66% - 66% - 66% - 67% - 67% - 68% - 68% - 71% - 72% - 74% - 74% - 74% - 74% - 80% - 80% - 85% - 87% - 87% - 87% - 90% - 90% - 91% - 92% - 93% - 94% - 96% - 96% - 100% - 100% (78s) - loss: 0.7889\n",
      "Epoch 21 - 100% 3% - 3% - 6% - 11% - 11% - 11% - 11% - 12% - 18% - 18% - 21% - 23% - 26% - 26% - 27% - 28% - 30% - 38% - 42% - 42% - 42% - 43% - 43% - 45% - 49% - 51% - 55% - 60% - 60% - 60% - 60% - 60% - 60% - 63% - 64% - 64% - 64% - 65% - 67% - 67% - 68% - 70% - 71% - 73% - 73% - 73% - 74% - 74% - 75% - 75% - 76% - 82% - 82% - 83% - 84% - 84% - 85% - 85% - 86% - 87% - 88% - 89% - 91% - 93% - 93% - 93% - 93% - 94% - 95% - 95% - 95% - 96% - 96% (78s) - loss: 0.7885\n",
      "Epoch 22 - 100% 1% - 2% - 7% - 7% - 11% - 13% - 13% - 13% - 13% - 13% - 13% - 14% - 14% - 14% - 18% - 18% - 19% - 20% - 22% - 22% - 22% - 26% - 28% - 28% - 28% - 28% - 29% - 29% - 29% - 30% - 30% - 30% - 30% - 32% - 37% - 39% - 39% - 39% - 39% - 42% - 44% - 44% - 44% - 46% - 47% - 47% - 48% - 48% - 50% - 50% - 53% - 53% - 54% - 54% - 54% - 54% - 55% - 55% - 56% - 56% - 56% - 58% - 59% - 59% - 61% - 62% - 62% - 63% - 64% - 65% - 65% - 65% - 65% - 67% - 67% - 67% - 67% - 67% - 70% - 73% - 74% - 74% - 74% - 74% - 75% - 76% - 77% - 77% - 77% - 77% - 78% - 81% - 83% - 86% - 87% - 87% - 87% - 87% - 88% - 89% - 89% - 89% - 89% - 89% - 89% - 92% - 93% - 93% - 98% - 98% - 99% (78s) - loss: 0.7857\n",
      "Epoch 23 - 100% 2% - 3% - 4% - 4% - 4% - 4% - 5% - 6% - 6% - 7% - 11% - 12% - 12% - 13% - 14% - 14% - 16% - 17% - 19% - 21% - 21% - 21% - 21% - 21% - 21% - 24% - 28% - 28% - 29% - 29% - 30% - 30% - 30% - 31% - 31% - 31% - 31% - 31% - 31% - 31% - 34% - 34% - 34% - 36% - 36% - 36% - 37% - 39% - 40% - 40% - 42% - 44% - 46% - 46% - 47% - 51% - 51% - 56% - 56% - 56% - 56% - 58% - 58% - 59% - 59% - 59% - 59% - 60% - 64% - 65% - 65% - 66% - 66% - 66% - 67% - 67% - 70% - 70% - 70% - 73% - 73% - 74% - 74% - 74% - 76% - 76% - 77% - 77% - 79% - 80% - 80% - 80% - 80% - 83% - 88% - 89% - 92% - 95% - 99% - 100% (78s) - loss: 0.7835\n",
      "Epoch 24 - 100% 1% - 1% - 1% - 1% - 3% - 3% - 3% - 4% - 4% - 4% - 4% - 5% - 6% - 7% - 9% - 10% - 12% - 12% - 12% - 12% - 12% - 12% - 14% - 15% - 15% - 16% - 16% - 16% - 16% - 17% - 18% - 23% - 25% - 25% - 25% - 29% - 34% - 35% - 35% - 35% - 35% - 37% - 42% - 42% - 43% - 43% - 45% - 46% - 46% - 47% - 47% - 49% - 50% - 50% - 50% - 50% - 50% - 50% - 50% - 51% - 52% - 53% - 53% - 54% - 56% - 56% - 56% - 58% - 58% - 58% - 59% - 60% - 60% - 63% - 64% - 64% - 65% - 66% - 66% - 68% - 68% - 69% - 70% - 71% - 76% - 77% - 78% - 79% - 79% - 80% - 80% - 81% - 81% - 81% - 81% - 81% - 82% - 82% - 82% - 82% - 83% - 83% - 84% - 85% - 88% - 88% - 89% - 89% - 90% - 90% - 90% - 91% - 91% - 92% - 93% - 93% - 93% - 93% - 94% - 94% - 99% (78s) - loss: 0.7792\n",
      "Epoch 25 - 100% 1% - 1% - 4% - 4% - 4% - 6% - 6% - 11% - 14% - 14% - 14% - 16% - 17% - 17% - 18% - 18% - 18% - 19% - 21% - 22% - 22% - 22% - 22% - 22% - 22% - 28% - 28% - 28% - 28% - 29% - 29% - 29% - 29% - 29% - 29% - 32% - 33% - 33% - 34% - 36% - 36% - 36% - 36% - 37% - 37% - 37% - 37% - 37% - 37% - 40% - 40% - 41% - 42% - 43% - 45% - 45% - 47% - 50% - 55% - 58% - 59% - 65% - 66% - 66% - 66% - 67% - 67% - 67% - 67% - 68% - 69% - 70% - 70% - 72% - 72% - 72% - 72% - 72% - 72% - 73% - 74% - 74% - 75% - 75% - 75% - 79% - 79% - 80% - 81% - 81% - 81% - 81% - 81% - 81% - 82% - 82% - 83% - 85% - 85% - 88% - 89% - 90% - 90% - 90% - 90% - 90% - 90% - 90% - 91% - 93% - 94% - 95% - 95% - 95% - 95% - 100% - 100% - 100% (78s) - loss: 0.7810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - 100% 2% - 2% - 3% - 3% - 3% - 3% - 5% - 7% - 7% - 7% - 8% - 8% - 9% - 10% - 11% - 11% - 11% - 12% - 12% - 12% - 13% - 13% - 15% - 16% - 18% - 18% - 18% - 18% - 21% - 21% - 22% - 22% - 23% - 23% - 24% - 26% - 30% - 30% - 33% - 34% - 34% - 35% - 36% - 38% - 39% - 39% - 40% - 42% - 42% - 42% - 44% - 46% - 46% - 46% - 46% - 46% - 46% - 47% - 48% - 56% - 56% - 56% - 57% - 57% - 57% - 57% - 60% - 61% - 61% - 62% - 62% - 62% - 63% - 63% - 63% - 64% - 64% - 65% - 65% - 65% - 65% - 66% - 66% - 68% - 68% - 68% - 70% - 72% - 72% - 74% - 74% - 74% - 74% - 75% - 80% - 80% - 80% - 81% - 81% - 82% - 82% - 82% - 83% - 84% - 86% - 87% - 87% - 88% - 88% - 89% - 89% - 90% - 90% - 90% - 91% - 91% - 92% - 92% - 92% - 93% - 95% - 95% - 97% - 98% (79s) - loss: 0.7788\n",
      "Epoch 27 - 100% 0% - 0% - 1% - 1% - 1% - 2% - 2% - 3% - 3% - 3% - 3% - 4% - 4% - 4% - 9% - 9% - 10% - 10% - 11% - 12% - 12% - 12% - 13% - 17% - 17% - 17% - 19% - 20% - 21% - 22% - 22% - 22% - 22% - 22% - 23% - 23% - 26% - 27% - 27% - 29% - 29% - 29% - 34% - 34% - 34% - 36% - 36% - 36% - 37% - 37% - 38% - 38% - 39% - 39% - 40% - 43% - 43% - 43% - 43% - 44% - 44% - 46% - 46% - 47% - 48% - 49% - 49% - 49% - 50% - 50% - 52% - 54% - 55% - 56% - 56% - 60% - 61% - 61% - 61% - 61% - 61% - 63% - 63% - 64% - 64% - 65% - 67% - 72% - 79% - 81% - 81% - 81% - 82% - 82% - 83% - 85% - 85% - 85% - 86% - 86% - 87% - 87% - 91% - 94% - 94% - 94% - 95% - 97% - 97% - 99% (78s) - loss: 0.7771\n",
      "Epoch 28 - 100% 0% - 0% - 5% - 6% - 6% - 9% - 10% - 10% - 13% - 14% - 17% - 17% - 20% - 20% - 20% - 20% - 22% - 22% - 23% - 23% - 27% - 28% - 28% - 31% - 31% - 31% - 32% - 34% - 34% - 34% - 37% - 37% - 37% - 37% - 37% - 38% - 40% - 40% - 41% - 42% - 43% - 47% - 52% - 52% - 53% - 53% - 62% - 62% - 62% - 62% - 62% - 62% - 66% - 67% - 68% - 70% - 73% - 74% - 75% - 75% - 76% - 80% - 80% - 81% - 81% - 84% - 86% - 89% - 90% - 91% - 91% - 91% - 92% - 92% - 92% - 92% - 92% - 96% - 96% - 97% - 98% - 98% - 98% - 99% (78s) - loss: 0.7756\n",
      "Epoch 29 - 100% 3% - 5% - 5% - 6% - 6% - 6% - 10% - 12% - 15% - 19% - 19% - 19% - 21% - 21% - 23% - 24% - 26% - 28% - 28% - 28% - 28% - 29% - 31% - 32% - 32% - 32% - 33% - 33% - 33% - 38% - 38% - 38% - 38% - 40% - 41% - 41% - 42% - 45% - 47% - 47% - 47% - 47% - 59% - 61% - 61% - 61% - 61% - 67% - 68% - 69% - 70% - 71% - 72% - 72% - 72% - 74% - 75% - 78% - 78% - 79% - 79% - 80% - 81% - 85% - 86% - 88% - 88% - 88% - 88% - 88% - 88% - 90% - 90% - 91% - 95% - 96% - 96% - 96% - 96% - 97% - 98% - 98% - 99% (78s) - loss: 0.7734\n",
      "Epoch 30 - 100% 0% - 0% - 1% - 2% - 2% - 4% - 6% - 13% - 16% - 16% - 18% - 20% - 20% - 21% - 21% - 22% - 22% - 23% - 23% - 23% - 29% - 30% - 31% - 31% - 31% - 31% - 31% - 32% - 34% - 34% - 35% - 36% - 36% - 38% - 38% - 38% - 39% - 39% - 40% - 41% - 43% - 43% - 43% - 43% - 45% - 45% - 45% - 46% - 46% - 48% - 49% - 49% - 51% - 52% - 52% - 52% - 52% - 53% - 53% - 53% - 53% - 53% - 53% - 53% - 53% - 53% - 53% - 54% - 54% - 54% - 54% - 55% - 55% - 55% - 55% - 57% - 57% - 58% - 59% - 60% - 62% - 62% - 62% - 65% - 65% - 65% - 65% - 65% - 71% - 75% - 75% - 75% - 76% - 77% - 81% - 87% - 87% - 88% - 88% - 88% - 88% - 90% - 90% - 95% - 95% - 95% - 99% - 99% - 100% (78s) - loss: 0.7739\n",
      "Epoch 31 - 100% 9% - 11% - 11% - 12% - 12% - 14% - 15% - 16% - 16% - 17% - 18% - 19% - 19% - 19% - 19% - 20% - 20% - 21% - 21% - 21% - 22% - 23% - 23% - 24% - 24% - 27% - 27% - 28% - 29% - 29% - 29% - 30% - 30% - 31% - 31% - 32% - 33% - 33% - 34% - 35% - 41% - 41% - 45% - 45% - 47% - 48% - 48% - 50% - 50% - 50% - 53% - 55% - 57% - 57% - 58% - 59% - 59% - 65% - 66% - 66% - 66% - 66% - 66% - 66% - 68% - 71% - 71% - 72% - 73% - 73% - 74% - 75% - 75% - 79% - 80% - 81% - 83% - 83% - 87% - 88% - 89% - 90% - 94% - 94% - 95% - 96% - 97% - 99% (78s) - loss: 0.7735\n",
      "Epoch 32 - 100% 2% - 2% - 2% - 3% - 3% - 5% - 5% - 5% - 7% - 8% - 9% - 10% - 11% - 11% - 11% - 12% - 12% - 13% - 18% - 19% - 20% - 21% - 21% - 22% - 22% - 22% - 24% - 24% - 24% - 24% - 24% - 24% - 25% - 26% - 27% - 30% - 31% - 31% - 32% - 32% - 32% - 32% - 32% - 34% - 36% - 36% - 36% - 36% - 36% - 37% - 37% - 38% - 38% - 41% - 41% - 41% - 41% - 41% - 43% - 43% - 54% - 56% - 56% - 59% - 68% - 70% - 70% - 71% - 72% - 72% - 73% - 74% - 74% - 75% - 75% - 79% - 81% - 82% - 83% - 87% - 88% - 90% - 95% - 96% (78s) - loss: 0.7705\n",
      "Epoch 33 - 100% 1% - 1% - 2% - 3% - 6% - 6% - 6% - 6% - 6% - 7% - 9% - 20% - 20% - 20% - 22% - 22% - 22% - 22% - 25% - 29% - 29% - 34% - 34% - 35% - 38% - 40% - 40% - 41% - 41% - 41% - 45% - 45% - 46% - 48% - 50% - 52% - 52% - 55% - 55% - 55% - 58% - 58% - 61% - 63% - 64% - 64% - 64% - 64% - 70% - 70% - 73% - 73% - 73% - 78% - 78% - 78% - 79% - 79% - 79% - 79% - 79% - 84% - 87% - 89% - 91% - 91% - 91% - 92% - 92% (78s) - loss: 0.7695\n",
      "Epoch 34 - 100% 6% - 7% - 7% - 14% - 18% - 23% - 26% - 26% - 26% - 29% - 29% - 30% - 30% - 30% - 32% - 33% - 33% - 33% - 37% - 38% - 38% - 42% - 44% - 45% - 45% - 46% - 48% - 49% - 51% - 53% - 53% - 56% - 57% - 58% - 58% - 58% - 58% - 59% - 59% - 59% - 59% - 59% - 64% - 64% - 65% - 65% - 66% - 66% - 66% - 67% - 69% - 74% - 74% - 74% - 75% - 75% - 75% - 76% - 76% - 76% - 79% - 84% - 84% - 84% - 84% - 84% - 85% - 87% - 89% - 89% - 90% - 92% - 92% - 92% - 93% - 93% - 94% - 95% - 95% - 95% - 95% - 95% - 95% - 95% - 97% - 99% (78s) - loss: 0.7704\n",
      "Epoch 35 - 100% 4% - 4% - 6% - 6% - 7% - 7% - 9% - 15% - 15% - 15% - 16% - 16% - 21% - 21% - 21% - 21% - 22% - 23% - 24% - 25% - 26% - 26% - 26% - 26% - 28% - 29% - 29% - 29% - 29% - 30% - 31% - 31% - 31% - 31% - 35% - 35% - 38% - 38% - 40% - 50% - 54% - 58% - 58% - 58% - 60% - 61% - 61% - 64% - 64% - 67% - 68% - 73% - 77% - 78% - 78% - 78% - 78% - 78% - 78% - 79% - 79% - 80% - 84% - 85% - 85% - 85% - 87% - 87% - 91% - 91% - 91% - 93% - 93% - 97% - 97% - 97% - 97% - 99% (78s) - loss: 0.7688\n",
      "Epoch 36 - 100% 2% - 2% - 2% - 6% - 6% - 8% - 8% - 8% - 8% - 9% - 9% - 9% - 9% - 10% - 10% - 11% - 12% - 12% - 12% - 13% - 13% - 15% - 17% - 17% - 17% - 17% - 17% - 18% - 19% - 20% - 20% - 20% - 21% - 21% - 21% - 21% - 21% - 21% - 22% - 22% - 25% - 25% - 25% - 27% - 27% - 29% - 32% - 32% - 32% - 33% - 34% - 34% - 36% - 36% - 37% - 37% - 37% - 41% - 42% - 42% - 43% - 44% - 45% - 45% - 45% - 47% - 48% - 49% - 50% - 50% - 51% - 51% - 51% - 52% - 56% - 56% - 56% - 56% - 57% - 57% - 62% - 65% - 67% - 68% - 68% - 70% - 71% - 72% - 74% - 79% - 79% - 79% - 81% - 81% - 82% - 82% - 82% - 82% - 83% - 83% - 84% - 84% - 85% - 87% - 87% - 87% - 87% - 87% - 87% - 90% - 93% - 93% - 93% - 94% - 96% - 96% - 97% - 97% - 98% - 99% (78s) - loss: 0.7687\n",
      "Epoch 37 - 100% 3% - 3% - 3% - 4% - 4% - 7% - 8% - 10% - 13% - 13% - 15% - 15% - 17% - 17% - 18% - 18% - 20% - 23% - 27% - 27% - 27% - 27% - 27% - 27% - 27% - 30% - 32% - 32% - 32% - 32% - 32% - 33% - 36% - 39% - 39% - 39% - 39% - 41% - 43% - 44% - 45% - 45% - 46% - 46% - 46% - 48% - 48% - 48% - 49% - 51% - 52% - 54% - 57% - 57% - 57% - 58% - 58% - 58% - 58% - 59% - 60% - 60% - 61% - 61% - 65% - 70% - 70% - 71% - 72% - 73% - 73% - 74% - 74% - 74% - 76% - 76% - 78% - 80% - 80% - 80% - 83% - 88% - 88% - 92% - 92% - 92% - 93% - 94% - 94% - 95% - 95% - 97% - 99% (78s) - loss: 0.7676\n",
      "Epoch 38 - 100% 4% - 5% - 5% - 5% - 5% - 5% - 6% - 6% - 7% - 7% - 8% - 9% - 10% - 10% - 10% - 11% - 12% - 14% - 14% - 14% - 16% - 17% - 17% - 18% - 18% - 19% - 30% - 31% - 31% - 31% - 31% - 31% - 31% - 31% - 35% - 36% - 36% - 38% - 41% - 41% - 43% - 45% - 46% - 48% - 52% - 52% - 53% - 54% - 54% - 54% - 54% - 54% - 55% - 55% - 55% - 55% - 56% - 57% - 57% - 57% - 61% - 61% - 61% - 62% - 62% - 62% - 63% - 65% - 65% - 66% - 66% - 68% - 68% - 68% - 71% - 72% - 79% - 81% - 82% - 82% - 83% - 83% - 83% - 83% - 84% - 88% - 90% - 90% - 90% - 92% - 94% - 95% - 95% - 96% - 96% (78s) - loss: 0.7659\n",
      "Epoch 39 - 100% 3% - 4% - 12% - 16% - 16% - 16% - 16% - 16% - 16% - 16% - 18% - 20% - 21% - 21% - 21% - 26% - 33% - 34% - 35% - 35% - 37% - 41% - 41% - 43% - 43% - 47% - 48% - 50% - 54% - 54% - 56% - 59% - 62% - 62% - 63% - 63% - 63% - 64% - 64% - 64% - 64% - 64% - 65% - 65% - 66% - 67% - 72% - 74% - 77% - 77% - 81% - 82% - 88% - 88% - 88% - 88% - 93% - 98% - 99% - 100% (77s) - loss: 0.7659\n",
      "Epoch 40 - 100% 5% - 5% - 5% - 5% - 8% - 8% - 10% - 10% - 10% - 11% - 12% - 12% - 13% - 14% - 15% - 15% - 16% - 16% - 18% - 19% - 20% - 21% - 23% - 26% - 29% - 31% - 33% - 33% - 34% - 34% - 34% - 34% - 35% - 35% - 36% - 36% - 38% - 39% - 44% - 52% - 52% - 53% - 53% - 54% - 55% - 55% - 55% - 55% - 55% - 56% - 57% - 57% - 57% - 57% - 58% - 59% - 59% - 60% - 64% - 64% - 65% - 67% - 67% - 70% - 70% - 71% - 71% - 71% - 71% - 72% - 72% - 72% - 74% - 79% - 80% - 80% - 83% - 83% - 84% - 84% - 84% - 84% - 88% - 88% - 91% - 91% - 93% - 97% - 98% (78s) - loss: 0.7657\n",
      "Epoch 41 - 100% 2% - 3% - 5% - 5% - 5% - 6% - 6% - 6% - 6% - 7% - 7% - 7% - 7% - 12% - 15% - 17% - 17% - 17% - 19% - 29% - 29% - 30% - 35% - 35% - 35% - 38% - 39% - 40% - 40% - 40% - 42% - 44% - 45% - 47% - 55% - 58% - 58% - 59% - 60% - 61% - 62% - 62% - 62% - 63% - 64% - 65% - 65% - 71% - 73% - 76% - 78% - 79% - 80% - 80% - 86% - 87% - 87% - 88% - 88% - 88% - 91% - 91% - 91% - 92% - 93% - 93% - 98% - 98% - 98% - 98% (78s) - loss: 0.7638\n",
      "Epoch 42 - 100% 4% - 5% - 5% - 7% - 8% - 10% - 10% - 11% - 11% - 12% - 12% - 12% - 13% - 15% - 21% - 22% - 22% - 23% - 24% - 26% - 29% - 31% - 31% - 31% - 32% - 33% - 34% - 35% - 35% - 36% - 36% - 36% - 38% - 38% - 41% - 41% - 42% - 42% - 42% - 44% - 45% - 45% - 46% - 47% - 47% - 47% - 48% - 49% - 49% - 49% - 49% - 51% - 51% - 52% - 53% - 54% - 54% - 54% - 54% - 54% - 54% - 55% - 55% - 55% - 56% - 59% - 60% - 61% - 62% - 62% - 63% - 64% - 64% - 65% - 65% - 65% - 65% - 66% - 67% - 67% - 67% - 68% - 68% - 68% - 69% - 74% - 75% - 75% - 75% - 76% - 76% - 76% - 76% - 76% - 79% - 79% - 79% - 81% - 87% - 88% - 88% - 89% - 91% - 91% - 91% - 91% - 91% - 92% - 94% - 94% - 94% - 94% - 96% - 97% (79s) - loss: 0.7647\n",
      "Epoch 43 - 100% 1% - 3% - 6% - 9% - 9% - 9% - 9% - 10% - 10% - 13% - 13% - 17% - 18% - 18% - 18% - 18% - 18% - 18% - 19% - 23% - 23% - 24% - 25% - 26% - 27% - 27% - 27% - 27% - 28% - 30% - 30% - 30% - 30% - 30% - 31% - 31% - 31% - 32% - 33% - 34% - 34% - 35% - 35% - 36% - 38% - 38% - 39% - 39% - 40% - 40% - 40% - 40% - 41% - 42% - 42% - 43% - 45% - 46% - 51% - 51% - 51% - 52% - 52% - 54% - 56% - 57% - 60% - 62% - 66% - 67% - 67% - 67% - 68% - 72% - 75% - 77% - 79% - 80% - 80% - 83% - 84% - 84% - 85% - 85% - 86% - 86% - 95% - 95% - 95% - 95% - 96% - 96% - 96% - 96% - 96% - 96% - 96% - 100% (78s) - loss: 0.7632\n",
      "Epoch 44 - 100% 2% - 5% - 5% - 7% - 7% - 9% - 10% - 11% - 14% - 14% - 14% - 15% - 15% - 15% - 20% - 21% - 21% - 21% - 21% - 22% - 22% - 24% - 24% - 25% - 29% - 29% - 29% - 32% - 32% - 33% - 34% - 34% - 35% - 36% - 36% - 37% - 40% - 40% - 41% - 41% - 44% - 44% - 45% - 45% - 45% - 45% - 45% - 45% - 50% - 50% - 50% - 50% - 52% - 54% - 54% - 56% - 56% - 57% - 57% - 60% - 60% - 60% - 60% - 60% - 60% - 60% - 60% - 61% - 64% - 66% - 66% - 66% - 67% - 71% - 73% - 75% - 77% - 80% - 80% - 80% - 82% - 82% - 86% - 87% - 95% - 95% - 95% - 96% - 97% - 98% - 98% - 98% - 98% (78s) - loss: 0.7618\n",
      "Epoch 45 - 100% 1% - 1% - 3% - 11% - 13% - 14% - 14% - 20% - 21% - 21% - 23% - 25% - 27% - 29% - 29% - 37% - 38% - 39% - 40% - 40% - 40% - 43% - 43% - 43% - 43% - 44% - 45% - 45% - 45% - 46% - 48% - 50% - 55% - 56% - 56% - 60% - 60% - 63% - 63% - 65% - 70% - 70% - 70% - 70% - 73% - 74% - 74% - 76% - 76% - 85% - 90% - 91% - 94% - 95% - 96% - 96% - 96% - 96% - 96% - 99% (78s) - loss: 0.7616\n",
      "Epoch 46 - 100% 0% - 1% - 3% - 3% - 3% - 3% - 4% - 4% - 4% - 4% - 9% - 9% - 9% - 13% - 13% - 13% - 13% - 15% - 18% - 19% - 19% - 19% - 19% - 19% - 19% - 21% - 21% - 21% - 22% - 22% - 22% - 25% - 26% - 26% - 29% - 29% - 32% - 33% - 33% - 37% - 39% - 40% - 40% - 42% - 42% - 43% - 43% - 43% - 45% - 45% - 46% - 46% - 46% - 46% - 46% - 46% - 46% - 50% - 51% - 51% - 51% - 53% - 53% - 54% - 55% - 59% - 59% - 65% - 70% - 74% - 74% - 75% - 75% - 77% - 78% - 78% - 78% - 80% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 82% - 83% - 84% - 84% - 85% - 85% - 85% - 85% - 86% - 86% - 86% - 87% - 87% - 88% - 90% - 90% - 91% - 92% - 93% - 93% - 93% - 93% - 94% - 95% - 95% - 95% (78s) - loss: 0.7621\n",
      "Epoch 47 - 100% 1% - 2% - 4% - 4% - 4% - 5% - 5% - 5% - 5% - 7% - 8% - 8% - 8% - 8% - 14% - 16% - 16% - 17% - 17% - 17% - 17% - 17% - 17% - 17% - 18% - 18% - 18% - 18% - 18% - 18% - 21% - 24% - 24% - 24% - 25% - 25% - 25% - 25% - 25% - 26% - 26% - 27% - 27% - 27% - 27% - 28% - 28% - 28% - 30% - 31% - 31% - 31% - 33% - 33% - 33% - 35% - 36% - 36% - 39% - 39% - 40% - 41% - 41% - 42% - 44% - 45% - 45% - 45% - 45% - 45% - 45% - 47% - 47% - 47% - 47% - 49% - 49% - 51% - 53% - 56% - 56% - 59% - 60% - 63% - 63% - 64% - 64% - 66% - 66% - 66% - 67% - 67% - 68% - 69% - 71% - 71% - 73% - 75% - 75% - 75% - 77% - 78% - 80% - 80% - 80% - 80% - 81% - 81% - 81% - 83% - 83% - 83% - 87% - 87% - 87% - 90% - 91% - 91% - 93% - 94% - 94% - 94% - 99% (78s) - loss: 0.7621\n",
      "Epoch 48 - 100% 0% - 1% - 1% - 1% - 2% - 2% - 2% - 2% - 3% - 7% - 7% - 10% - 11% - 11% - 11% - 14% - 14% - 16% - 16% - 16% - 16% - 17% - 18% - 18% - 22% - 23% - 23% - 23% - 23% - 30% - 30% - 30% - 30% - 30% - 40% - 42% - 42% - 42% - 47% - 51% - 52% - 52% - 52% - 56% - 56% - 56% - 56% - 57% - 57% - 59% - 60% - 60% - 61% - 62% - 63% - 63% - 65% - 68% - 68% - 69% - 69% - 73% - 73% - 74% - 75% - 75% - 76% - 77% - 78% - 78% - 79% - 79% - 83% - 83% - 83% - 83% - 83% - 84% - 84% - 84% - 86% - 86% - 86% - 87% - 88% - 88% - 89% - 89% - 89% - 89% - 90% - 90% - 96% - 98% - 99% - 99% - 99% - 99% - 99% (78s) - loss: 0.7605\n",
      "Epoch 49 - 100% 1% - 2% - 2% - 2% - 2% - 3% - 3% - 3% - 7% - 8% - 9% - 15% - 20% - 26% - 26% - 27% - 36% - 40% - 42% - 45% - 45% - 48% - 48% - 48% - 48% - 49% - 49% - 49% - 49% - 49% - 52% - 54% - 55% - 55% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 56% - 57% - 57% - 57% - 57% - 58% - 59% - 59% - 59% - 61% - 64% - 64% - 64% - 68% - 68% - 68% - 68% - 68% - 68% - 69% - 69% - 70% - 70% - 74% - 75% - 76% - 77% - 81% - 86% - 86% - 87% - 87% - 88% - 88% - 95% - 96% - 98% - 99% - 100% (78s) - loss: 0.7610\n",
      "Epoch 50 - 100% 3% - 5% - 11% - 14% - 15% - 15% - 20% - 24% - 24% - 26% - 28% - 28% - 28% - 28% - 28% - 28% - 34% - 34% - 34% - 34% - 34% - 34% - 38% - 38% - 38% - 43% - 43% - 43% - 47% - 47% - 47% - 51% - 53% - 54% - 56% - 57% - 59% - 60% - 60% - 64% - 65% - 65% - 66% - 68% - 69% - 70% - 70% - 71% - 71% - 71% - 71% - 72% - 74% - 74% - 74% - 85% - 85% - 85% - 85% - 85% - 89% - 89% - 90% - 90% - 90% - 90% - 90% - 91% - 91% - 92% - 99% - 99% - 100% (77s) - loss: 0.7605\n",
      "Epoch 51 - 100% 5% - 10% - 12% - 14% - 16% - 18% - 18% - 20% - 21% - 21% - 22% - 23% - 23% - 23% - 24% - 24% - 24% - 25% - 26% - 26% - 26% - 26% - 26% - 27% - 27% - 28% - 29% - 32% - 32% - 35% - 36% - 39% - 40% - 41% - 41% - 41% - 41% - 41% - 44% - 44% - 44% - 44% - 45% - 47% - 48% - 49% - 56% - 58% - 58% - 58% - 58% - 60% - 63% - 65% - 67% - 67% - 77% - 78% - 78% - 79% - 79% - 81% - 83% - 85% - 85% - 86% - 86% - 87% - 87% - 87% - 88% - 88% - 88% - 88% - 88% - 88% - 90% - 91% - 91% - 93% - 94% - 94% - 94% - 94% - 98% - 99% - 99% - 100% (78s) - loss: 0.7595\n",
      "Epoch 52 - 100% 0% - 3% - 3% - 4% - 5% - 18% - 20% - 24% - 26% - 27% - 27% - 28% - 28% - 30% - 31% - 34% - 37% - 37% - 37% - 38% - 41% - 42% - 42% - 44% - 44% - 48% - 50% - 51% - 52% - 52% - 53% - 54% - 54% - 54% - 55% - 55% - 55% - 60% - 60% - 60% - 60% - 62% - 63% - 63% - 63% - 64% - 64% - 65% - 65% - 65% - 66% - 67% - 69% - 70% - 70% - 70% - 71% - 71% - 71% - 71% - 72% - 72% - 73% - 74% - 75% - 75% - 75% - 76% - 78% - 78% - 78% - 78% - 78% - 78% - 79% - 79% - 79% - 79% - 79% - 81% - 82% - 82% - 83% - 84% - 84% - 88% - 91% - 92% - 92% - 93% - 93% - 93% - 94% - 98% - 98% - 98% - 99% - 99% (78s) - loss: 0.7582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 - 100% 1% - 1% - 2% - 5% - 7% - 9% - 10% - 15% - 16% - 16% - 16% - 19% - 21% - 22% - 23% - 23% - 24% - 24% - 24% - 24% - 25% - 26% - 26% - 26% - 27% - 27% - 28% - 28% - 28% - 29% - 30% - 30% - 32% - 33% - 33% - 33% - 34% - 36% - 37% - 37% - 38% - 39% - 40% - 40% - 41% - 45% - 45% - 46% - 46% - 46% - 47% - 47% - 47% - 48% - 49% - 52% - 54% - 55% - 55% - 56% - 58% - 60% - 60% - 60% - 61% - 62% - 62% - 62% - 62% - 63% - 63% - 64% - 64% - 65% - 67% - 67% - 67% - 68% - 68% - 69% - 75% - 75% - 75% - 77% - 77% - 77% - 78% - 78% - 78% - 78% - 78% - 78% - 79% - 79% - 80% - 80% - 81% - 83% - 83% - 83% - 84% - 84% - 84% - 84% - 86% - 86% - 88% - 88% - 89% - 91% - 91% - 91% - 94% - 94% - 94% - 94% - 96% - 97% - 97% - 97% - 97% - 99% - 99% - 99% - 99% (78s) - loss: 0.7569\n",
      "Epoch 54 - 100% 1% - 2% - 2% - 5% - 5% - 7% - 7% - 7% - 7% - 9% - 9% - 9% - 9% - 9% - 9% - 10% - 10% - 11% - 11% - 14% - 14% - 14% - 14% - 15% - 18% - 21% - 24% - 24% - 24% - 24% - 26% - 26% - 26% - 28% - 28% - 29% - 30% - 31% - 33% - 34% - 38% - 38% - 41% - 41% - 41% - 41% - 41% - 41% - 41% - 43% - 44% - 47% - 48% - 48% - 50% - 50% - 50% - 50% - 50% - 50% - 52% - 52% - 54% - 56% - 57% - 59% - 59% - 60% - 61% - 61% - 61% - 61% - 64% - 65% - 66% - 69% - 69% - 70% - 70% - 71% - 72% - 73% - 75% - 75% - 76% - 77% - 77% - 79% - 79% - 79% - 86% - 87% - 89% - 90% - 91% - 93% - 95% - 95% - 95% - 96% - 97% - 97% - 97% - 97% (78s) - loss: 0.7579\n",
      "Epoch 55 - 100% 1% - 1% - 2% - 3% - 3% - 3% - 3% - 4% - 4% - 8% - 8% - 8% - 16% - 16% - 16% - 16% - 18% - 21% - 21% - 22% - 22% - 23% - 23% - 27% - 27% - 35% - 35% - 39% - 39% - 44% - 49% - 49% - 51% - 51% - 52% - 53% - 54% - 58% - 58% - 58% - 58% - 60% - 62% - 62% - 62% - 62% - 62% - 63% - 63% - 67% - 68% - 68% - 68% - 68% - 70% - 70% - 70% - 71% - 72% - 75% - 76% - 77% - 79% - 82% - 83% - 83% - 83% - 83% - 83% - 85% - 86% - 86% - 88% - 88% - 88% - 90% - 93% - 93% - 94% - 94% - 96% - 96% - 96% - 99% (77s) - loss: 0.7565\n",
      "Epoch 56 - 100% 3% - 3% - 4% - 11% - 15% - 15% - 16% - 21% - 22% - 22% - 22% - 22% - 22% - 22% - 22% - 22% - 22% - 24% - 28% - 32% - 32% - 34% - 38% - 38% - 38% - 38% - 38% - 38% - 41% - 43% - 43% - 45% - 46% - 46% - 46% - 46% - 46% - 49% - 50% - 50% - 50% - 50% - 50% - 50% - 51% - 53% - 53% - 58% - 58% - 59% - 61% - 61% - 61% - 61% - 62% - 64% - 65% - 65% - 67% - 68% - 68% - 70% - 72% - 72% - 73% - 73% - 73% - 73% - 73% - 74% - 76% - 76% - 76% - 79% - 79% - 79% - 81% - 81% - 81% - 81% - 82% - 82% - 82% - 82% - 82% - 82% - 86% - 86% - 86% - 86% - 86% - 86% - 89% - 89% - 91% - 93% - 93% - 93% - 96% - 96% - 97% - 98% - 98% - 98% - 99% (78s) - loss: 0.7567\n",
      "Epoch 57 - 100% 0% - 1% - 1% - 1% - 1% - 1% - 4% - 7% - 8% - 8% - 10% - 10% - 12% - 12% - 13% - 17% - 18% - 19% - 19% - 19% - 19% - 19% - 20% - 22% - 23% - 23% - 24% - 25% - 25% - 25% - 25% - 25% - 31% - 33% - 37% - 37% - 37% - 37% - 37% - 38% - 41% - 41% - 41% - 43% - 43% - 48% - 48% - 49% - 50% - 50% - 51% - 52% - 56% - 56% - 60% - 60% - 60% - 61% - 62% - 62% - 62% - 63% - 68% - 68% - 68% - 68% - 68% - 68% - 69% - 70% - 70% - 73% - 74% - 74% - 74% - 74% - 77% - 77% - 78% - 78% - 78% - 79% - 79% - 79% - 80% - 80% - 82% - 82% - 85% - 89% - 89% - 89% - 89% - 89% - 90% - 98% - 99% - 99% (78s) - loss: 0.7589\n",
      "Epoch 58 - 100% 1% - 1% - 2% - 2% - 3% - 3% - 4% - 4% - 4% - 5% - 5% - 5% - 6% - 8% - 10% - 10% - 11% - 11% - 11% - 12% - 12% - 12% - 12% - 12% - 13% - 14% - 14% - 14% - 14% - 14% - 14% - 14% - 15% - 15% - 16% - 16% - 16% - 16% - 16% - 16% - 18% - 19% - 21% - 21% - 21% - 21% - 23% - 24% - 24% - 24% - 25% - 26% - 27% - 28% - 30% - 31% - 31% - 32% - 32% - 34% - 34% - 35% - 35% - 35% - 35% - 35% - 38% - 39% - 40% - 40% - 40% - 40% - 40% - 41% - 42% - 42% - 45% - 45% - 46% - 46% - 46% - 46% - 47% - 47% - 49% - 50% - 50% - 51% - 51% - 51% - 51% - 52% - 52% - 54% - 54% - 55% - 55% - 56% - 56% - 58% - 58% - 59% - 59% - 61% - 61% - 61% - 62% - 63% - 63% - 64% - 64% - 66% - 66% - 66% - 67% - 67% - 68% - 68% - 69% - 76% - 76% - 76% - 77% - 77% - 78% - 80% - 81% - 81% - 83% - 86% - 86% - 86% - 87% - 87% - 88% - 88% - 92% - 92% - 94% - 94% - 96% - 99% - 99% - 100% (79s) - loss: 0.7589\n",
      "Epoch 59 - 100% 1% - 2% - 3% - 3% - 4% - 4% - 5% - 5% - 5% - 8% - 8% - 9% - 10% - 10% - 10% - 11% - 11% - 11% - 12% - 12% - 13% - 13% - 14% - 15% - 15% - 15% - 16% - 16% - 16% - 17% - 18% - 18% - 18% - 18% - 19% - 19% - 19% - 19% - 20% - 22% - 22% - 25% - 25% - 28% - 29% - 29% - 29% - 29% - 30% - 32% - 32% - 32% - 32% - 32% - 33% - 34% - 34% - 34% - 34% - 35% - 35% - 35% - 35% - 36% - 37% - 37% - 39% - 42% - 43% - 45% - 46% - 47% - 48% - 48% - 48% - 49% - 49% - 50% - 50% - 50% - 50% - 50% - 52% - 52% - 53% - 54% - 57% - 57% - 58% - 59% - 60% - 60% - 61% - 61% - 63% - 63% - 64% - 65% - 65% - 66% - 67% - 67% - 69% - 69% - 70% - 72% - 72% - 73% - 73% - 73% - 74% - 74% - 74% - 76% - 78% - 78% - 78% - 80% - 82% - 85% - 85% - 85% - 86% - 88% - 89% - 91% - 92% - 95% - 95% - 96% - 96% - 96% - 96% - 98% - 98% - 98% - 98% - 100% (78s) - loss: 0.7575\n",
      "Epoch 60 - 100% 1% - 1% - 1% - 3% - 7% - 10% - 10% - 10% - 10% - 11% - 11% - 11% - 11% - 13% - 13% - 18% - 19% - 21% - 22% - 23% - 23% - 23% - 34% - 35% - 35% - 36% - 36% - 36% - 36% - 36% - 40% - 41% - 41% - 41% - 41% - 42% - 42% - 42% - 43% - 43% - 43% - 44% - 44% - 44% - 47% - 50% - 50% - 50% - 53% - 53% - 54% - 54% - 54% - 57% - 57% - 59% - 59% - 59% - 59% - 59% - 63% - 65% - 67% - 67% - 67% - 67% - 69% - 69% - 70% - 70% - 70% - 70% - 70% - 73% - 74% - 74% - 74% - 74% - 74% - 75% - 76% - 82% - 82% - 82% - 82% - 83% - 84% - 88% - 91% - 92% - 96% (78s) - loss: 0.7562\n",
      "Epoch 61 - 100% 0% - 3% - 4% - 7% - 11% - 13% - 14% - 16% - 16% - 25% - 29% - 29% - 30% - 32% - 34% - 36% - 36% - 36% - 36% - 37% - 37% - 38% - 39% - 40% - 40% - 42% - 42% - 49% - 49% - 49% - 52% - 59% - 61% - 61% - 61% - 61% - 61% - 63% - 63% - 69% - 69% - 69% - 69% - 70% - 70% - 71% - 71% - 71% - 74% - 79% - 79% - 80% - 83% - 86% - 86% - 86% - 86% - 87% - 87% - 90% - 93% - 93% - 95% - 95% - 95% - 98% - 98% - 99% - 99% - 99% - 99% (78s) - loss: 0.7571\n",
      "Epoch 62 - 100% 0% - 1% - 4% - 4% - 4% - 6% - 8% - 8% - 12% - 12% - 12% - 13% - 13% - 13% - 13% - 13% - 14% - 15% - 17% - 19% - 19% - 19% - 19% - 20% - 21% - 22% - 23% - 24% - 24% - 24% - 24% - 25% - 25% - 26% - 32% - 32% - 33% - 33% - 33% - 33% - 35% - 36% - 38% - 39% - 39% - 41% - 50% - 50% - 51% - 53% - 53% - 53% - 53% - 54% - 54% - 54% - 54% - 57% - 60% - 60% - 62% - 62% - 62% - 62% - 63% - 64% - 65% - 65% - 66% - 67% - 67% - 68% - 70% - 70% - 70% - 71% - 71% - 71% - 71% - 72% - 72% - 72% - 73% - 73% - 74% - 74% - 75% - 76% - 76% - 76% - 77% - 77% - 77% - 79% - 80% - 81% - 84% - 86% - 86% - 86% - 86% - 86% - 87% - 89% - 90% - 90% - 91% - 91% - 91% - 92% - 92% - 92% - 93% - 93% - 94% - 94% - 96% - 96% - 96% - 96% - 96% - 96% - 97% - 100% (78s) - loss: 0.7561\n",
      "Epoch 63 - 100% 1% - 1% - 1% - 3% - 6% - 16% - 18% - 18% - 18% - 19% - 20% - 20% - 20% - 20% - 27% - 27% - 28% - 28% - 28% - 29% - 30% - 32% - 33% - 36% - 37% - 37% - 37% - 39% - 39% - 40% - 40% - 40% - 40% - 43% - 43% - 43% - 43% - 43% - 43% - 43% - 44% - 45% - 48% - 49% - 49% - 49% - 50% - 51% - 57% - 57% - 61% - 64% - 67% - 70% - 71% - 72% - 72% - 76% - 76% - 80% - 81% - 82% - 83% - 84% - 84% - 87% - 87% - 87% - 92% - 97% - 99% (78s) - loss: 0.7569\n",
      "Epoch 64 - 100% 1% - 2% - 2% - 2% - 2% - 3% - 3% - 3% - 3% - 3% - 6% - 8% - 11% - 11% - 12% - 13% - 25% - 27% - 27% - 29% - 33% - 34% - 34% - 34% - 35% - 35% - 35% - 39% - 40% - 41% - 46% - 47% - 47% - 47% - 47% - 47% - 51% - 51% - 56% - 58% - 59% - 59% - 61% - 62% - 65% - 67% - 70% - 70% - 71% - 71% - 72% - 75% - 81% - 81% - 81% - 81% - 81% - 85% - 85% - 86% - 86% - 86% - 86% - 94% - 94% - 94% - 94% - 94% - 94% - 96% - 97% - 97% - 97% - 99% - 99% - 99% - 99% (77s) - loss: 0.7573\n",
      "Epoch 65 - 100% 0% - 4% - 4% - 5% - 5% - 6% - 8% - 8% - 10% - 10% - 11% - 16% - 16% - 16% - 16% - 17% - 17% - 17% - 18% - 21% - 21% - 22% - 24% - 26% - 27% - 27% - 29% - 31% - 37% - 37% - 38% - 42% - 45% - 49% - 52% - 52% - 52% - 58% - 59% - 60% - 71% - 71% - 71% - 72% - 72% - 72% - 76% - 76% - 79% - 79% - 81% - 81% - 81% - 81% - 81% - 82% - 84% - 84% - 86% - 86% - 88% - 88% - 88% - 88% - 88% - 88% - 88% - 88% - 89% - 89% - 89% - 89% - 94% - 95% - 98% - 99% (78s) - loss: 0.7556\n",
      "Epoch 66 - 100% 2% - 3% - 3% - 6% - 10% - 10% - 11% - 11% - 11% - 11% - 11% - 14% - 15% - 16% - 17% - 17% - 17% - 18% - 19% - 21% - 23% - 24% - 24% - 25% - 25% - 25% - 26% - 26% - 27% - 27% - 28% - 29% - 30% - 30% - 30% - 30% - 30% - 31% - 32% - 34% - 36% - 36% - 39% - 39% - 40% - 40% - 40% - 40% - 41% - 44% - 45% - 45% - 47% - 48% - 48% - 49% - 51% - 51% - 52% - 52% - 52% - 52% - 52% - 54% - 54% - 54% - 54% - 54% - 55% - 55% - 55% - 57% - 58% - 58% - 58% - 60% - 60% - 61% - 61% - 63% - 63% - 64% - 64% - 64% - 64% - 64% - 65% - 65% - 66% - 69% - 69% - 71% - 73% - 75% - 75% - 76% - 77% - 77% - 80% - 80% - 80% - 81% - 81% - 81% - 81% - 81% - 81% - 81% - 82% - 82% - 82% - 83% - 84% - 84% - 84% - 85% - 86% - 88% - 88% - 88% - 88% - 88% - 89% - 89% - 89% - 89% - 90% - 90% - 93% - 95% - 95% - 99% - 99% - 100% (78s) - loss: 0.7548\n",
      "Epoch 67 - 100% 0% - 0% - 0% - 0% - 1% - 1% - 1% - 1% - 2% - 2% - 2% - 3% - 3% - 3% - 5% - 6% - 7% - 7% - 9% - 14% - 16% - 17% - 18% - 18% - 18% - 18% - 19% - 20% - 21% - 21% - 23% - 23% - 23% - 24% - 24% - 25% - 25% - 25% - 25% - 25% - 26% - 27% - 30% - 30% - 30% - 31% - 31% - 33% - 34% - 34% - 34% - 34% - 35% - 39% - 39% - 39% - 39% - 39% - 43% - 45% - 46% - 46% - 47% - 47% - 50% - 50% - 50% - 53% - 53% - 54% - 54% - 57% - 58% - 65% - 66% - 67% - 68% - 68% - 69% - 69% - 71% - 74% - 75% - 76% - 76% - 76% - 80% - 80% - 80% - 81% - 82% - 86% - 86% - 87% - 87% - 87% - 87% - 87% - 87% - 91% - 93% - 95% - 99% (78s) - loss: 0.7531\n",
      "Epoch 68 - 100% 0% - 0% - 0% - 1% - 1% - 1% - 1% - 1% - 2% - 2% - 2% - 3% - 6% - 6% - 6% - 6% - 6% - 8% - 8% - 8% - 8% - 18% - 19% - 20% - 23% - 24% - 24% - 24% - 33% - 33% - 38% - 38% - 42% - 43% - 43% - 43% - 43% - 43% - 45% - 45% - 47% - 47% - 49% - 49% - 49% - 51% - 51% - 51% - 53% - 53% - 53% - 59% - 61% - 61% - 64% - 65% - 65% - 68% - 69% - 69% - 69% - 70% - 70% - 71% - 71% - 71% - 72% - 73% - 74% - 78% - 81% - 81% - 84% - 85% - 85% - 89% - 89% - 91% - 91% - 91% - 95% - 96% - 98% (78s) - loss: 0.7542\n",
      "Epoch 69 - 100% 2% - 4% - 5% - 11% - 11% - 12% - 13% - 13% - 13% - 15% - 17% - 17% - 18% - 19% - 22% - 23% - 23% - 23% - 23% - 24% - 28% - 28% - 28% - 29% - 29% - 32% - 32% - 32% - 33% - 33% - 33% - 33% - 34% - 34% - 34% - 34% - 35% - 36% - 37% - 37% - 38% - 38% - 39% - 39% - 40% - 40% - 41% - 41% - 41% - 44% - 47% - 48% - 49% - 50% - 50% - 50% - 54% - 57% - 58% - 58% - 58% - 58% - 58% - 58% - 58% - 58% - 58% - 61% - 62% - 67% - 67% - 67% - 67% - 68% - 70% - 71% - 71% - 71% - 71% - 71% - 72% - 73% - 73% - 73% - 73% - 75% - 76% - 76% - 76% - 76% - 77% - 79% - 79% - 82% - 82% - 83% - 84% - 85% - 86% - 86% - 86% - 86% - 86% - 87% - 87% - 87% - 87% - 88% - 89% - 93% - 93% - 98% - 100% (78s) - loss: 0.7551\n",
      "Epoch 70 - 100% 4% - 5% - 6% - 6% - 6% - 6% - 6% - 7% - 9% - 11% - 11% - 13% - 13% - 16% - 18% - 20% - 20% - 20% - 25% - 25% - 26% - 26% - 27% - 27% - 28% - 29% - 31% - 31% - 31% - 32% - 32% - 32% - 33% - 33% - 34% - 35% - 35% - 36% - 37% - 37% - 39% - 39% - 41% - 44% - 46% - 47% - 48% - 49% - 50% - 50% - 51% - 55% - 55% - 55% - 56% - 57% - 59% - 60% - 60% - 60% - 62% - 62% - 62% - 62% - 62% - 63% - 70% - 72% - 72% - 73% - 73% - 74% - 75% - 76% - 76% - 82% - 82% - 82% - 83% - 84% - 87% - 89% - 90% - 90% - 90% - 91% - 91% - 93% - 93% - 94% - 94% - 97% - 98% - 99% - 99% (78s) - loss: 0.7534\n",
      "Epoch 71 - 100% 1% - 3% - 3% - 3% - 3% - 5% - 6% - 8% - 9% - 11% - 12% - 12% - 13% - 15% - 15% - 16% - 16% - 20% - 20% - 21% - 23% - 26% - 31% - 31% - 32% - 39% - 40% - 40% - 40% - 40% - 40% - 42% - 42% - 42% - 44% - 44% - 48% - 49% - 51% - 51% - 51% - 51% - 53% - 53% - 56% - 56% - 56% - 57% - 57% - 60% - 60% - 61% - 63% - 63% - 63% - 63% - 63% - 63% - 68% - 72% - 72% - 72% - 72% - 72% - 73% - 75% - 75% - 75% - 80% - 80% - 80% - 80% - 81% - 81% - 83% - 84% - 84% - 84% - 85% - 87% - 89% - 90% - 95% - 95% - 95% - 97% - 97% (78s) - loss: 0.7545\n",
      "Epoch 72 - 100% 0% - 5% - 7% - 9% - 12% - 12% - 12% - 12% - 12% - 12% - 12% - 12% - 13% - 13% - 14% - 14% - 17% - 19% - 20% - 20% - 27% - 28% - 30% - 30% - 31% - 31% - 32% - 39% - 39% - 39% - 42% - 46% - 48% - 48% - 48% - 48% - 50% - 50% - 50% - 52% - 52% - 54% - 54% - 54% - 54% - 57% - 61% - 61% - 62% - 62% - 62% - 62% - 64% - 68% - 69% - 69% - 70% - 70% - 73% - 79% - 79% - 79% - 81% - 81% - 82% - 82% - 82% - 82% - 82% - 90% - 90% - 95% - 95% - 96% - 98% - 98% - 99% - 100% (78s) - loss: 0.7533\n",
      "Epoch 73 - 100% 1% - 15% - 15% - 19% - 20% - 22% - 22% - 23% - 23% - 27% - 29% - 29% - 29% - 31% - 34% - 36% - 36% - 36% - 36% - 37% - 37% - 40% - 41% - 41% - 41% - 45% - 46% - 47% - 47% - 47% - 47% - 47% - 47% - 48% - 48% - 49% - 49% - 49% - 50% - 51% - 51% - 52% - 52% - 52% - 52% - 53% - 54% - 57% - 57% - 57% - 57% - 57% - 58% - 61% - 61% - 61% - 61% - 61% - 61% - 61% - 62% - 63% - 64% - 65% - 65% - 66% - 66% - 66% - 68% - 68% - 69% - 69% - 70% - 72% - 72% - 73% - 76% - 78% - 80% - 80% - 81% - 81% - 82% - 85% - 85% - 85% - 86% - 87% - 88% - 88% - 89% - 90% - 91% - 92% - 92% - 93% - 93% - 94% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 95% - 97% - 97% - 98% - 98% - 99% - 99% - 99% - 100% - 100% (79s) - loss: 0.7537\n",
      "Epoch 74 - 100% 0% - 1% - 2% - 5% - 5% - 6% - 6% - 6% - 7% - 7% - 9% - 9% - 9% - 11% - 12% - 12% - 12% - 12% - 13% - 14% - 15% - 15% - 15% - 15% - 16% - 16% - 18% - 18% - 19% - 20% - 20% - 20% - 20% - 21% - 22% - 22% - 22% - 23% - 23% - 24% - 24% - 25% - 27% - 28% - 28% - 28% - 28% - 28% - 31% - 32% - 32% - 32% - 32% - 33% - 33% - 33% - 33% - 34% - 34% - 35% - 36% - 36% - 38% - 39% - 41% - 42% - 42% - 42% - 44% - 45% - 46% - 47% - 47% - 47% - 48% - 50% - 50% - 50% - 51% - 53% - 56% - 56% - 56% - 56% - 56% - 59% - 59% - 59% - 60% - 60% - 60% - 61% - 61% - 61% - 62% - 62% - 63% - 63% - 63% - 63% - 64% - 64% - 66% - 71% - 72% - 72% - 72% - 73% - 73% - 74% - 74% - 79% - 80% - 80% - 82% - 82% - 82% - 83% - 83% - 83% - 83% - 83% - 84% - 84% - 85% - 85% - 86% - 86% - 86% - 86% - 87% - 87% - 92% - 92% - 92% - 94% - 94% - 94% - 95% - 96% - 96% - 97% - 98% - 99% (79s) - loss: 0.7532\n",
      "Epoch 75 - 100% 3% - 5% - 5% - 7% - 7% - 7% - 8% - 8% - 10% - 10% - 11% - 11% - 12% - 13% - 15% - 15% - 17% - 17% - 17% - 17% - 17% - 18% - 19% - 25% - 26% - 27% - 27% - 27% - 28% - 28% - 32% - 35% - 37% - 40% - 40% - 40% - 42% - 43% - 43% - 43% - 44% - 44% - 45% - 45% - 48% - 48% - 48% - 50% - 52% - 53% - 55% - 56% - 56% - 56% - 59% - 59% - 61% - 62% - 62% - 68% - 68% - 68% - 68% - 71% - 71% - 72% - 72% - 72% - 76% - 76% - 76% - 77% - 77% - 79% - 83% - 83% - 84% - 86% - 87% - 96% - 96% - 97% - 97% - 98% - 98% - 98% - 99% - 99% - 99% (78s) - loss: 0.7548\n",
      "Epoch 76 - 100% 1% - 1% - 1% - 2% - 4% - 7% - 10% - 17% - 17% - 18% - 19% - 19% - 23% - 23% - 23% - 25% - 28% - 28% - 28% - 32% - 37% - 38% - 39% - 39% - 40% - 40% - 42% - 43% - 43% - 45% - 45% - 46% - 46% - 46% - 46% - 48% - 49% - 52% - 56% - 56% - 57% - 61% - 64% - 66% - 68% - 69% - 69% - 70% - 72% - 72% - 73% - 73% - 74% - 75% - 78% - 78% - 78% - 78% - 80% - 83% - 84% - 84% - 84% - 88% - 89% - 89% - 89% - 89% - 91% - 91% - 91% - 91% - 96% - 98% - 98% - 99% - 100% (78s) - loss: 0.7545\n",
      "Epoch 77 - 100% 0% - 3% - 3% - 3% - 5% - 5% - 5% - 5% - 5% - 5% - 6% - 9% - 11% - 12% - 12% - 14% - 15% - 20% - 23% - 23% - 23% - 23% - 23% - 23% - 24% - 26% - 27% - 27% - 34% - 34% - 35% - 35% - 35% - 36% - 40% - 40% - 41% - 42% - 42% - 42% - 43% - 47% - 47% - 47% - 47% - 47% - 47% - 50% - 51% - 51% - 51% - 55% - 55% - 57% - 57% - 58% - 58% - 58% - 58% - 58% - 58% - 58% - 61% - 61% - 63% - 65% - 65% - 66% - 66% - 68% - 68% - 68% - 70% - 71% - 72% - 72% - 72% - 73% - 74% - 77% - 77% - 81% - 82% - 83% - 83% - 83% - 84% - 85% - 87% - 87% - 89% - 89% - 91% - 91% - 91% - 97% - 99% - 99% - 99% - 99% - 99% - 99% - 100% (78s) - loss: 0.7527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 - 100% 1% - 2% - 2% - 2% - 3% - 4% - 6% - 6% - 9% - 9% - 9% - 11% - 12% - 12% - 15% - 19% - 22% - 25% - 26% - 27% - 27% - 28% - 28% - 29% - 30% - 30% - 30% - 30% - 31% - 31% - 31% - 34% - 37% - 38% - 38% - 39% - 40% - 40% - 40% - 40% - 40% - 41% - 41% - 41% - 41% - 41% - 41% - 45% - 45% - 47% - 47% - 47% - 47% - 48% - 49% - 50% - 53% - 54% - 55% - 56% - 56% - 57% - 59% - 60% - 60% - 60% - 60% - 60% - 61% - 62% - 63% - 64% - 68% - 69% - 69% - 70% - 71% - 72% - 72% - 72% - 73% - 73% - 73% - 75% - 75% - 75% - 75% - 75% - 75% - 77% - 77% - 77% - 78% - 78% - 79% - 79% - 82% - 82% - 82% - 84% - 85% - 86% - 88% - 88% - 88% - 89% - 89% - 89% - 89% - 89% - 90% - 91% - 93% - 94% - 94% - 94% - 94% - 97% - 99% - 100% (78s) - loss: 0.7539\n",
      "Epoch 79 - 100% 2% - 5% - 5% - 5% - 5% - 5% - 8% - 8% - 9% - 9% - 9% - 9% - 10% - 12% - 12% - 12% - 12% - 18% - 19% - 20% - 20% - 23% - 26% - 27% - 27% - 28% - 29% - 29% - 31% - 33% - 33% - 33% - 41% - 41% - 43% - 43% - 44% - 48% - 48% - 51% - 52% - 54% - 54% - 54% - 54% - 54% - 54% - 54% - 55% - 56% - 56% - 58% - 59% - 59% - 59% - 59% - 60% - 60% - 62% - 62% - 63% - 63% - 63% - 63% - 64% - 64% - 65% - 65% - 65% - 67% - 67% - 67% - 67% - 67% - 67% - 68% - 69% - 69% - 70% - 70% - 70% - 70% - 71% - 72% - 74% - 74% - 74% - 80% - 80% - 81% - 81% - 81% - 82% - 82% - 82% - 82% - 83% - 85% - 86% - 86% - 86% - 92% - 95% - 95% - 97% - 98% (78s) - loss: 0.7519\n",
      "Epoch 80 - 100% 2% - 2% - 2% - 3% - 3% - 6% - 6% - 6% - 8% - 8% - 8% - 11% - 11% - 13% - 13% - 16% - 16% - 18% - 18% - 21% - 21% - 21% - 21% - 21% - 25% - 25% - 29% - 29% - 30% - 31% - 31% - 38% - 42% - 44% - 45% - 49% - 53% - 55% - 56% - 56% - 57% - 60% - 62% - 64% - 64% - 65% - 65% - 66% - 66% - 73% - 74% - 74% - 79% - 79% - 80% - 81% - 85% - 88% - 89% - 95% - 95% - 98% - 99% - 99% (77s) - loss: 0.7537\n",
      "Epoch 81 - 100% 1% - 4% - 7% - 7% - 7% - 7% - 7% - 8% - 9% - 9% - 9% - 11% - 12% - 14% - 14% - 15% - 15% - 16% - 18% - 18% - 21% - 21% - 22% - 31% - 31% - 33% - 34% - 34% - 35% - 35% - 38% - 38% - 38% - 40% - 40% - 42% - 42% - 46% - 48% - 51% - 53% - 54% - 54% - 55% - 57% - 58% - 58% - 60% - 60% - 60% - 60% - 61% - 62% - 63% - 63% - 65% - 67% - 67% - 70% - 71% - 72% - 72% - 73% - 73% - 74% - 75% - 75% - 75% - 75% - 77% - 77% - 78% - 79% - 82% - 82% - 83% - 83% - 83% - 83% - 84% - 90% - 90% - 91% - 91% - 92% - 92% - 94% - 99% - 99% - 99% - 99% (78s) - loss: 0.7535\n",
      "Epoch 82 - 100% 3% - 3% - 4% - 4% - 4% - 7% - 7% - 7% - 7% - 7% - 7% - 8% - 8% - 8% - 8% - 9% - 9% - 10% - 12% - 17% - 17% - 17% - 17% - 18% - 19% - 20% - 20% - 20% - 20% - 20% - 21% - 22% - 23% - 24% - 24% - 24% - 27% - 27% - 27% - 28% - 28% - 28% - 28% - 28% - 28% - 31% - 34% - 35% - 36% - 36% - 39% - 39% - 39% - 40% - 40% - 40% - 42% - 43% - 45% - 45% - 49% - 49% - 51% - 52% - 57% - 59% - 60% - 61% - 61% - 61% - 63% - 63% - 64% - 64% - 65% - 65% - 65% - 67% - 68% - 69% - 69% - 70% - 70% - 70% - 70% - 71% - 72% - 72% - 73% - 74% - 74% - 74% - 76% - 76% - 77% - 77% - 78% - 80% - 81% - 81% - 83% - 83% - 84% - 86% - 86% - 86% - 86% - 89% - 89% - 93% - 95% - 95% - 95% - 96% - 97% - 99% - 99% - 99% - 99% - 99% (78s) - loss: 0.7524\n",
      "Epoch 83 - 100% 3% - 4% - 5% - 5% - 6% - 6% - 6% - 7% - 7% - 7% - 7% - 9% - 9% - 15% - 15% - 15% - 15% - 15% - 16% - 16% - 17% - 18% - 19% - 19% - 19% - 22% - 22% - 23% - 23% - 24% - 25% - 25% - 27% - 27% - 27% - 27% - 27% - 28% - 34% - 34% - 35% - 37% - 37% - 38% - 38% - 38% - 39% - 39% - 40% - 43% - 43% - 43% - 44% - 46% - 50% - 51% - 51% - 52% - 55% - 58% - 58% - 63% - 63% - 64% - 64% - 64% - 66% - 67% - 69% - 72% - 72% - 72% - 72% - 72% - 72% - 72% - 72% - 73% - 75% - 80% - 85% - 89% - 93% - 93% - 93% - 93% - 95% - 95% - 95% - 98% - 99% (78s) - loss: 0.7502\n",
      "Epoch 84 - 100% 4% - 6% - 7% - 7% - 8% - 12% - 12% - 12% - 13% - 13% - 13% - 13% - 15% - 16% - 16% - 16% - 17% - 17% - 17% - 17% - 17% - 17% - 18% - 18% - 18% - 18% - 18% - 18% - 19% - 19% - 20% - 21% - 21% - 22% - 22% - 22% - 24% - 25% - 27% - 27% - 28% - 33% - 34% - 35% - 35% - 35% - 35% - 36% - 36% - 38% - 42% - 42% - 43% - 44% - 44% - 45% - 45% - 45% - 45% - 45% - 47% - 48% - 48% - 48% - 49% - 51% - 51% - 53% - 54% - 55% - 57% - 58% - 58% - 58% - 58% - 59% - 59% - 60% - 60% - 60% - 61% - 61% - 66% - 68% - 68% - 71% - 71% - 71% - 71% - 73% - 73% - 74% - 74% - 78% - 78% - 81% - 82% - 84% - 88% - 88% - 88% - 88% - 90% - 90% - 92% - 94% - 96% - 97% - 97% - 98% - 99% (78s) - loss: 0.7522\n",
      "Epoch 85 - 100% 2% - 2% - 5% - 6% - 6% - 6% - 8% - 10% - 10% - 11% - 11% - 12% - 12% - 13% - 13% - 14% - 15% - 17% - 18% - 18% - 18% - 18% - 19% - 20% - 20% - 20% - 20% - 20% - 20% - 21% - 23% - 23% - 25% - 25% - 25% - 25% - 25% - 26% - 29% - 29% - 30% - 30% - 30% - 30% - 30% - 30% - 30% - 31% - 31% - 32% - 34% - 36% - 36% - 36% - 36% - 36% - 37% - 38% - 38% - 38% - 39% - 39% - 46% - 46% - 47% - 48% - 48% - 48% - 48% - 48% - 48% - 49% - 50% - 51% - 53% - 56% - 56% - 56% - 56% - 56% - 58% - 59% - 59% - 59% - 60% - 62% - 62% - 62% - 62% - 63% - 63% - 63% - 63% - 63% - 66% - 66% - 70% - 72% - 75% - 75% - 76% - 77% - 78% - 78% - 81% - 82% - 83% - 83% - 83% - 86% - 89% - 90% - 91% - 91% - 92% - 92% - 94% - 94% - 94% - 94% - 95% - 99% (78s) - loss: 0.7529\n",
      "Epoch 86 - 100% 1% - 2% - 6% - 7% - 7% - 12% - 15% - 19% - 19% - 21% - 21% - 26% - 26% - 26% - 27% - 27% - 31% - 32% - 32% - 32% - 33% - 34% - 34% - 34% - 34% - 34% - 35% - 37% - 37% - 37% - 42% - 43% - 43% - 45% - 46% - 48% - 48% - 48% - 48% - 48% - 48% - 48% - 48% - 50% - 50% - 50% - 51% - 51% - 51% - 53% - 53% - 54% - 57% - 58% - 60% - 66% - 68% - 69% - 72% - 72% - 73% - 74% - 75% - 75% - 76% - 78% - 79% - 81% - 81% - 82% - 82% - 82% - 82% - 83% - 83% - 84% - 84% - 85% - 85% - 87% - 90% - 90% - 91% - 92% - 93% - 94% - 94% - 96% - 98% - 98% - 98% - 99% - 99% - 100% (78s) - loss: 0.7524\n",
      "Epoch 87 - 100% 0% - 0% - 1% - 2% - 2% - 3% - 5% - 5% - 8% - 8% - 8% - 8% - 9% - 9% - 11% - 11% - 13% - 13% - 13% - 14% - 14% - 14% - 15% - 15% - 15% - 17% - 17% - 18% - 18% - 18% - 19% - 19% - 21% - 21% - 29% - 30% - 36% - 36% - 37% - 37% - 38% - 41% - 41% - 41% - 43% - 45% - 45% - 45% - 47% - 47% - 47% - 47% - 48% - 48% - 48% - 49% - 49% - 49% - 50% - 55% - 60% - 60% - 61% - 64% - 64% - 64% - 64% - 64% - 66% - 68% - 72% - 76% - 79% - 81% - 82% - 82% - 82% - 82% - 82% - 82% - 84% - 86% - 86% - 86% - 86% - 86% - 86% - 86% - 91% - 91% - 91% - 91% - 92% - 92% - 92% - 93% - 95% - 97% - 98% - 98% - 99% (78s) - loss: 0.7522\n",
      "Epoch 88 - 100% 2% - 2% - 4% - 4% - 4% - 6% - 7% - 7% - 13% - 13% - 15% - 15% - 15% - 15% - 15% - 16% - 19% - 20% - 22% - 22% - 26% - 26% - 27% - 27% - 28% - 33% - 34% - 36% - 36% - 38% - 41% - 47% - 48% - 48% - 51% - 51% - 51% - 52% - 53% - 58% - 58% - 58% - 59% - 59% - 59% - 60% - 61% - 62% - 63% - 63% - 63% - 67% - 69% - 69% - 69% - 70% - 70% - 70% - 70% - 71% - 71% - 73% - 73% - 74% - 75% - 76% - 77% - 78% - 83% - 84% - 84% - 85% - 87% - 87% - 88% - 88% - 89% - 90% - 91% - 94% - 96% (78s) - loss: 0.7525\n",
      "Epoch 89 - 100% 3% - 4% - 5% - 7% - 8% - 8% - 10% - 17% - 17% - 18% - 19% - 19% - 19% - 24% - 24% - 27% - 29% - 32% - 32% - 35% - 36% - 39% - 42% - 42% - 42% - 42% - 42% - 42% - 48% - 49% - 51% - 52% - 52% - 52% - 53% - 53% - 53% - 53% - 55% - 55% - 57% - 59% - 61% - 65% - 65% - 67% - 67% - 67% - 68% - 69% - 71% - 73% - 77% - 77% - 77% - 77% - 78% - 78% - 78% - 79% - 81% - 81% - 81% - 82% - 85% - 85% - 86% - 86% - 86% - 86% - 86% - 86% - 87% - 87% - 87% - 88% - 89% - 89% - 89% - 92% - 94% - 94% - 95% - 95% - 96% - 99% (78s) - loss: 0.7524\n",
      "Epoch 90 - 100% 2% - 3% - 5% - 5% - 6% - 6% - 6% - 6% - 6% - 7% - 7% - 9% - 9% - 13% - 13% - 18% - 18% - 18% - 19% - 20% - 21% - 21% - 21% - 21% - 21% - 23% - 26% - 26% - 28% - 28% - 28% - 30% - 33% - 33% - 34% - 35% - 36% - 36% - 36% - 36% - 36% - 38% - 43% - 45% - 45% - 45% - 46% - 48% - 49% - 50% - 50% - 50% - 50% - 55% - 56% - 57% - 59% - 59% - 62% - 63% - 63% - 63% - 64% - 66% - 66% - 66% - 66% - 66% - 67% - 67% - 67% - 69% - 69% - 70% - 70% - 70% - 70% - 70% - 70% - 71% - 71% - 73% - 75% - 76% - 80% - 80% - 80% - 83% - 84% - 86% - 96% - 96% - 96% - 96% - 97% - 97% - 97% (78s) - loss: 0.7531\n",
      "Epoch 91 - 100%- 10% - 10% - 10% - 12% - 12% - 13% - 18% - 19% - 21% - 24% - 25% - 25% - 25% - 25% - 26% - 28% - 30% - 30% - 31% - 31% - 32% - 33% - 34% - 35% - 36% - 38% - 41% - 41% - 41% - 42% - 42% - 42% - 42% - 44% - 45% - 45% - 46% - 48% - 50% - 52% - 52% - 52% - 52% - 53% - 56% - 58% - 60% - 60% - 60% - 64% - 65% - 65% - 66% - 70% - 70% - 72% - 72% - 78% - 79% - 79% - 79% - 79% - 79% - 81% - 82% - 82% - 86% - 87% - 87% - 87% - 87% - 88% - 89% - 90% - 93% - 96% - 97% - 97% - 98% - 100% (78s) - loss: 0.7510\n",
      "Epoch 92 - 100% 1% - 1% - 5% - 9% - 10% - 10% - 19% - 22% - 22% - 22% - 23% - 28% - 28% - 31% - 32% - 32% - 32% - 32% - 33% - 33% - 34% - 34% - 36% - 39% - 40% - 40% - 40% - 40% - 45% - 46% - 46% - 54% - 56% - 57% - 58% - 58% - 59% - 59% - 60% - 60% - 60% - 63% - 63% - 64% - 64% - 64% - 64% - 65% - 66% - 66% - 68% - 68% - 69% - 69% - 71% - 71% - 73% - 81% - 81% - 81% - 81% - 81% - 81% - 85% - 85% - 88% - 89% - 90% - 90% - 90% - 90% - 95% - 96% - 96% - 96% - 97% (77s) - loss: 0.7522\n",
      "Epoch 93 - 100% 6% - 6% - 6% - 8% - 8% - 8% - 8% - 11% - 13% - 15% - 15% - 15% - 20% - 23% - 25% - 33% - 34% - 37% - 38% - 39% - 39% - 41% - 44% - 46% - 46% - 47% - 47% - 54% - 54% - 56% - 56% - 57% - 61% - 61% - 64% - 64% - 69% - 70% - 70% - 71% - 72% - 73% - 75% - 75% - 75% - 78% - 81% - 81% - 83% - 84% - 85% - 87% - 87% - 87% - 90% - 91% - 91% - 96% - 97% - 98% - 98% - 98% (78s) - loss: 0.7502\n",
      "Epoch 94 - 100% 2% - 2% - 3% - 4% - 5% - 5% - 5% - 6% - 6% - 6% - 8% - 9% - 10% - 10% - 10% - 10% - 11% - 11% - 12% - 12% - 13% - 14% - 15% - 15% - 16% - 16% - 17% - 17% - 17% - 20% - 20% - 21% - 22% - 22% - 23% - 23% - 24% - 26% - 26% - 27% - 27% - 27% - 28% - 28% - 28% - 29% - 30% - 31% - 33% - 35% - 35% - 36% - 36% - 36% - 37% - 38% - 38% - 39% - 39% - 39% - 39% - 39% - 42% - 42% - 42% - 42% - 42% - 43% - 45% - 46% - 46% - 46% - 49% - 50% - 51% - 51% - 54% - 54% - 54% - 57% - 58% - 58% - 58% - 58% - 58% - 61% - 62% - 62% - 62% - 63% - 63% - 63% - 63% - 63% - 64% - 65% - 66% - 69% - 71% - 71% - 73% - 73% - 73% - 73% - 74% - 74% - 75% - 75% - 76% - 81% - 82% - 83% - 83% - 83% - 86% - 86% - 87% - 89% - 90% - 91% - 91% - 92% - 92% - 92% - 92% - 93% - 93% - 94% - 94% - 94% - 95% - 96% - 99% (79s) - loss: 0.7514\n",
      "Epoch 95 - 100% 0% - 2% - 2% - 2% - 3% - 3% - 3% - 3% - 3% - 4% - 4% - 5% - 5% - 5% - 5% - 6% - 7% - 9% - 9% - 10% - 12% - 12% - 12% - 15% - 16% - 16% - 16% - 17% - 17% - 18% - 18% - 18% - 18% - 18% - 18% - 18% - 18% - 18% - 18% - 19% - 19% - 19% - 19% - 19% - 22% - 24% - 26% - 28% - 28% - 28% - 29% - 32% - 33% - 34% - 44% - 46% - 47% - 49% - 49% - 51% - 53% - 55% - 56% - 58% - 58% - 58% - 58% - 58% - 58% - 58% - 58% - 61% - 61% - 61% - 62% - 62% - 64% - 71% - 75% - 76% - 76% - 76% - 77% - 81% - 81% - 81% - 82% - 82% - 84% - 84% - 84% - 84% - 90% - 90% - 90% - 91% - 93% - 94% - 94% - 100% (78s) - loss: 0.7512\n",
      "Epoch 96 - 100% 0% - 1% - 1% - 2% - 2% - 4% - 14% - 14% - 15% - 19% - 20% - 20% - 22% - 22% - 25% - 31% - 33% - 33% - 42% - 44% - 44% - 44% - 44% - 44% - 44% - 47% - 54% - 55% - 55% - 55% - 55% - 55% - 58% - 58% - 61% - 61% - 61% - 65% - 75% - 75% - 79% - 80% - 80% - 80% - 81% - 81% - 81% - 83% - 87% - 87% - 88% - 88% - 88% - 89% - 92% - 94% - 94% - 95% - 96% - 96% - 97% - 98% - 99% - 100% (77s) - loss: 0.7515\n",
      "Epoch 97 - 100% 0% - 2% - 3% - 3% - 3% - 3% - 4% - 4% - 4% - 4% - 5% - 6% - 7% - 7% - 8% - 8% - 10% - 10% - 11% - 11% - 11% - 12% - 12% - 13% - 13% - 13% - 14% - 14% - 19% - 20% - 23% - 24% - 30% - 32% - 32% - 32% - 33% - 34% - 34% - 34% - 34% - 35% - 35% - 41% - 41% - 41% - 41% - 41% - 43% - 43% - 47% - 47% - 47% - 47% - 47% - 47% - 47% - 48% - 48% - 48% - 48% - 49% - 50% - 52% - 53% - 55% - 55% - 56% - 57% - 58% - 59% - 59% - 59% - 68% - 68% - 70% - 71% - 72% - 72% - 72% - 73% - 73% - 73% - 73% - 73% - 73% - 74% - 74% - 74% - 74% - 74% - 76% - 76% - 76% - 76% - 79% - 80% - 80% - 81% - 81% - 81% - 82% - 83% - 83% - 84% - 86% - 87% - 88% - 90% - 95% - 100% (78s) - loss: 0.7501\n",
      "Epoch 98 - 100% 1% - 1% - 3% - 5% - 5% - 5% - 5% - 5% - 11% - 11% - 14% - 15% - 15% - 19% - 23% - 23% - 24% - 28% - 28% - 28% - 31% - 33% - 34% - 34% - 37% - 37% - 38% - 38% - 42% - 43% - 47% - 47% - 48% - 48% - 54% - 57% - 58% - 58% - 61% - 62% - 63% - 64% - 64% - 67% - 67% - 67% - 68% - 72% - 74% - 74% - 78% - 85% - 85% - 89% - 90% - 90% - 90% - 90% - 91% - 91% - 97% - 97% (78s) - loss: 0.7516\n",
      "Epoch 99 - 100% 1% - 2% - 6% - 6% - 6% - 9% - 11% - 12% - 12% - 12% - 13% - 14% - 14% - 14% - 14% - 14% - 16% - 16% - 20% - 20% - 21% - 21% - 21% - 22% - 22% - 24% - 26% - 32% - 32% - 36% - 40% - 40% - 44% - 44% - 44% - 49% - 49% - 50% - 52% - 53% - 53% - 55% - 60% - 63% - 66% - 66% - 70% - 72% - 72% - 72% - 72% - 73% - 73% - 73% - 75% - 75% - 75% - 76% - 77% - 78% - 78% - 82% - 82% - 82% - 82% - 82% - 83% - 84% - 86% - 87% - 87% - 87% - 87% - 89% - 91% - 91% - 91% - 94% - 94% - 94% - 95% - 95% - 95% - 95% - 95% - 97% - 98% - 98% - 98% - 98% - 99% - 99% (77s) - loss: 0.7517\n",
      "Epoch 100 - 100% 0% - 2% - 3% - 3% - 3% - 4% - 9% - 9% - 9% - 11% - 22% - 24% - 25% - 25% - 27% - 28% - 28% - 28% - 31% - 33% - 33% - 33% - 33% - 34% - 34% - 35% - 36% - 38% - 39% - 39% - 40% - 41% - 41% - 41% - 42% - 42% - 42% - 42% - 44% - 47% - 47% - 48% - 48% - 48% - 48% - 49% - 49% - 49% - 49% - 49% - 49% - 52% - 52% - 52% - 57% - 59% - 64% - 65% - 65% - 66% - 66% - 67% - 67% - 67% - 67% - 68% - 68% - 69% - 75% - 76% - 77% - 81% - 83% - 83% - 83% - 83% - 85% - 87% - 87% - 87% - 89% - 91% - 93% - 94% - 94% - 94% - 94% - 97% - 97% - 98% - 98% - 98% - 99% - 99% - 99% (78s) - loss: 0.7515\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sys import float_info, stdout\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "data_file_name = 'all_data.csv' \n",
    "\n",
    "num_epochs = 100 \n",
    "batch_size = 32 \n",
    "num_noise_words = 2 \n",
    "vec_dim = 100 \n",
    "lr = 1e-3\n",
    "\n",
    "model_ver_is_dbow = True\n",
    "model_ver = 'dbow'\n",
    "\n",
    "context_size=0\n",
    "num_workers=1\n",
    "\n",
    "vec_combine_method='sum'\n",
    "save_all=False\n",
    "generate_plot=True\n",
    "max_generated_batches=5\n",
    "num_workers=1\n",
    "\n",
    "if vec_combine_method not in ('sum', 'concat'):\n",
    "    raise ValueError(\"Invalid method for combining paragraph and word \"\n",
    "                     \"vectors when using dm\")\n",
    "\n",
    "\n",
    "dataset = load_dataset(data_file_name)\n",
    "nce_data = NCEData(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    context_size,\n",
    "    num_noise_words,\n",
    "    max_generated_batches,\n",
    "    num_workers)\n",
    "\n",
    "data_generator = nce_data._generator\n",
    "\n",
    "\n",
    "num_batches = len(nce_data)\n",
    "vocabulary_size = nce_data.vocabulary_size()\n",
    "\n",
    "model = DBOW(vec_dim, num_docs=len(dataset), num_words=vocabulary_size)\n",
    "cost_func = NegativeSampling()\n",
    "optimizer = Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print(\"Dataset comprised of {:d} documents.\".format(len(dataset)))\n",
    "print(\"Vocabulary size is {:d}.\\n\".format(vocabulary_size))\n",
    "print(\"Training started.\")\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "prev_model_file_path = None\n",
    "\n",
    "for epoch_i in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    loss = []\n",
    "\n",
    "    for batch_i in range(num_batches):\n",
    "        batch = data_generator.next()\n",
    "        if torch.cuda.is_available():\n",
    "            batch.cuda_()\n",
    "\n",
    "\n",
    "        x = model.forward(batch.doc_ids, batch.target_noise_ids)\n",
    "        x = cost_func.forward(x)\n",
    "\n",
    "        loss.append(x.item())\n",
    "        model.zero_grad()\n",
    "        x.backward()\n",
    "        optimizer.step()\n",
    "        _print_progress(epoch_i, batch_i, num_batches)\n",
    "\n",
    "    # end of epoch\n",
    "    loss = torch.mean(torch.FloatTensor(loss))\n",
    "    is_best_loss = loss < best_loss\n",
    "    best_loss = min(loss, best_loss)\n",
    "\n",
    "    state = {\n",
    "        'epoch': epoch_i + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    prev_model_file_path = save_training_state(\n",
    "        data_file_name,\n",
    "        model_ver,\n",
    "        vec_combine_method,\n",
    "        context_size,\n",
    "        num_noise_words,\n",
    "        vec_dim,\n",
    "        batch_size,\n",
    "        lr,\n",
    "        epoch_i,\n",
    "        loss,\n",
    "        state,\n",
    "        save_all,\n",
    "        generate_plot,\n",
    "        is_best_loss,\n",
    "        prev_model_file_path,\n",
    "        model_ver_is_dbow)\n",
    "\n",
    "    epoch_total_time = round(time.time() - epoch_start_time)\n",
    "    print(\" ({:d}s) - loss: {:.4f}\".format(epoch_total_time, loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = os.listdir(MODELS_DIR)[0]\n",
    "model_root = model_file_name.replace(\".pth.tar\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencerbraun/dev/virtualenvs/venv3/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/spencerbraun/dev/virtualenvs/venv3/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/Users/spencerbraun/dev/virtualenvs/venv3/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "data_file_name = 'all_data.csv' \n",
    "start(data_file_name, model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": ".venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
