{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.nn.init import xavier_normal, kaiming_normal\n",
    "\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format()\n",
    "# weights = torch.FloatTensor(model.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9218])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = glove['cat']\n",
    "y = glove['dog']\n",
    "torch.norm(y - x)\n",
    "\n",
    "torch.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 1.8846031427383423\n",
      "bike 5.048375129699707\n",
      "kitten 3.5068609714508057\n",
      "puppy 3.0644655227661133\n",
      "kite 4.210376262664795\n",
      "computer 6.030652046203613\n",
      "neuron 6.228669166564941\n"
     ]
    }
   ],
   "source": [
    "word = 'cat'\n",
    "other = ['dog', 'bike', 'kitten', 'puppy', 'kite', 'computer', 'neuron']\n",
    "for w in other:\n",
    "    dist = torch.norm(glove[word] - glove[w]) # euclidean distance\n",
    "    print(w, float(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 1.8846031\n",
      "rabbit 2.4572797\n",
      "monkey 2.8102052\n",
      "cats 2.8972247\n",
      "rat 2.9455352\n",
      "beast 2.9878407\n",
      "monster 3.0022194\n",
      "pet 3.0396757\n",
      "snake 3.0617998\n",
      "puppy 3.0644655\n"
     ]
    }
   ],
   "source": [
    "def print_closest_words(vec, n=5):\n",
    "    dists = torch.norm(glove.vectors - vec, dim=1)     # compute distances to all words\n",
    "    lst = sorted(enumerate(dists.numpy()), key=lambda x: x[1]) # sort by distance\n",
    "    for idx, difference in lst[1:n+1]: # take the top n\n",
    "        print(glove.itos[idx], difference)\n",
    "\n",
    "print_closest_words(glove[\"cat\"], n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah 4.121112\n",
      "everybody 4.362761\n",
      "guess 4.381542\n",
      "hey 4.4264035\n",
      "maybe 4.44897\n"
     ]
    }
   ],
   "source": [
    "print_closest_words(glove['big'] - glove['small'] + glove['yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"section\" id=\"linear-models\">\r\n",
      "<span id=\"linear-model\"></span><h1>1.1. Linear Models<a class=\"headerlink\" href=\"#linear-models\" title=\"Permalink to this headline\">Â¶</a></h1>\r\n",
      "<p>The following are a set of methods intended for regression in which\r\n",
      "the target value is expected to be a linear combination of the features.\r\n",
      "In mathematical notation, if <span class=\"math notranslate nohighlight\">\\(\\hat{y}\\)</span> is the predicted\r\n",
      "value.</p>\r\n",
      "<div class=\"math notranslate nohighlight\">\r\n",
      "\\[\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p\\]</div>\r\n",
      "<p>Across the module, we designate the vector <span class=\"math notranslate nohighlight\">\\(w = (w_1,\r\n",
      "..., w_p)\\)</span> as <code class=\"docutils literal notranslate\"><span class=\"pre\">coef_</span></code> and <span class=\"math notranslate nohighlight\">\\(w_0\\)</span> as <code class=\"docutils literal notranslate\"><span class=\"pre\">intercept_</span></code>.</p>\r\n",
      "cat: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "! cat sklearn_data/1_1_Linear_Models.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    \"But as I wrote in my tweet, I agree with you that it's hard to police. I just disagree that the main losers will be U.S. consumers. I think the main losers will be poor people in poor countries.\",\n",
    "    \"I would like to discuss several common exploration strategies in Deep RL here. As this is a very big topic, my post by no means can cover all the important subtopics. I plan to update it periodically and keep further enriching the content gradually in time.\",\n",
    "    \"Good exploration becomes especially hard when the environment rarely provides rewards as feedback or the environment has distracting noise. Many exploration strategies are proposed to solve one or both of the following problems.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for comment in sample:\n",
    "    counter.update(comment.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = torchtext.vocab.Vocab(counter, max_size=len(counter), vectors=glove, specials=['<pad>', '<unk>'])\n",
    "torch.zero_(vocabulary.vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vocab size:  89\n"
     ]
    }
   ],
   "source": [
    "print('Embedding vocab size: ', vocabulary.vectors.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(89, 50)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "         -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "          2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "          1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "         -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "         -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "          4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "          7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "         -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "          1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding = nn.Embedding.from_pretrained(vocabulary.vectors)\n",
    "# Get embeddings for index 1\n",
    "input_ = torch.LongTensor([2])\n",
    "embedding(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, glu_layers, kernel_size, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        self.ConvLayers = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels = hidden_dim, \n",
    "                out_channels = 2 * hidden_dim, \n",
    "                kernel_size = kernel_size, \n",
    "                padding = (kernel_size - 1) // 2\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.max = nn.MaxPool1d(glu_layers) ## come back to this\n",
    "        self.linear = nn.Linear() ## fill this in with dimensions\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.res_scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\n",
    "        \n",
    "        \n",
    "        def forward(self, x):\n",
    "            \n",
    "            for idx, conv in enumerate(self.ConvLayers):\n",
    "                \n",
    "                x_conv = conv(self.dropout(x))\n",
    "                x_conv = F.glu(x_conv, dim=1)\n",
    "                x_conv = (x_conv + x) * self.res_scale\n",
    "                \n",
    "                x = x_conv\n",
    "                \n",
    "            \n",
    "            x = self.max(x)\n",
    "            \n",
    "            x = F.relu(self.linear(x))\n",
    "            \n",
    "            return x\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.modules.pooling._MaxPoolNd??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 50]) torch.Size([1, 16, 23])\n"
     ]
    }
   ],
   "source": [
    "m = nn.MaxPool1d(5, stride=2)\n",
    "input = torch.randn(1, 16, 50)\n",
    "output = m(input)\n",
    "\n",
    "print(input.shape, output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
